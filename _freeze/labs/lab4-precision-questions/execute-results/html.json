{
  "hash": "f3e11bed340611f0cd9cde6c6286444e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 4: Precision and adjustment for baseline\"\nauthor: \"Chris Slaughter\"\nname: labs/lab4-precision-questions.qmd\ntoc: true\n---\n\n\n## Introduction\n\nBaseline covariates impact the outcome in many clinical trials. Although baseline adjustment is not always necessary, in case of a strong or moderate association between a baseline covariate(s) and the primary outcome measure, adjustment for such covariate(s) generally improves the efficiency of the analysis and avoids conditional bias from chance covariate imbalance.\n\n## Part 1: Continuous outcomes\n\nIf a baseline value of a continuous primary outcome measure is available, then this should usually be included as a covariate.\n\nFirst, we will go over the overview slides on Supplemental Materials on course web page: Analyzing change from baseline in trials. The mean difference presented in the slides can be expressed using the following three linear regression model.\n\n### Models\n\nFor a continuous outcome $Y$, also measured at baseline $W$ and treatment group $X$, consider the following linear regression models. Let $Z = Y - W$, the change from baseline.\n\n#### Model 1: Compare the mean final value by treatment group\n\n$$\nY_i = \\gamma_0 + \\gamma_1*X_i + \\epsilon_i\n$$\n\n#### Model 2: Compare the mean change, final minus initial, by treatment group.\n\n$$\nZ_i = \\alpha_0 + \\alpha_1 * X_i + e_i\n$$\n\n#### Model 3: Final value adjusted for baseline by treatment group\n\n$$\nY_i = \\beta_0 + \\beta_1 * X_i + \\beta_2 * W_i + e_i\n$$\n\n#### Q 1.1 When is model 1 preferred or model 2? That is, what values of $\\rho$ (correlation between baseline and followup values of outcome) lead to smaller variance under each model?\n\n-   If we assume equal variance for the baseline and final values\n\n    -   $\\textrm{Var}(Y) = \\textrm{Var}(W) = \\sigma^2$\n\n    -   $\\textrm{Cov}(Y,W) = \\rho \\sigma^2$\n\n-   For Model 1\n\n$$\n\\textrm{Var(Y)} = \\sigma^2\n$$\n\n-   And we can calculate for Model 2\n\n$$\n\\begin{aligned}\n\\textrm{Var}(Z) & = \\textrm{Var}(Y-W) \\\\\n& = \\textrm{Var}(Y) + \\textrm{Var}(W) - 2\\textrm{Cov}(Y,W) \\\\\n& = 2\\sigma^2 (1 - \\rho)\n\\end{aligned}\n$$\n\n#### Q 1.2 When is model 3 preferred over models 1 and 2? Consider different values of $\\rho$.\n\n-   In model 3 where we adjust for baseline\n\n$$\n\\begin{aligned}\n\\textrm{Var}(Y - \\rho W) & = \\textrm{Var(Y)} - \\rho(\\textrm{Cov}(Y,W)) + \\rho^2\\textrm{Var(W)} \\\\\n& = \\sigma^2 - 2\\rho^2\\sigma^2 + \\rho^2\\sigma^2. \\\\\n& = \\sigma^2(1-\\rho^2)\n\\end{aligned}\n$$\n\n#### Summary table\n\nThe following table gives the calculated SD from the formulas for Models 1, 2 and 3 for values of rho ranging from -0.2 to 0.9. Models 1 is more efficient than model 2 for low correlations below 0.5; Model 2 is more efficient than model 1 for high correlations above 0.5; Model 1 and Model 2 are equivalent at rho of 0.5. Model 3, adjustment for baseline, is equivalent to Model 1 when rho is 0 (baseline and followup are not correlated). Otherwise, model 3 is always better than models 1 or 2. For very high correlations, Models 2 and 3 have similar efficiency. Model 3 improves efficiency if rho is positive or negative.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrho <- seq(-.2,.9,by=.1)\nsigma <- 1\n\n# Model 1\nsd1 <- rep(sigma, length(rho))\n\n# Model 2\nsd2 <- sqrt(2*sigma^2*(1-rho))\n\n# Model 3\nsd3 <- sqrt(sigma^2*(1-rho^2))\n\ncbind(rho, sd1, sd2, sd3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       rho sd1       sd2       sd3\n [1,] -0.2   1 1.5491933 0.9797959\n [2,] -0.1   1 1.4832397 0.9949874\n [3,]  0.0   1 1.4142136 1.0000000\n [4,]  0.1   1 1.3416408 0.9949874\n [5,]  0.2   1 1.2649111 0.9797959\n [6,]  0.3   1 1.1832160 0.9539392\n [7,]  0.4   1 1.0954451 0.9165151\n [8,]  0.5   1 1.0000000 0.8660254\n [9,]  0.6   1 0.8944272 0.8000000\n[10,]  0.7   1 0.7745967 0.7141428\n[11,]  0.8   1 0.6324555 0.6000000\n[12,]  0.9   1 0.4472136 0.4358899\n```\n\n\n:::\n:::\n\n\n### Power/sample size calculations\n\n#### Supplemental Notes Example\n\n-   Assuming a correlation of 0.4 between baseline and follow-up pain scores, a clinically important difference of 1.8 NRS units, a standard deviation of 3 NRS units, power of 80% and significance level of 5%, the following sample sizes are required:\n\n##### R code and results\n\n-   Using the formulas above, we can find the standard deviation under the three analysis approaches (Final, Change, Regression adjusted for baseline)\n\n-   Effect size is then difference in means (1.8) divided by the standard deviations\n\n-   In R, input this effect size divided by the standard deviation (d) and either power (to output sample size) or sample size (to output power)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\n\n# For final value\ns1 <- 3\n\n# For change\ns2 <- sqrt(2*3^2*(1-0.4))\ns2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.286335\n```\n\n\n:::\n\n```{.r .cell-code}\n# For linear regression (Stata calls this ANCOVA)\ns3 <- sqrt(3^2*(1-.4^2))\ns3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.749545\n```\n\n\n:::\n\n```{.r .cell-code}\n# Final value\npwr.t.test(n=NULL, d=1.8/s1, power=.9)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 59.35155\n              d = 0.6\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n\n```{.r .cell-code}\n# Change\npwr.t.test(n=NULL, d=1.8/s2, power=.9)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 71.02369\n              d = 0.5477226\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n\n```{.r .cell-code}\n# Regression adjusting for baseline\npwr.t.test(n=NULL, d=1.8/s3, power=.9)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 50.01479\n              d = 0.6546537\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\n##### Stata approach\n\n-   Stata can give these same results, but doesn't require you to know the standard deviation formulas given above for Models 1, 2 and 3\n\n-   Following is the full Stata output for the example.\n\n-   (You would have to know that ANCOVA is equivalent to the linear regression model adjusted for baseline)\n\n```         \n. sampsi 0 1.8, sd(3) pre(1) post(1) r01(.4)\n\nEstimated sample size for two samples with repeated measures\nAssumptions:\n                                      alpha =   0.0500  (two-sided)\n                                      power =   0.9000\n                                         m1 =        0\n                                         m2 =      1.8\n                                        sd1 =        3\n                                        sd2 =        3\n                                      n2/n1 =     1.00\n           number of follow-up measurements =        1\n            number of baseline measurements =        1\n   correlation between baseline & follow-up =    0.400\n\nMethod: POST\n relative efficiency =    1.000\n    adjustment to sd =    1.000\n        adjusted sd1 =    3.000\n\n Estimated required sample sizes:\n                  n1 =       59\n                  n2 =       59\n\nMethod: CHANGE\n relative efficiency =    0.833\n    adjustment to sd =    1.095\n        adjusted sd1 =    3.286\n\n Estimated required sample sizes:\n                  n1 =       71\n                  n2 =       71\n\nMethod: ANCOVA\n relative efficiency =    1.190\n    adjustment to sd =    0.917\n        adjusted sd1 =    2.750\n\n Estimated required sample sizes:\n                  n1 =       50\n                  n2 =       50\n\n. di sqrt(1-0.4^2)\n.91651514\n\n. di 3*sqrt(1-.4^2)\n2.7495454\n\n. di sqrt(2*1*(1-0.4))\n1.0954451\n```\n\n## Part 2: Binary outcomes\n\nFor generalized linear models or non-linear models, adjusted and unadjusted treatment effects may not have the same interpretation and, sometimes, different results may be obtained from adjusted and unadjusted analyses. Thus, the choice of the appropriate covariates and the pre-specification of the primary model are critically important.\n\n[RCT analysis with covariate adjustment (binary outcome)](https://www.fharrell.com/post/covadj/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}