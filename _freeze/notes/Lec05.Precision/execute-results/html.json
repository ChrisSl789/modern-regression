{
  "hash": "b93cc064a8041dc57b14aa280cdf085a",
  "result": {
    "markdown": "---\ntitle: \"Precision of Statistical Intefence\"\nsubtitle: \"Lecture 05\"\nauthor: \"Chris Slaughter\"\nfooter: \"Bios 6312\"\nformat:\n  html:\n    embed-resources: true\n    standalone: true\n    number-sections: true\n    number-depth: 4\n    anchor-sections: true\n    smooth-scroll: true\n    theme: journal\n    toc: true\n    toc-depth: 4\n    toc-title: Contents\n    toc-location: left\n    code-link: false\n    code-tools: true\n    code-fold: true\n    code-block-bg: \"#f1f3f5\"\n    code-block-border-left: \"#31BAE9\"\n    reference-location: margin\n    fig-cap-location: margin\n    fontsize: medium\nexecute:\n   warning: false\n   message: false\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n## Overview\n\n-   Goal of statistical inference is to estimate parameters *accurately*\n    (unbiased) and with high *precision*\n\n-   Measures of precision\n\n    -   Standard error (not standard deviation)\n\n    -   Width of confidence intervals\n\n    -   Power (equivalently, type II error rate)\n\n-   Scientific hypotheses are typically refined in statistical\n    hypotheses by identifying some parameter, $\\theta$, measuring\n    differences in the distribution of the response variable\n\n-   Often we are interested in if $\\theta$ differs across of levels of\n    categorical (e.g. treatment/control) or continuous (e.g. age)\n    predictor variables\n\n-   $\\theta$ could be any summary measure such as\n\n    -   Difference/ratio of means\n\n    -   Difference/ratio of medians\n\n    -   Ratio of geometric means\n\n    -   Difference/ratio of proportions\n\n    -   Odds ratio, relative risk, risk difference\n\n    -   Hazard ratio\n\n-   How to select $\\theta$? In order of importance\\...\n\n1.  Scientific (clinical) importance. May be based on current state of\n    knowledge\n\n2.  Is $\\theta$ likely to vary across the predictor of interest? Impacts\n    the ability to detect a difference, if it exists.\n\n3.  Statistical precision. Only relevant if all other factors are equal.\n\n-   Statistics is concerned with making inference about population\n    parameters, ($\\theta$), based on a sample of data\n\n    -   Frequentist estimation includes both point estimates\n        ($\\hat{\\theta}$) and interval estimates (confidence intervals)\n\n    -   Bayesian analysis estimates the posterior distribution of\n        $\\theta$ given the sampled data, $p(\\theta | \\textrm{data})$.\n        The posterior distribution can then be summarized by quantities\n        like the posterior mean and 95% credible interval.\n\n### Example\n\nConsider the following results from 5 clinical trials of three drugs (A,\nB, C) designed to lower cholesterol compared to baseline. Assume a 10\nunit drop in cholesterol (relative to baseline) is clinically\nmeaningful.\n\n| Trial | Drug | Pts  | Mean diff | Std dev | Std error | 95% CI for diff  | p-value |\n|:------|:-----|:-----|:----------|:--------|:----------|:-----------------|:--------|\n| 1     | A    | 30   | -30       | 191.7   | 49.5      | \\[-129, 69\\]     | 0.55    |\n| 2     | A    | 1000 | -30       | 223.6   | 10        | \\[-49.6, -10.4\\] | 0.002   |\n| 3     | B    | 40   | -20       | 147.6   | 33        | \\[-85, 45\\]      | 0.55    |\n| 4     | B    | 4000 | -2        | 147.6   | 3.3       | \\[-8.5, 4.5\\]    | 0.54    |\n| 5     | C    | 5000 | -6        | 100.0   | 2         | \\[-9.9, -2.1\\]   | 0.002   |\n\n-   Compare the results of the different trials with respect to the\n    sample size, mean difference, etc.\n\n    -   Which drug is effective at reducing cholesterol?\n\n    -   Why is study 4 more informative than study 3 (even though the\n        $p$ values are similar)?\n\n    -   Key points\n\n        -   Hypothesis tests and $p$-values can often be insufficient to\n            make proper decisions. The confidence interval provides more\n            useful information.\n        -   Narrower confidence intervals (more precise estimates) allow\n            for scientific conclusion regardless of the $p$ value\n\n## Precision variables and regression modeling\n\n### Definition\n\n-   Pure precision variables are associated with the outcome only\n\n    -   That is, no association (in the sample) with the predictor of\n        interest\n\n-   In a randomized trial where random treatment assignment is the\n    predictor of interest it may be possible to have a pure precision\n    variable by using stratified randomization\n\n    -   Stratified randomization can guarantee that there is no\n        correlation between the precision variable and treatment group\n        assignment\n\n-   In observational research, there may be some correlation between the\n    precision variable and the predictor of interest\n\n    -   May act more like a confounder in these cases, depending on the\n        size of the association\n\n### Directed Acyclic Graph\n\n\n```{mermaid}\nflowchart LR\n  X[Predictor\\nof interest] --> Y[Outcome]\n  W[Precision] --> Y[Outcome]\n```\n\n\n### Example\n\n#### Data generation\n\n-   Categorical precision variable (W), Predictor of Interest (X),\n    Outcome (Y)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate some data\nset.seed(1231)\nn <- 200\nprecisiondata <- \n  data.frame(W=rep(0:1, each=n/2),\n             X=runif(n),\n             Y=NA\n)\nprecisiondata$Y <- 10 + 1.5*precisiondata$X + 10*precisiondata$W + rnorm(n,0,4)\nprecisiondata$W <- factor(precisiondata$W)\n```\n:::\n\n\n#### Bivariate plots\n\n-   W is uncorrelated with X, and associated with Y\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(precisiondata, aes(x=W,y=X)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![Box plot showing the (lack of) association between the precision variable (W) and the predictor of interest (X)](Lec05.Precision_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(precisiondata, aes(x=W,y=Y)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![Box plot showing the association between the precision variable (W) and the outcome (Y)](Lec05.Precision_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(precisiondata, aes(x=X,y=Y)) + geom_point() + geom_smooth(method=\"lm\")\n```\n\n::: {.cell-output-display}\n![Association between the predictor of interest (X) and the outcome (Y) ignoring the precision variable (W)](Lec05.Precision_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n#### Bivariate plot by W\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(precisiondata, aes(x=X,y=Y,color=W,group=W)) + geom_point() + geom_smooth(method=\"lm\")\n```\n\n::: {.cell-output-display}\n![Association between the predictor of interest (X) and the outcome (Y) by the precision variable (W)](Lec05.Precision_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n#### Adjusted and unadjusted regression models\n\n-   Unadjusted: $E[Y|X] = \\beta_0 + \\beta_1*X$\n-   Adjusted: $E[Y|X] = \\beta_0 + \\beta_1*X + \\beta_2*W$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Y ~ X, data=precisiondata))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ X, data = precisiondata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.9532  -4.6804  -0.7675   5.5132  13.5264 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  13.8858     0.8822  15.740   <2e-16 ***\nX             3.4619     1.5818   2.189   0.0298 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.227 on 198 degrees of freedom\nMultiple R-squared:  0.02362,\tAdjusted R-squared:  0.01869 \nF-statistic:  4.79 on 1 and 198 DF,  p-value: 0.0298\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(Y ~ X + W, data=precisiondata))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ X + W, data = precisiondata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.2400 -2.8797  0.3465  2.3857 11.7172 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   9.1712     0.6417  14.292  < 2e-16 ***\nX             3.4659     1.0294   3.367 0.000915 ***\nW1            9.4252     0.5731  16.446  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.052 on 197 degrees of freedom\nMultiple R-squared:  0.5885,\tAdjusted R-squared:  0.5844 \nF-statistic: 140.9 on 2 and 197 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmykable = function(x){\n  knitr::kable(x, row.names = FALSE, align = c(\"l\", \"l\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\"),\n               booktabs=TRUE)\n}\n\nlibrary(finalfit)\nlibrary(dplyr)\n\nexplanatory = c(\"X\", \"W\")\ndependent = \"Y\"\n\nprecisiondata %>% \n  finalfit(dependent, explanatory) %>% mykable()\n```\n\n::: {.cell-output-display}\n|Dependent: Y |          |      unit|      value|     Coefficient (univariable)|   Coefficient (multivariable)|\n|:------------|:---------|---------:|----------:|-----------------------------:|-----------------------------:|\n|X            |[0.0,1.0] | Mean (sd)| 15.6 (6.3)|  3.46 (0.34 to 6.58, p=0.030)|  3.47 (1.44 to 5.50, p=0.001)|\n|W            |0         | Mean (sd)| 10.8 (4.1)|                             -|                             -|\n|             |1         | Mean (sd)| 20.3 (4.2)| 9.42 (8.27 to 10.58, p<0.001)| 9.43 (8.30 to 10.56, p<0.001)|\n:::\n:::\n\n\n## Sampling Distributions\n\n-   The sampling distribution is the probability distribution of a\n    statistic\n\n    -   e.g. the sampling distribution of the sample mean is\n        $N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$\n\n-   Most often we choose estimators that are asymptotically Normally\n    distributed\n\n    -   For large $n$,\n        $\\hat{\\theta} \\sim N\\left(\\theta, \\frac{V}{n} \\right)$\n\n    -   $\\hat{\\theta}$ is our estimate of $\\theta$. The $\\hat{ }$\n        indicates it is an estimate.\n\n    -   Mean: $\\theta$\n\n-   Variance: $V$, which is related to the \"average amount of\n    statistical information\" available from each observation\n\n    -   Often $V$ depends on $\\theta$\n\n\"Large\" $n$ depends on the distribution of the underlying data. If $n$\nis large enough, approximate Normality of $\\hat{\\theta}$ will hold.\n\nCalculating $100 (1-\\alpha)\\%$ confidence intervals\n$\\left(\\theta_L, \\theta_U \\right)$ with approximate Normality\n\n-   $\\theta_L = \\hat{\\theta} - Z_{1-\\alpha/2} \\sqrt{\\frac{V}{n}}$\n\n-   $\\theta_U = \\hat{\\theta} + Z_{1-\\alpha/2} \\sqrt{\\frac{V}{n}}$\n\n-   (estimate) $\\pm$ (crit val) $\\times$ (std err of estimate)\n\nCan similarly calculate approximate two-sided $p$-values\n\n-   $Z = \\frac{\\textrm{(estimate)} - \\textrm{(hyp value)}}{\\textrm{(std err of estimate)}}$\n\n## Precision and Power/Sample Size\n\n-   What are the measures of (high) precision?\n\n    -   Estimators are less variable across studies, which is often\n        measured by decreased standard error.\n\n    -   Narrower confidence intervals. Estimators are consistent with\n        fewer hypotheses if the CIs are narrow.\n\n    -   Able to reject false hypotheses. Z statistic is higher when the\n        alternative hypothesis is true.\n\n-   Translation into sample size\n\n    -   Based on the width of the confidence interval\n\n    -   Choose a sample size such that a 95% CI will not contain both\n        the null and design alternative\n\n    -   If both $\\theta_0$ and $\\theta_1$ cannot be in the CI, we have\n        discriminated between those hypotheses\n\n-   Based on statistical power\n\n    -   When the alternative is true, have a high probability of\n        rejecting the null\n\n    -   In other words, minimize the type II error rate\n\n-   Statistical power: Quick review\n\n    -   Power is the probability of rejecting the null hypothesis when\n        the alternative is true\n\n    -   Pr(reject $H_0 | \\theta = \\theta_1$)\n\n    -   Most often\n        $\\hat{\\theta} \\sim N\\left(\\theta, \\frac{V}{n} \\right)$ so that\n        the test statistic\n        $Z = \\frac{\\hat{\\theta} - \\theta_0}{\\sqrt{V/n}}$ wll follow a\n        Normal distribution\n\n    -   Under $H_0$, $Z \\sim N(0, 1)$ so we reject $H_0$ if\n        $|Z| > Z_{1-\\alpha/2}$\n\n    -   Under $H_1$,\n        $Z \\sim N\\left(\\frac{\\theta_1 - \\theta_0}{\\sqrt{V/n}}, 1\\right)$\n\n-   Power curves\n\n    -   The power function (power curve) is a function of the true value\n        of $\\theta$\n\n    -   We can compute power for every value of $\\theta$\n\n    -   As $\\theta$ moves away from $\\theta_0$, power increases (for\n        two-sided alternatives)\n\n    -   For any choice of desired power, there is always some $\\theta$\n        such that the study has that power\n\n    -   $Pwr(\\theta_0) = \\alpha$, the type I error rate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmydiffs <- seq(-.8,.8,.05)\n\nmypower <- vector(\"numeric\", length(mydiffs))\nmypower2 <- vector(\"numeric\", length(mydiffs))\n\nfor(i in 1:length(mydiffs)){\n   mypower[i] <- power.t.test(n=100, sd=1, delta=mydiffs[i])$power\n   mypower2[i] <- power.t.test(n=100, sd=1.2, delta=mydiffs[i])$power\n}\n\nplot(mydiffs, mypower, xlab=\"True difference in means (theta)\", ylab=\"Power\", type=\"l\", main=\"\")\nlines(mydiffs, mypower2, lty=2)\nlegend(\"top\", c(\"sigma = 1.0\",\"sigma = 1.2\"), lty=1:2, inset=0.05)\n```\n\n::: {.cell-output-display}\n![Power curves for a two-sample, equal variance, t-test; n=100](Lec05.Precision_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## Precision and Standard Errors\n\n-   Standard errors are the key to precision\n\n-   Greater precision is achieved with smaller standard errors\n\n-   Standard errors are decreased by either decreasing $V$ or increasing\n    $n$\n\n    -   Typically: $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}}$\n\n    -   Width of CI:\n        $2 \\times (\\textrm{crit value}) \\times se(\\hat{\\theta})$\n\n    -   Test statistic:\n        $Z = \\frac{\\hat{\\theta} - \\theta_0}{se(\\hat{\\theta})}$\n\n### Example: One sample mean\n\n-   Observations are independent and identically distributed (iid)\n\n    -   $\\textrm{iid } Y_i \\sim (\\mu, \\sigma^2), i = 1, \\ldots, n$\n\n    -   $\\theta = \\mu$,\n        $\\hat{\\theta} = \\frac{1}{n} \\displaystyle \\sum_{i=1}^n Y_i = \\overline{Y}$\n\n    -   $V = \\sigma^2$, $se(\\hat{\\theta}) = \\sqrt{\\frac{\\sigma^2}{n}}$\n\n-   Note that we are not assuming a specific distribution for $Y_i$,\n    just that the distribution has a mean and variance\n\n-   We are assuming that $n$ is large so asymptotic results are\n    applicable\n\n    -   Then the distribution $Y_i$ could be binary data, Poisson,\n        exponential, normal, etc. and the results will hold\n\n-   There are ways to decrease $V$ including\\...\n\n    -   Restrict sample by age, gender, etc.\n\n    -   Take repeated measures on each subject, summarize, and perform\n        test on summary measures\n\n    -   Better ideas (this course)\n\n        -   Adjust for age and gender rather than restrict\n        -   Use all repeated observations and modeling correlation\n\n### Example: Two sample mean\n\n-   Difference of independent means\n\n-   Observations no longer identically distributed, just independent.\n    Group 1 has a different mean and variance than group 2\n\n    -   $\\textrm{ind } Y_{ij} \\sim (\\mu_j, \\sigma_j^2), j = 1, 2; i = 1, \\ldots, n_j$\n\n    -   $n = n_1 + n_2$; $r = n_1 / n_2$\n\n    -   $\\theta = \\mu_1 - \\mu_2$,\n        $\\hat{\\theta} = \\overline{Y}_1 - \\overline{Y}_2$\n\n    -   $V = (r+1)(\\frac{\\sigma_1^2}{r} + \\sigma_2^2)$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}$\n\n### Comments on the optimal ratio of sample sizes ($r$)\n\n-   If we are constrained by the maximal sample size $n = n_1 + n_2$\n\n    -   Smallest $V$ when\n        $r = \\frac{n_1}{n_2} = \\frac{\\sigma_1}{\\sigma_2}$\n\n    -   In other words, smaller $V$ if we sample more subjects from the\n        more variable group\n\n-   If we are unconstrained by the maximal sample size, there is a point\n    of diminishing returns\n\n-   Example: Case-control study where finding cases is\n    difficult/expensive but finding controls is easy/cheap\n\n    -   Often quoted little benefit beyond $r = 5$. That is, little\n        benefit in having more than 5 times as many controls as cases\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.fn <- function(r, s1, s2) {\n  (r + 1) * (s1^2/r + s2^2)\n}\n\n# Optimal sample size ratio for fixed sample size\n\nn <- 100\ns2 <- 10\n\nplot(function(r) sqrt(var.fn(r, s1=s2, s2=s2) / n), 0, 20, ylim=c(1,6), xlim=c(0,25), ylab=\"Standard Error\", xlab=\"Sample Size Ratio r = n1/n2\")\nplot(function(r) sqrt(var.fn(r, s1=2*s2, s2=s2) / n), 0, 20, add=TRUE, lty=2)\nplot(function(r) sqrt(var.fn(r, s1=3*s2, s2=s2) / n), 0, 20, add=TRUE, lty=3)\ntext(20,4.7,\"s1 = s2\", pos=4)\ntext(20,5.1,\"s1 = 2*s2\", pos=4)\ntext(20,5.5,\"s1 = 3*s2\", pos=4)\npoints(c(1,2,3), sqrt(var.fn(c(1,2,3), s1=c(1,2,3)*s2, s2=s2)/ n), pch=2)\ntext(1, 1.8, \"r = 1\")\ntext(2, 2.8, \"r = 2\")\ntext(3, 3.8, \"r = 3\")\n```\n\n::: {.cell-output-display}\n![Optimal r for Fixed (n1 + n2). r = s1 / s2, the ratio of standard deviations in the two group.](Lec05.Precision_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn1 <- 200\n\nplot(function(r) sqrt(var.fn(r, s1=s2, s2=s2) / (n1 + r*n1)), 0, 20, ylim=c(0.5,3), xlim=c(0,25), ylab=\"Standard Error\", xlab=\"Sample Size Ratio r = n1/n2\")\nplot(function(r) sqrt(var.fn(r, s1=2*s2, s2=s2) / (n1 + r*n1)), 0, 20, add=TRUE, lty=2)\nplot(function(r) sqrt(var.fn(r, s1=3*s2, s2=s2) / (n1 + r*n1)), 0, 20, add=TRUE, lty=3)\n\ntext(20,.7,\"s1 = s2\", pos=4)\ntext(20,.8,\"s1 = 2*s2\", pos=4)\ntext(20,.9,\"s1 = 3*s2\", pos=4)\n```\n\n::: {.cell-output-display}\n![Diminishing returns for r > 5.  s1 and s2 are the standard deviations is group 1 and group 2, respectively.  s1=s2 indicates the two groups have equal variablility.  Other conditions represent the cases where the group we are oversampling has more variability.](Lec05.Precision_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n### Example: Paired means\n\n-   Difference of paired means\n\n-   No longer iid. Group 1 has a different mean and variance than group\n    2, and observations are paired (correlated)\n\n    -   $Y_{ij} \\sim (\\mu_j, \\sigma_j^2), j = 1, 2; i = 1, \\ldots, n$\n\n    -   $corr(Y_{i1}, Y_{i2}) = \\rho; corr(Y_{ij}, Y_{mk}) = 0 \\textrm{ if } i \\neq m$\n\n    -   $\\theta = \\mu_1 - \\mu_2$,\n        $\\hat{\\theta} = \\overline{Y}_1 - \\overline{Y}_2$\n\n    -   $V = \\sigma_1^2+ \\sigma_2^2 - 2 \\rho \\sigma_1 \\sigma_2$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}}$\n\n-   Precision gains are made when matched observations are positively\n    correlated ($\\rho > 0$)\n\n    -   Usually the case, but possible exceptions\n\n        -   Sleep on successive nights\n\n        -   Intrauterine growth of litter-mates\n\n### Example: Clustered data\n\n-   Clustered data: Experiment where treatments/interventions are\n    assigned based on the basis of \"clusters\"\n\n    -   Households\n\n    -   Schools\n\n    -   Clinics\n\n    -   Cities\n\n-   Mean of clustered data\n\n    -   $Y_{ij} \\sim (\\mu, \\sigma^2), i = 1, \\ldots, n; j = 1, \\ldots, m$\n\n-   Up to $n$ clusters, each of which have $m$ subjects\n\n    -   $corr(Y_{ij}, Y_{ik}) = \\rho \\textrm{ if } j \\neq k$\n\n    -   $corr(Y_{ij}, Y_{mk}) = 0 \\textrm{ if } i \\neq m$\n\n-   $\\theta = \\mu$,\n    $\\hat{\\theta} = \\frac{1}{nm} \\displaystyle \\sum_{i=1}^{n} \\sum_{j=1}^m Y_{ij} = \\overline{Y}$\n\n-   $V = \\sigma^2 \\left(\\frac{1 + (m-1)\\rho}{m} \\right)$\n\n-   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}}$\n\nWhat is V if \\...\n\n-   $\\rho = 0$ (independent)\n\n-   $m = 1$\n\n-   $m$ is large (e.g $m = 1000$) and $\\rho$ is 0, 1, or 0.01\n\n-   With clustered data, even small correlations can be very important\n    to consider\n\n    -   Equal precision achieved with\n\n::: center\n| Clusters ($n$) | $m$ | $\\rho$ | Total N |\n|:---------------|:----|:-------|:--------|\n| 1000           | 1   | 0.01   | 1000    |\n| 650            | 2   | 0.30   | 1300    |\n| 550            | 2   | 0.10   | 1100    |\n| 190            | 10  | 0.10   | 1900    |\n| 109            | 10  | 0.01   | 1090    |\n| 20             | 100 | 0.01   | 2000    |\n:::\n\n-   Always consider practical issues. Is it easier/cheaper to collect 1\n    observation on 1000 different subjects ($n=1000$, $m=1$), or 100\n    observations on 20 different subjects ($n=20$, $m=100$)? These two\n    designs have equal precision.\n\n### Example: Independent Odds Ratios\n\n-   Binary outcomes\n\n-   $\\textrm{ind } Y_{ij} \\sim B(1, p_j), i = 1, \\ldots, n_j; j = 1, 2$\n\n-   $n = n_1 + n_2; r = n_1 / n_2$\n\n-   $\\theta = \\textrm{log}\\left(\\frac{p_1/(1-p_1)}{p_2/(1-p_2)} \\right)$;\n    $\\hat{\\theta} = \\textrm{log}\\left(\\frac{\\hat{p}_1/(1-\\hat{p}_1)}{\\hat{p}_2/(1-\\hat{p}_2)} \\right)$\n\n-   $\\sigma^2_j = \\frac{1}{p_j(1-p_j)} = \\frac{1}{p_j(q_j)}$\n\n-   $V = (r+1)(\\frac{\\sigma_1^2}{r} + \\sigma_2^2)$\n\n-   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}} = \\sqrt{\\frac{1}{n_1 p_1 q_1} + \\frac{1}{n_2 p_2 q_2}}$\n\n-   Notes on maximum precision\n\n    -   Max precision is achieved when the underlying odds are near 1\n        (proportions near 0.5)\n\n    -   If we were considering differences in proportions, the max\n        precision is achieved when the underlying proportions are near 0\n        or 1\n\n### Example: Hazard Ratios\n\n-   Independent censored time to event outcomes\n\n    -   $(T_{ij}, \\delta_{ij}), i = 1, \\ldots, n_j; j = 1, 2$\n\n    -   $n = n_1 + n_2; r = n_1 / n_2$\n\n    -   $\\theta = \\textrm{log(HR)}$; $\\hat{\\theta} = \\hat{\\beta}$ from\n        proportional hazards (PH) regression\n\n    -   $V = \\frac{(r+1)(1/r+1)}{\\textrm{Pr}(\\delta_{ij} = 1)}$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}} = \\sqrt{\\frac{(r+1)(1/r+1)}{d}}$\n\n-   In the PH model, statistical information is roughly proportional to\n    $d$, the number of observed events\n\n    -   Papers always report the number of events\n\n    -   Study design must consider how long it will take to observe\n        events (e.g. deaths) starting from randomization\n\n### Example: Linear Regression\n\n-   Independent continuous outcomes associated with covariates\n\n    -   $\\textrm{ind } Y_i | X_i ~ \\sim(\\beta_0 + \\beta_1 X_i, \\sigma^2_{Y|X}), i = 1, \\ldots, n$\n\n    -   $\\theta = \\beta_1, \\hat{\\theta} = \\hat{\\beta_1}$ from LS\n        regression\n\n    -   $V = \\frac{\\sigma^2_{Y|X}}{\\textrm{Var}(X)}$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\sigma}^2_{Y|X}}{n \\hat{\\textrm{Var}}(X)}}$\n\n-   Precision tends to increases as the predictor ($X$) is measured over\n    a wider range\n\n-   Precision also related to the within group variance $\\sigma^2_{Y|X}$\n\n    -   What happens to the formulas when $X$ is a binary variable? See\n        two sample mean\n\n## Summary and Concluding Comments\n\n-   Options for increasing precision\n\n    -   Increase sample size\n\n    -   Decrease $V$\n\n    -   (Decrease confidence level)\n\n-   Criteria for precision\n\n    -   Standard error\n\n    -   Width of confidence intervals\n\n    -   Statistical power\n\n-   Select a suitable, scientifically meaningful alternative\n\n    -   With proper precision, can distinguish between minor and\n        meaningful effects\n\n-   Select desired power\n\n-   Sample size calculation: The number of sampling units needed to\n    obtain the desired precision\n\n    -   Level of significance $\\alpha$ when $\\theta = \\theta_0$\n\n    -   Power $\\beta$ when $\\theta = \\theta_1$\n\n    -   Variability $V$ within one sampling unit\n\n    -   $n = \\frac{(z_{1-\\alpha/2} + z_\\beta)^2 \\times V}{(\\theta_1 - \\theta_0)^2}$\n\n-   When sample size is constrained (the usual case) either\n\n    -   Compute power to detect a specified alternative\n\n        -   $1 - \\beta = \\phi \\left(\\frac{(\\theta_1-\\theta_0)}{\\sqrt{V/n}} - z_{1-\\alpha/2} \\right)$\n\n        -   $\\phi$ is the standard Normal cdf function\n\n        -   In STATA, use normprob for the $\\phi$ function\n\n    -   Compute alternative that can be detected with high power\n\n        -   $\\theta_1 = \\theta_0 + (z_{1-\\alpha/2} + z_\\beta) \\sqrt{V/n}$\n\n### General Comments\n\n-   Sample size required behaves like the square of the width of the CI.\n    To cut the width of the CI in half, need to quadruple the sample\n    size.\n\n-   Positively correlated observations within the same group provide\n    less precision than the same number of independent observations\n\n-   Positively correlated observations across groups provide more\n    precision\n\n-   What power do you use?\n\n    -   Most popular is 80% (too low) or 90%\n\n    -   Key is to be able to discriminate between scientifically\n        meaningful hypotheses\n",
    "supporting": [
      "Lec05.Precision_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}