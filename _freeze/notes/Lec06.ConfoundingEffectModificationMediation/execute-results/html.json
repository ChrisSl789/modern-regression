{
  "hash": "33731a922123174450906405b1cdf66c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Confouding, Effect Modification, and Mediation\"\nsubtitle: \"Lecture 06\"\nname: Lec06.ConfoundingEffectModificationMediation.qmd\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ntryCatch(source('pander_registry.R'), error = function(e) invisible(e))\n```\n:::\n\n\n## Overview\n\n-   Most often scientific questions are translated into comparing the\n    distribution of some response variable across groups of interest\n\n-   Groups are defined by the predictor of interest (POI). Regression\n    methods allow for either categorical or continuous predictors of\n    interest\n\n    -   Categorical predictors of interest: Treatment or control,\n        knockout or\n\n        wild type, ethnic group\n\n    -   Continuous predictors of interest: Age, BMI, cholesterol, blood\n        pressure\n\n-   Often we need to consider additional variables other than the\n    predictor of interest to answer our scientific question\n\n-   Covariates other than the predictor of of interest are included in\n    the regression model as\n\n    -   Effect modifiers\n\n    -   Confounders\n\n    -   Mediating variables\n\n    -   Precision variables\n\n    -   (Not necessarily mutually exclusive)\n\n## Effect Modification\n\n-   The association between the Response and the Predictor of Interest\n    differs in strata defined by the effect modifier\n\n-   Statistical term: \"Interaction\" between the effect modifier and the\n    POI\n\n### Effect modification depends on the measure of effect that you choose\n\n-   Choice of summary measure: mean, median, geometric mean, odds,\n    hazard\n\n-   Choice of comparisons across groups: differences, ratios\n\n### Examples of Effect Modification\n\n#### Example 1: Is serum LDL by smoking modified by gender?\n\n|          |       |      |        |        |\n|----------|-------|------|--------|--------|\n|          | Mean  | Mean | Median | Median |\n|          | Women | Men  | Women  | Men    |\n| No Smoke | 120   | 122  | 120    | 115    |\n| Smoke    | 133   | 122  | 133    | 124    |\n| Diff     | -13   | 0    | -13    | -9     |\n| Ratio    | 0.90  | 1    | 0.90   | 0.93   |\n\n-   Effect modification by gender exists if the effect of smoking in\n    males is different from the effect of smoking in females\n\n    -   Compare the diff (or ratio) for the mean (or median) in women to\n        the diff (or ratio) for the mean (or median) in men\n\n-   Effect modification for mean, not as much for median\n\n    -   Statement holds for both difference or ratio of mean/median\n\n#### Example 2: Creatinine by stroke (modified by gender?)\n\n|           |       |       |        |        |\n|-----------|-------|-------|--------|--------|\n|           | Mean  | Mean  | Median | Median |\n|           | Women | Men   | Women  | Men    |\n| No Stroke | 0.72  | 1.08  | 0.7    | 1.1    |\n| Stroke    | 1.01  | 1.51  | 1.0    | 1.5    |\n| Diff      | -0.29 | -0.43 | -0.3   | -0.4   |\n| Ratio     | 0.71  | 0.72  | 0.70   | 0.73   |\n\n-   Effect modification for difference, not really for ratio\n\n    -   True for Mean or median\n\n#### Example 3: Stroke by smoking (modified by gender?)\n\n|          |            |            |       |       |\n|----------|------------|------------|-------|-------|\n|          | Proportion | Proportion | Odds  | Odds  |\n|          | Women      | Men        | Women | Men   |\n| No Smoke | 0.10       | 0.16       | 0.03  | 0.19  |\n| Smoke    | 0.16       | 0.26       | 0.19  | 0.35  |\n| Diff     | -0.06      | -0.10      | -0.16 | -0.16 |\n| Ratio    | 0.62       | 0.62       | 0.16  | 0.54  |\n\n-   Proportion: No effect modification for ratio, small amount for\n    difference\n\n-   Odds: No effect modification for difference, yes for ratio\n\n#### Example 4: Stroke by smoking (modified by CVD?)\n\n|          |            |            |       |       |\n|----------|------------|------------|-------|-------|\n|          | Proportion | Proportion | Odds  | Odds  |\n|          | None       | CVD        | None  | CVD   |\n| No Smoke | 0.02       | 0.33       | 0.02  | 0.50  |\n| Smoke    | 0.04       | 0.50       | 0.04  | 1.00  |\n| Diff     | -0.02      | -0.17      | -0.02 | -0.50 |\n| Ratio    | 0.50       | 0.67       | 0.50  | 0.50  |\n\n-   Effect Modficiation?\n\n    -   Proportion: Yes for ratio, yes for difference\n\n    -   Odds: Yes for difference, no for ratio\n\n#### Example 5: CHD by current smoking (modified by gender?)\n\n|          |            |            |       |      |\n|----------|------------|------------|-------|------|\n|          | Proportion | Proportion | Odds  | Odds |\n|          | Women      | Men        | Women | Men  |\n| No Smoke | 0.18       | 0.26       | 0.22  | 0.36 |\n| Smoke    | 0.05       | 0.24       | 0.05  | 0.32 |\n| Diff     | 0.13       | 0.02       | 0.17  | 0.03 |\n| Ratio    | 3.60       | 1.08       | 4.17  | 1.11 |\n\n-   Effect Modfication?\n\n    -   Proportion: Yes for ratio, yes for difference\n\n    -   Odds: Yes for difference, yes for ratio\n\n#### Example 6: CHD by ever smoke (modified by gender?)\n\n|             |            |            |       |       |\n|-------------|------------|------------|-------|-------|\n|             | Proportion | Proportion | Odds  | Odds  |\n|             | Women      | Men        | Women | Men   |\n| Never Smoke | 0.16       | 0.25       | 0.19  | 0.33  |\n| Ever Smoke  | 0.16       | 0.26       | 0.19  | 0.35  |\n| Diff        | 0.00       | -0.01      | 0.00  | -0.02 |\n| Ratio       | 1.00       | 0.96       | 1.00  | 0.95  |\n\n-   Effect Modfication?\n\n    -   Proportion: No for ratio, no for difference\n\n    -   Odds: No for difference, no for ratio\n\n#### Summary comments on examples\n\n-   If there is an effect, will see effect modification on at least one\n    of the difference and ratio scale\n\n-   If there is no effect (example 6), will see no effect modification\n    on both difference and ratio scale\n\n-   In real world, will usually see effect modification on both scales.\n    The real question is \"Is the effect modification scientifically\n    meaningful?\"\n\n    -   If we find there is important effect modification, science will\n        go forward estimating effects separately\n\n    -   Models with interaction terms are useful for testing if effect\n        modification is present (statistically)\n\n<!-- -->\n\n-   Aside: Be careful when comparing two ratios\n\n    -   How close are two ratios?\n\n        -   0.20 and 0.25 VERSUS 5.0 and 4.0?\n\n        -   0.10 and 0.15 VERSUS 10.0 and 6.7?\n\n    -   Compare the ratio of ratios, not the difference\n\n    -   We might consider ratios to be more different when both ratios\n        are $>1$ than when both are $<1$. But, that would be wrong.\n\n### Analysis of Effect Modification\n\n-   When the scientific question involves effect modification\n\n    -   Conduct analysis within each stratum separately\n\n    -   If we want to estimate the degree of effect modification or test\n        its existence, use a regression model including\n\n        -   Predictor of interest (main effect)\n\n        -   Effect modifying variable (main effect)\n\n        -   A covariate modeling the interaction (usually a product)\n\n    #### Impact of ignoring effect modification\n\n    -   By design or mistake, we sometimes do not model effect\n        modification\n\n    -   Might perform\n\n        -   Unadjusted analysis: POI only\n\n        -   Adjusted analysis: POI and third variable, but no\n            interaction term\n\n    -   If effect modification exists, an unadjusted analysis will give\n        different results according to the association between the POI\n        and effect modifier in the sample\n\n-   If the POI and the effect modifier are not associated\n\n    -   Unadjusted analysis tends toward an (approximate) weighted\n        average of the stratum specific effects\n\n        -   With means, exactly a weighted average\n\n        -   With odds and hazards, an approximate weighted average\n            (because they are non-linear functions of the mean)\n\n-   If the POI and the effect modifier are associated in the sample\n\n    -   The \"average\" effect is confounded and thus unreliable\n        (variables can be both effect modifiers and confounders)\n\n-   If effect modification exists, an analysis adjusting only for the\n    third variable (but no interaction) will tend toward a weighted\n    average of the stratum specific effects\n\n    -   Hence, an association in one stratum and not the other will make\n        an adjusted analysis look like an association (provide the\n        sample size is large enough)\n\n## Confounding\n\n### Simpson's Paradox\n\n-   Confounding has its roots in Simpson's Paradox\n\n-   Given binary variables $Y$ (response), $X$ (POI), and $Z$ (strata)\n    it is possible to have ...\n\n$$\\textrm{Pr}(Y=1 | X=1, Z=1) > \\textrm{Pr}(Y=1 | X=0, Z=1)$$\n$$\\textrm{Pr}(Y=1 | X=1, Z=0) > \\textrm{Pr}(Y=1 | X=0, Z=0)$$\n\n... but to also have ...\n\n$$\\textrm{Pr}(Y=1 | X=1) < \\textrm{Pr}(Y=1 | X=0)$$\n\n#### Example: Probability of death (Y) at two hospitals (X) stratified by poor patient condition (Z)\n\n-   Question: Which hospital do you want to be treated at?\n    -   Consider the results overall (averaging over Z) and conditional\n        on Z below\n\n| Overall    | Died | Survived | Death Rate |\n|------------|------|----------|------------|\n| Hospital A | 16   | 784      | 2.0%       |\n| Hospital B | 63   | 2037     | 3.0%       |\n\n| Good Condition | Died | Survived | Death Rate |\n|----------------|------|----------|------------|\n| Hospital A     | 8    | 592      | 1.3%       |\n| Hospital B     | 6    | 594      | 1.0%       |\n\n| Poor Condition | Died | Survived | Death Rate |\n|----------------|------|----------|------------|\n| Hospital A     | 8    | 192      | 4.0%       |\n| Hospital B     | 57   | 1443     | 3.8%       |\n\n-   Ignoring condition, Hospital B has a **higher** death rather.\n    However, within both poor and good condition, Hospital B has a\n    **lower** death rate.\n\n    -   Poor condition is a confounder. Hospital B has more subjects\n        with poor condition and subjects with poor condition have a\n        higher death rate.\n\n### Definition of Confounding\n\n-   The association between a predictor of interest and the response is\n    confounded by a third variable if\n\n    -   The third variable is associated with the predictor of interest\n        in the sample, AND\n\n    -   The third variable is associated with the response\n\n        -   Causally (in truth)\n\n        -   In groups that are homogeneous with respect to the predictor\n            of interest\n\n        -   Not in the causal pathway of interest\n\n-   We must consider our belief about the causal relationships among the\n    measured variables\n\n    -   There is no statistical test for causality\n\n    -   Inference about causation comes only from the study design\n\n    -   BUT, consideration of the causal relationships helps us to\n        decide which statistical questions to answer\n\n-   Classic confounder\n\n    -   A clear case of confounding occurs when some third variable is a\n        \"cause\" of both the POI and response\n    -   We generally adjust for such a confounder\n\n#### Directed Acyclyic Graph\n\n\n```{mermaid}\nflowchart LR\n  X[Predictor\\nof interest] -- Causal? --> Y[Outcome]\n  X[Predictor\\nof interest] <-- Association --> Z[Confounder]\n  Z[Confounder] -- Causal --> Y[Outcome]\n```\n\n\n-   Example: Ice cream (POI), murder rate (outcome), and temperature\n    (confounder) in New York City during the summer\n\n\n```{mermaid}\nflowchart LR\n  X[Ice Cream] -- Causal? --> Y[Murder Rate]\n  X[Ice Cream] <-- Association --> Z[Air temperature]\n  Z[Air temperature] -- Causal --> Y[Murder Rate]\n```\n\n\n#### Causal pathways\n\n##### A variable in the causal pathway of interest\n\n-   Not a confounder, so we would not adjust for such a variable\n\n-   If we did adjust, we would lose ability to detect associations\n    between the POI and the outcome\n\n-   Example: Second hand smoke (POI), stunted growth (confounder), FEV1\n    (outcome)\n\n    -   Scientific question is about the impact of smoking on lung\n        function\n\n        -   Stunted growth addresses lung anatomy, not lung function,\n            which we don't care about it\n\n\n```{mermaid}\nflowchart LR\n  X[Second hand smoke] --> Y[FEV1]\n  X[Second hand smoke] --> Z[Stuntend growth]\n  Z[Stunted growth] --> Y[FEV1]\n```\n\n\n##### A variable in the causal pathway *not* of interest\n\n-   However, we want to adjust for a variable in a causal pathway that\n    is not of interest\n    -   Example: Work stress causing ulcers by hormonal effects versus\n        alcoholism\n    -   Directed Acyclyic Graph\n        -   We can adjust for alcoholism to estimate the path through\n            horomonal effects\n        -   Alternatively, we can adjust for hormonal effects to\n            estimate the effect through alcoholism\n\n\n```{mermaid}\nflowchart LR\n  X[Work stress] --> W[Hormonal Effects]\n  X[Work Stress] --> Z[Alcholism]\n  W[Hormonal Effects] --> Y[Ulcers]\n  Z[Alcholism] --> Y[Ulcers]\n```\n\n\n##### Surrogate for response\n\n-   Adjustment for a surrogate is a bad idea\n\n-   As the name implies, surrogates are a substitute for the response\n    variable\n\n-   Directed Acyclyic Graph where forced vital capacity (FVC) is a\n    surrogate for forced exp\n\n\n```{mermaid}\nflowchart LR\n  X[Second hand smoke] --> Z[FVC]\n  Z[FVC] --> Y[FEV1]\n```\n\n\n##### Many other (complicated) patterns possible\n\n-   Greenland, Pearl, and Robins. Causal Diagrams for Epidemiologic\n    Research. Epidemiology. (1999) <http://www.jstor.org/stable/3702180>\n-   <https://www.dagitty.net/>\n\n### Diagnosing Confounding\n\n-   Confounding typically produces a difference between unadjusted and\n    adjusted analyses\n\n    -   This symptom is not proof of confounding\n\n        -   Such a difference can occur when there is no confounding\n\n        -   Symptom is more indicative of confounding when modeling\n            means (linear regression) than when modeling odds (logistic\n            regression) or hazards (Cox, proportional hazards\n            regression)\n\n-   Estimates of association from unadjusted analysis are markedly\n    different from estimates of association from adjusted analysis\n\n    -   Association within each stratum is similar to each other, but\n        different from the association in the combined data\n\n-   In linear regression, differences between adjusted and unadjusted\n    analyses are diagnostic of confounding\n\n    -   Precision variables tend to change standard errors, but not\n        slope estimates\n\n    -   Effect modification would show differences between adjusted\n        analysis and unadjusted analysis, but would also show different\n        associations in the strata\n\n-   More difficult to diagnosis confounding with non-linear functions of\n    the mean\n\n    -   Common non-linear functions: Odds (odds ratios), hazards (hazard\n        ratios)\n\n    -   May show the symptoms of confounding when confounding is not\n        present\n\n    -   Adjusting for precision variables can appear to be confounding\n\n    -   In logistic and PH regression, difference between adjusted and\n        unadjusted analyses are more difficult to judge\n\n        -   Comparison in more homogeneous groups (i.e. after adjustment\n            for a precision variable) will drive slope estimates away\n            from the null\n\n-   Example: Suppose you have a sample where 50% of the subjects die\n\n    -   What is the variability? $p*(1-p)=0.25$\n\n    -   We can reduce this variability by changing $p$, the probability\n        of death\n\n    -   Estimate $p$ in different stratum. One stratum may have a higher\n        $p$, another a lower $p$.\n\n        -   e.g. Stratum 1, 20% death rate and Stratum 2 an 80% death\n            rate.\n\n    -   By making the estimate more precise, we have also impacted the\n        mean\n\n## Mediating variables\n\n-   A mediating variable is a predictor hypothesized to lie on the\n    causal pathway between a predictor of interest and the outcome\n\n-   Whether or not to adjust for a mediating variable depends on the\n    scientific question of interest\n\n    -   Without adjustment, we are estimating the **total** (causal)\n        effect of the predictor of interest via all pathways on the\n        outcome\n\n    -   If we adjust for a mediator, we are estimating the **direct**\n        (causal) effect via other pathways that do not involve the\n        mediator\n\n-   If a potential mediator is identified *a priori* on scientific\n    grounds, we can estimate the **direct** effect via pathways other\n    than the mediator, the **indirect** effect through the mediator, and\n    the degree of mediation (e.g. **proportion mediated**).\n\n-   Example: Depression (predictor) and Crohn's Disease activitity\n    (outcome) with possible mediators being physical activity, smoking,\n    and sleep quality\n\n    -   Mediation models were considered using baseline, 6-month, and\n        12-month follow-up data\n\n    -   Depression at baseline was the predictor of interest, mediators\n        were assessed at 6 months, and disease activity at 12 months was\n        the outcome.\n\n    -   To establish and estimate the mediation effect, we utilized the\n        four steps originally outlined by Barron and Kenny [^1]\n\n        -   First, we tested that there was a significant effect of\n            depression at baseline with disease activity at 12 months to\n            establish there was an effect to be mediated\n\n        -   Second, we estimated the correlation between depression at\n            baseline and each of the potential mediators measured at 6\n            months\n\n        -   Third, we tested if each of the mediators at 6 months was\n            associated with disease activity at 12 months while\n            controlling for disease activity at baseline.\n\n        -   Fourth, the mediation package in R was used to estimate\n            various quantities for causal mediation analysis, including\n            average causal mediation effects (indirect effect), average\n            direct effects, proportions mediated, and total effect. This\n            step involves combining estimates from the mediator model\n            (mediator at 6 months outcome, depression at baseline the\n            predictor) and estimates from the outcome model (disease\n            activity at 12 months outcome, mediator at 6 months and\n            depression at baseline as predictors of interest, and\n            controlling for disease activity at baseline) efficiently\n            and with appropriate standard error estimates.\n\n    -   Results\n\n[^1]: Baron RM, Kenny DA. The moderator-mediator variable distinction in\n    social psychological research: conceptual, strategic, and\n    statistical considerations. J Pers Soc Psychol. 1986\n    Dec;51(6):1173-82. doi: 10.1037//0022-3514.51.6.1173. PMID: 3806354.\n\n![Multiple mediation model path diagram and estimates from structural\nequations model. Part A shows the total effect of depression at baseline\non disease activity at 12 months is that, per one unit increase in\ndepression, disease activity increases by 2.90. Part B show the\nassociations of depression at baseline, mediators at 6 months, and\ndisease activity at 12 months. Individual mediation effects are found by\nmultiplying a by b for each mediator. Of the 2.90 total effect, 0.005\nwent through sleep, 0.138 went through smoking and 0.107 went through\nactivity. Summing these three value, a total of 0.250 (8.6% mediated)\nwhen through the three\nmediators.](figures/multiplemediation.png){width=\"150%\"}\n\n## Precision Variables\n\n### Overview\n\n-   Sometimes the scientific question to be answered is chosen based on\n    which questions can be answered most precisely\n\n-   In general, questions can be answered more precisely when the within\n    group distribution is less variable\n\n-   Comparing groups that are similar with respect to other important\n    risk factors decreases variability\n\n-   The precision variability is independent of the cause of the\n    response\n\n-   If we adjust for such a variable, we tend to gain precision\n\n-   Directed Acyclyic Graph:\n\n\n```{mermaid}\nflowchart LR\n  X[Predictor] --> Y[Outcome]\n  Z[Precision] --> Y[Outcome]\n```\n\n\n### Adjusting for Precision Variables\n\n#### Precision for Difference of Independent Means\n\n-   Independent observations where group 1 has a different mean and\n    variance than group 2\n\n    -   $\\textrm{ind } Y_{ij} \\sim (\\mu_j, \\sigma_j^2), j = 1, 2; i = 1, \\ldots, n_j$\n\n    -   $n = n_1 + n_2$; $r = n_1 / n_2$\n\n    -   $\\theta = \\mu_1 - \\mu_2$,\n        $\\hat{\\theta} = \\overline{Y}_1 - \\overline{Y}_2$\n\n    -   $V = (r+1)(\\frac{\\sigma_1^2}{r} + \\sigma_2^2)$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}$\n\n-   Might control for some variable in order to decrease the within\n    group variability\n\n    -   Restrict population sampled\n\n    -   Standardize ancillary treatments\n\n    -   Standardize measurement procedure\n\n#### Precision for Linear Regression\n\n-   Independent continuous outcome associated with covariate ($X$)\n\n    -   $\\textrm{ind } Y_i | X_i ~ \\sim(\\beta_0 + \\beta_1 X_i, \\sigma^2_{Y|X}), i = 1, \\ldots, n$\n\n    -   $\\theta = \\beta_1, \\hat{\\theta} = \\hat{\\beta_1}$ from LS\n        regression\n\n    -   $V = \\frac{\\sigma^2_{Y|X}}{\\textrm{Var}(X)}$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\sigma}^2_{Y|X}}{n \\hat{\\textrm{Var}}(X)}}$\n\n-   Adjusting for covariates ($W$) decreases the within group standard\n    deviation\n\n    -   $\\textrm{Var}(Y | X)$ versus $\\textrm{Var}(Y | X, W)$\n\n-   Independent continuous outcome associated with covariate ($X$) and\n    precision variable ($W$)\n\n    -   $\\textrm{ind } Y_i | X_i, W_i ~ \\sim(\\beta_0 + \\beta_1 X_i + \\beta_2 W_i, \\sigma^2_{Y|X,W}), i = 1, \\ldots, n$\n\n    -   $\\theta = \\beta_1, \\hat{\\theta} = \\hat{\\beta_1}$ from LS\n        regression\n\n    -   $V = \\frac{\\sigma^2_{Y|X,W}}{\\textrm{Var}(X)(1-r^2_{X,W})}$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\sigma}^2_{Y|X,W}}{n \\hat{\\textrm{Var}}(X)(1-r^2_{X,W})}}$\n\n    -   $\\sigma^2_{Y|X,W} = \\sigma^2_{Y|X} - \\beta_2^2 \\textrm{Var}(W | X)$\n\n#### Precision for Difference of Proportions\n\n-   When analyzing proportions (means), the mean variance relationship\n    is critical\n\n    -   Precision is greatest when proportion is close to 0 or 1\n\n    -   Greater homogeneity of groups makes results more deterministic\n        (this is the goal, at least)\n\n-   Independent binary outcomes\n\n    -   $\\textrm{ind } Y_{ij} \\sim B(1, p_j), i = 1, \\ldots, n_j; j = 1, 2$\n\n    -   $n = n_1 + n_2; r = n_1 / n_2$\n\n    -   $\\theta = p_1 - p_2$,\n        $\\hat{\\theta} = \\hat{p}_1 - \\hat{p_2} = \\overline{Y}_1 - \\overline{Y}_2$\n\n    -   $\\sigma^2_j = p_j(1-p_j)$\n\n    -   $V = (r+1)(\\frac{\\sigma_1^2}{r} + \\sigma_2^2)$\n\n    -   $se(\\hat{\\theta}) = \\sqrt{\\frac{V}{n}} = \\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}}$\n\n#### Precision for Odds\n\n-   When analyzing odds (a nonlinear function of the mean), adjusting\n    for precision variables results in more extreme estimates\n\n-   $\\textrm{Odds} = \\frac{p}{1-p}$\n\n-   Odds using average of stratum specific $p$ is not the average of\n    stratum specific odds\n\n-   Example: Stroke by smoking (in CVD strata)\n\n    -   No association between smoking and CVD in the sample: 10%\n        smokers in subjects with and without CVD\n\n    -   CVD (precision variable) associated with stroke (outcome)\n\n        -   CVD is not a confounder, but it is clearly a precision\n            variable\n\n    -   Within each CVD stratum, the (adjusted) odds ratio for stroke by\n        smoking is 2.0.\n\n    -   Overall, the unadjusted odds ratio is 1.8. That is, the\n        unadjusted odds ratio is attenuated toward the null compared to\n        the adjusted odds ratios\n\n        | No CVD    | N     | p    | Odds |\n        |-----------|-------|------|------|\n        | Smoke     | 1000  | 0.04 | 0.04 |\n        | Non-Smoke | 10000 | 0.02 | 0.02 |\n        | Ratio     |       |      | 2.0  |\n\n        | CVD       | N    | p    | Odds |\n        |-----------|------|------|------|\n        | Smoke     | 100  | 0.50 | 1.00 |\n        | Non-Smoke | 1000 | 0.33 | 0.50 |\n        | Ratio     |      |      | 2.0  |\n\n        | Overall   | N     | p     | Odds |\n        |-----------|-------|-------|------|\n        | Smoke     | 1100  | 0.082 | 0.09 |\n        | Non-Smoke | 11000 | 0.048 | 0.05 |\n        | Ratio     |       |       | 1.8  |\n\n## Diagnosing Confounding\n\n### Adjustment for Covariates\n\n-   We include predictors in an analysis for a number of reasons. In\n    order of importance...\n\n    1.  Scientific question\n\n        -   Predictor of Interest\n\n        -   Effect Modifiers\n\n    2.  Adjust for confounding\n\n    3.  Gain precision\n\n-   Adjustment for covariates changes the question being answered by the\n    statistical analysis\n\n    -   Adjustments can be made to isolate associations that are of\n        particular interest\n\n    -   When consulting with a scientist, it is often difficult to\n        decide whether the interest in an additional covariate is due to\n        confounding, effect modification, or precision\n\n        -   The distinction is important because I tend to treat these\n            variable differently in the analysis\n\n    -   Often the scientific question dictates inclusion of particular\n        predictors\n\n        -   Predictor of interest: The scientific parameter of interest\n            can be modeled by multiple predictors (e.g. dummy variables,\n            polynomials, splines)\n\n        -   Effect Modifiers: The scientific question relates to the\n            detection of effect modification\n\n        -   Confounders: The scientific question may be state in terms\n            of adjusting for known (or suspected) confounders\n\n### Confounder Detection\n\n-   Unanticipated confounding\n\n    -   Some times we must explore our data to assess whether our\n        results were confounded by some variable\n\n    -   Goal is to assess the \"independent effect\" of the predictor of\n        interest on the outcome\n\n-   Confounders\n\n    -   Variables (causally) predictive of the outcome, but not in the\n        causal pathway\n\n        -   Best method: Think about the scientific problem beforehand\n            (perhaps draw DAG)\n\n        -   Using data, often assessed in the control group\n\n    -   Variables associated with the predictor of interest in the\n        sample\n\n        -   Note that statistical significance is not relevant because\n            this tells us about associations in the population\n\n    -   Detection of confounding ultimately must rely on our best\n        knowledge about the possible scientific mechanisms\n\n-   Effect of confounding: A confounder can make the association between\n    the predictor of interest and the response variable look...\n\n    -   Stronger than the true association\n\n    -   Weaker than the true association\n\n    -   The complete reverse of the true association (\"qualitative\n        confounding\")\n\n## Graphical Methods for Visualizing Effect Modification, Confounding, and Precision\n\n-   Conduct stratified analysis to distinguish between\n\n    -   Effect modifiers\n\n    -   Confounders\n\n    -   Precision variables\n\n-   Plots most illustrative for continuous outcomes\n\n### Effect Modifiers\n\n-   Estimates of treatment effect differ among strata\n\n    -   When analyzing difference of means of continuous data,\n        stratified smooth curves of the data are non-parallel\n\n    -   Graphical techniques difficult in other settings\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1231)\nn <- 200\ngrp <- rep(c(0,1),each=n/2)\nX <- runif(n)\nemplot <- data.frame(grp=grp,\n                     X=X,\n                     Y=.1*grp + 2*X -4*grp*X + rnorm(n)\n)\nemplot$group <- factor(emplot$grp, levels=0:1, labels=c(\"Trt\",\"Ctrl\"))\nggplot(emplot, aes(x=X, y=Y)) + geom_point() + geom_smooth(se=FALSE) + theme_bw()\n```\n\n::: {.cell-output-display}\n![Unadjusted association between outcome and predictor shows a flat slope.](Lec06.ConfoundingEffectModificationMediation_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(emplot, aes(x=X, y=Y, color=group, grp=group)) + geom_point() + geom_smooth(se=FALSE,) + theme_bw()\n```\n\n::: {.cell-output-display}\n![Adjusted association between outcome and predictor shows an increasing slope in one group and a decreasing slope in the other.  This demonstrates effect modification of group.](Lec06.ConfoundingEffectModificationMediation_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n### Confounders\n\n-   Estimates of treatment effect the same across strata, AND\n\n    -   Confounder is causally associated with the response, AND\n\n    -   Confounder associated with the POI in the sample\n\n-   When analyzing difference of means of continuous data\n\n    -   Stratified smooth curve of data are parallel\n\n    -   Distribution of POI differs across strata\n\n    -   Unadjusted and adjusted analyses give different estimates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1231)\nn <- 200\ngrp <- rep(c(0:3), each=n/4)\nX <- c(runif(n/4, 0,.4), runif(n/4, 0.2,.6), runif(n/4, .4,.8), runif(n/4, .6, 1))\nY <- X - grp + rnorm(n)\n\npar(mfrow=c(1,2))\nplot(X,Y, main=\"Unadjusted\")\nlines(lowess(Y~X), lwd=2)\n\nplot(X,Y, pch=(grp+1), main=\"Adjusted Confounding\")\nm1 <- lm(Y~X + grp)\nsegments(x0=0  , x1=.4, y0=coef(m1)[1] + 0*coef(m1)[2],   y1=coef(m1)[1] + 0.4*coef(m1)[2], lwd=2)\nsegments(x0=0.2, x1=.6, y0=coef(m1)[1] + 0.2*coef(m1)[2]+ 1*coef(m1)[3], y1=coef(m1)[1] + 0.6*coef(m1)[2] + 1*coef(m1)[3], lty=2, lwd=2)\nsegments(x0=0.4, x1=.8, y0=coef(m1)[1] + 0.4*coef(m1)[2]+ 2*coef(m1)[3], y1=coef(m1)[1] + 0.8*coef(m1)[2] + 2*coef(m1)[3], lty=3, lwd=2)\nsegments(x0=0.6, x1= 1, y0=coef(m1)[1] + 0.6*coef(m1)[2]+ 3*coef(m1)[3], y1=coef(m1)[1] +   1*coef(m1)[2] + 3*coef(m1)[3], lty=4, lwd=2)\n```\n\n::: {.cell-output-display}\n![](Lec06.ConfoundingEffectModificationMediation_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Precision Variables\n\n-   Estimates of treatment effect the same across strata, AND\n\n    -   Variable is causally associated with the response, AND\n\n    -   Variable is not associated with the POI in the sample\n\n-   When analyzing difference of means of continuous data\n\n    -   Stratified smooth curve of data are parallel\n\n    -   Distribution of POI same across strata\n\n    -   Unadjusted and adjusted analyses give similar estimates but with\n        smaller standard errors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1231)\nn <- 200\ngrp <- rep(c(0:3), each=n/4)\nX <- runif(n)\nY <- 3*X + 5*grp + rnorm(n)\n\npar(mfrow=c(1,2))\nplot(X,Y, main=\"Unadjusted Precision\")\nlines(lowess(Y~X), lwd=2)\nplot(X,Y, main=\"Adjusted Precision\", pch=(grp+1))\nm2 <- lm(Y~X + grp)\nabline(a=coef(m2)[1], b=coef(m2)[2], lwd=2)\nabline(a=coef(m2)[1] + 1*coef(m2)[3], b=(coef(m2)[2]), lty=2, lwd=2)\nabline(a=coef(m2)[1] + 2*coef(m2)[3], b=(coef(m2)[2]), lty=3, lwd=2)\nabline(a=coef(m2)[1] + 3*coef(m2)[3], b=(coef(m2)[2]), lty=4, lwd=2)\n```\n\n::: {.cell-output-display}\n![](Lec06.ConfoundingEffectModificationMediation_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Lec06.ConfoundingEffectModificationMediation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}