<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris Slaughter">
<meta name="dcterms.date" content="2025-12-08">

<title>Simple Linear Regression – BIOS 6312 - Spring 2026</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notes/Lec04.Logistic.html" rel="next">
<link href="../notes/Lec02.review.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c437abfaa50d34d00910df3552cd5d13.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-1965ed886599d4b20805420ccffa35d1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-c437abfaa50d34d00910df3552cd5d13.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Simple Linear Regression – BIOS 6312 - Spring 2026">
<meta property="og:description" content="Lecture 03">
<meta property="og:image" content="https://chrissl789.github.io/modern-regression/notes/Lec03.SimpleLinearRegression_files/figure-html/fig-chol-age-1.png">
<meta property="og:site_name" content="BIOS 6312 - Spring 2026">
<meta property="og:image:height" content="960">
<meta property="og:image:width" content="1344">
</head>

<body class="nav-sidebar docked slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/Lec02.review.html">Course Notes</a></li><li class="breadcrumb-item"><a href="../notes/Lec03.SimpleLinearRegression.html">Simple Linear Regression</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">BIOS 6312 - Spring 2026</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/Lec01.Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introductory Slides</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../officehours.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Office Hours</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec02.review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Review of Key Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec03.SimpleLinearRegression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Simple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec04.Logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec05.Precision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Precision of Statistical Intefence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec06.ConfoundingEffectModificationMediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Confouding, Effect Modification, and Mediation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec07.MultivariableModels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multivariable Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Set2.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Set6.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Weighted Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec08.Survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Survival Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec09.Poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Poisson Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec10.Modeling.Effect.Modification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling Effect Modification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Set8.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multinomial and Ordinal Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec11.DoseResponse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Flexible Modeling of Continuous Predictors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec12.ANOVA.Model.Choice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA and Model Choice</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Lec13.Prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression Based Prediction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/BayesDiagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Model Diagnostics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Set13.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Missing Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/Set14.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Bootstrap</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/quarto-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quarto Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab1-linearregression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 1: Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab2-linearassumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2: Assumption in Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab3-logistic-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 3: Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab4-precision-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 4: Precision and adjustment for baseline</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab-weighted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">(Mini) Lab: Weighted Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab5-multivariable.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 5: Multivariable Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab6-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 6: Survival Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab7-effectmodification-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 7: Poisson Regression and Effect Modification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/Lab-DiscreteOutcomeRegression.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 8: Discrete Outcomes Lab</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://vanderbilt.box.com/s/rpftvmc9vua2w3gz3jy16phlnsojs6on" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Box folder with .qmd files</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Supplemental notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/slr-derivations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SLR derivations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/model-diagnostics-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model diagnostics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/mlr-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MLR matrix notation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/log-transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Log transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/model-selection-criteria.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model selection criteria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/ReviewMatrixAlgebra.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Matrix algebra review</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../supplemental/Baseline_Change_MACH.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Change from baseline and precision</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Statcomp2</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://statcomp2.app.vumc.org/modern-regression/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Main directory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://statcomp2.app.vumc.org/modern-regression/lectures/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://statcomp2.app.vumc.org/modern-regression/lectures/data" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#general-regression-setting" id="toc-general-regression-setting" class="nav-link active" data-scroll-target="#general-regression-setting"><span class="header-section-number">1</span> General Regression Setting</a>
  <ul>
  <li><a href="#two-variable-setting" id="toc-two-variable-setting" class="nav-link" data-scroll-target="#two-variable-setting"><span class="header-section-number">1.1</span> Two variable setting</a></li>
  <li><a href="#regression-versus-two-sample-approaches" id="toc-regression-versus-two-sample-approaches" class="nav-link" data-scroll-target="#regression-versus-two-sample-approaches"><span class="header-section-number">1.2</span> Regression versus two sample approaches</a></li>
  <li><a href="#guiding-principle" id="toc-guiding-principle" class="nav-link" data-scroll-target="#guiding-principle"><span class="header-section-number">1.3</span> Guiding principle</a></li>
  </ul></li>
  <li><a href="#motivating-problem-cholesterol-and-age" id="toc-motivating-problem-cholesterol-and-age" class="nav-link" data-scroll-target="#motivating-problem-cholesterol-and-age"><span class="header-section-number">2</span> Motivating Problem: Cholesterol and Age</a>
  <ul>
  <li><a href="#definitions" id="toc-definitions" class="nav-link" data-scroll-target="#definitions"><span class="header-section-number">2.1</span> Definitions</a></li>
  <li><a href="#simple-regression-model" id="toc-simple-regression-model" class="nav-link" data-scroll-target="#simple-regression-model"><span class="header-section-number">2.2</span> Simple Regression Model</a>
  <ul class="collapse">
  <li><a href="#descriptive-plots-of-cholesterol-and-age" id="toc-descriptive-plots-of-cholesterol-and-age" class="nav-link" data-scroll-target="#descriptive-plots-of-cholesterol-and-age"><span class="header-section-number">2.2.1</span> Descriptive plots of cholesterol and age</a></li>
  <li><a href="#simple-linear-regression-model" id="toc-simple-linear-regression-model" class="nav-link" data-scroll-target="#simple-linear-regression-model"><span class="header-section-number">2.2.2</span> Simple linear regression model</a></li>
  <li><a href="#frequentist-estimates-and-interpretation" id="toc-frequentist-estimates-and-interpretation" class="nav-link" data-scroll-target="#frequentist-estimates-and-interpretation"><span class="header-section-number">2.2.3</span> Frequentist Estimates and Interpretation</a></li>
  <li><a href="#bayesian-estimates-and-interpretation" id="toc-bayesian-estimates-and-interpretation" class="nav-link" data-scroll-target="#bayesian-estimates-and-interpretation"><span class="header-section-number">2.2.4</span> Bayesian Estimates and Interpretation</a></li>
  <li><a href="#comparison-of-frequentist-and-bayesian-interpretation-of-the-slope" id="toc-comparison-of-frequentist-and-bayesian-interpretation-of-the-slope" class="nav-link" data-scroll-target="#comparison-of-frequentist-and-bayesian-interpretation-of-the-slope"><span class="header-section-number">2.2.5</span> Comparison of Frequentist and Bayesian interpretation of the slope</a></li>
  </ul></li>
  <li><a href="#uses-of-regression" id="toc-uses-of-regression" class="nav-link" data-scroll-target="#uses-of-regression"><span class="header-section-number">2.3</span> Uses of Regression</a></li>
  <li><a href="#linear-regression-inference" id="toc-linear-regression-inference" class="nav-link" data-scroll-target="#linear-regression-inference"><span class="header-section-number">2.4</span> Linear Regression Inference</a></li>
  </ul></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression"><span class="header-section-number">3</span> Simple Linear Regression</a>
  <ul>
  <li><a href="#ingredients" id="toc-ingredients" class="nav-link" data-scroll-target="#ingredients"><span class="header-section-number">3.1</span> Ingredients</a></li>
  <li><a href="#matrix-notation" id="toc-matrix-notation" class="nav-link" data-scroll-target="#matrix-notation"><span class="header-section-number">3.2</span> Matrix Notation</a></li>
  </ul></li>
  <li><a href="#example-analysis-of-bmi-part-1" id="toc-example-analysis-of-bmi-part-1" class="nav-link" data-scroll-target="#example-analysis-of-bmi-part-1"><span class="header-section-number">4</span> Example Analysis of BMI (Part 1)</a></li>
  <li><a href="#residuals" id="toc-residuals" class="nav-link" data-scroll-target="#residuals"><span class="header-section-number">5</span> Residuals</a></li>
  <li><a href="#assumptions-and-inference-with-linear-regression" id="toc-assumptions-and-inference-with-linear-regression" class="nav-link" data-scroll-target="#assumptions-and-inference-with-linear-regression"><span class="header-section-number">6</span> Assumptions and Inference with Linear Regression</a>
  <ul>
  <li><a href="#the-big-three-assumptions" id="toc-the-big-three-assumptions" class="nav-link" data-scroll-target="#the-big-three-assumptions"><span class="header-section-number">6.1</span> The Big Three Assumptions</a></li>
  <li><a href="#additional-assumptions-for-additional-inference" id="toc-additional-assumptions-for-additional-inference" class="nav-link" data-scroll-target="#additional-assumptions-for-additional-inference"><span class="header-section-number">6.2</span> Additional Assumptions for Additional Inference</a>
  <ul class="collapse">
  <li><a href="#scenario-1-all-model-assumptions-hold" id="toc-scenario-1-all-model-assumptions-hold" class="nav-link" data-scroll-target="#scenario-1-all-model-assumptions-hold"><span class="header-section-number">6.2.1</span> Scenario 1: All model assumptions hold</a></li>
  <li><a href="#scenario-2-error-distribution-is-not-normally-distributed" id="toc-scenario-2-error-distribution-is-not-normally-distributed" class="nav-link" data-scroll-target="#scenario-2-error-distribution-is-not-normally-distributed"><span class="header-section-number">6.2.2</span> Scenario 2: Error distribution is not Normally distributed</a></li>
  <li><a href="#scenario-3-variance-increasing-with-predictor-and-expected-value-of-y-heteroskedasticity" id="toc-scenario-3-variance-increasing-with-predictor-and-expected-value-of-y-heteroskedasticity" class="nav-link" data-scroll-target="#scenario-3-variance-increasing-with-predictor-and-expected-value-of-y-heteroskedasticity"><span class="header-section-number">6.2.3</span> Scenario 3: Variance increasing with predictor and expected value of Y (heteroskedasticity)</a></li>
  <li><a href="#scenario-4-mean-model-incorrectly-specified" id="toc-scenario-4-mean-model-incorrectly-specified" class="nav-link" data-scroll-target="#scenario-4-mean-model-incorrectly-specified"><span class="header-section-number">6.2.4</span> Scenario 4: Mean model incorrectly specified</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">6.2.5</span> Summary</a></li>
  </ul></li>
  <li><a href="#interpreting-positive-results" id="toc-interpreting-positive-results" class="nav-link" data-scroll-target="#interpreting-positive-results"><span class="header-section-number">6.3</span> Interpreting “Positive” Results</a></li>
  <li><a href="#interpreting-negative-results" id="toc-interpreting-negative-results" class="nav-link" data-scroll-target="#interpreting-negative-results"><span class="header-section-number">6.4</span> Interpreting “Negative” Results</a></li>
  </ul></li>
  <li><a href="#model-checking" id="toc-model-checking" class="nav-link" data-scroll-target="#model-checking"><span class="header-section-number">7</span> Model Checking</a>
  <ul>
  <li><a href="#residuals-versus-fitted-values" id="toc-residuals-versus-fitted-values" class="nav-link" data-scroll-target="#residuals-versus-fitted-values"><span class="header-section-number">7.1</span> Residuals versus fitted values</a></li>
  <li><a href="#scale-location-plot" id="toc-scale-location-plot" class="nav-link" data-scroll-target="#scale-location-plot"><span class="header-section-number">7.2</span> Scale-location plot</a></li>
  <li><a href="#qq-plot" id="toc-qq-plot" class="nav-link" data-scroll-target="#qq-plot"><span class="header-section-number">7.3</span> QQ plot</a></li>
  <li><a href="#residuals-versus-leverage" id="toc-residuals-versus-leverage" class="nav-link" data-scroll-target="#residuals-versus-leverage"><span class="header-section-number">7.4</span> Residuals versus leverage</a></li>
  </ul></li>
  <li><a href="#linear-regression-with-robust-standard-error-estimates" id="toc-linear-regression-with-robust-standard-error-estimates" class="nav-link" data-scroll-target="#linear-regression-with-robust-standard-error-estimates"><span class="header-section-number">8</span> Linear Regression with Robust Standard Error estimates</a>
  <ul>
  <li><a href="#comparison-when-normality-constant-variance-holds" id="toc-comparison-when-normality-constant-variance-holds" class="nav-link" data-scroll-target="#comparison-when-normality-constant-variance-holds"><span class="header-section-number">8.1</span> Comparison when Normality, constant variance holds</a>
  <ul class="collapse">
  <li><a href="#age-and-cholesterol" id="toc-age-and-cholesterol" class="nav-link" data-scroll-target="#age-and-cholesterol"><span class="header-section-number">8.1.1</span> Age and Cholesterol</a></li>
  <li><a href="#scenario-1-dataset" id="toc-scenario-1-dataset" class="nav-link" data-scroll-target="#scenario-1-dataset"><span class="header-section-number">8.1.2</span> Scenario 1 dataset</a></li>
  </ul></li>
  <li><a href="#comparison-when-variance-is-increasing-with-predictor-scenario-3" id="toc-comparison-when-variance-is-increasing-with-predictor-scenario-3" class="nav-link" data-scroll-target="#comparison-when-variance-is-increasing-with-predictor-scenario-3"><span class="header-section-number">8.2</span> Comparison when variance is increasing with predictor (Scenario 3)</a></li>
  <li><a href="#comparison-when-error-variance-is-skewed-to-the-right-scenario-2" id="toc-comparison-when-error-variance-is-skewed-to-the-right-scenario-2" class="nav-link" data-scroll-target="#comparison-when-error-variance-is-skewed-to-the-right-scenario-2"><span class="header-section-number">8.3</span> Comparison when error variance is skewed to the right (Scenario 2)</a></li>
  <li><a href="#comments" id="toc-comments" class="nav-link" data-scroll-target="#comments"><span class="header-section-number">8.4</span> Comments</a></li>
  </ul></li>
  <li><a href="#linear-regression-and-correlation" id="toc-linear-regression-and-correlation" class="nav-link" data-scroll-target="#linear-regression-and-correlation"><span class="header-section-number">9</span> Linear Regression and Correlation</a>
  <ul>
  <li><a href="#pearsons-correlation" id="toc-pearsons-correlation" class="nav-link" data-scroll-target="#pearsons-correlation"><span class="header-section-number">9.1</span> Pearson’s Correlation</a></li>
  <li><a href="#relationship-to-regression" id="toc-relationship-to-regression" class="nav-link" data-scroll-target="#relationship-to-regression"><span class="header-section-number">9.2</span> Relationship to regression</a></li>
  </ul></li>
  <li><a href="#regression-on-geometric-means-log-transformations" id="toc-regression-on-geometric-means-log-transformations" class="nav-link" data-scroll-target="#regression-on-geometric-means-log-transformations"><span class="header-section-number">10</span> Regression on Geometric Means: Log transformations</a>
  <ul>
  <li><a href="#interpretation-of-parameters" id="toc-interpretation-of-parameters" class="nav-link" data-scroll-target="#interpretation-of-parameters"><span class="header-section-number">10.1</span> Interpretation of Parameters</a></li>
  <li><a href="#example-fev-with-height" id="toc-example-fev-with-height" class="nav-link" data-scroll-target="#example-fev-with-height"><span class="header-section-number">10.2</span> Example: FEV with Height</a></li>
  <li><a href="#log-transformed-predictors" id="toc-log-transformed-predictors" class="nav-link" data-scroll-target="#log-transformed-predictors"><span class="header-section-number">10.3</span> Log Transformed Predictors</a></li>
  <li><a href="#looking-ahead-to-multivariable-models" id="toc-looking-ahead-to-multivariable-models" class="nav-link" data-scroll-target="#looking-ahead-to-multivariable-models"><span class="header-section-number">10.4</span> Looking Ahead to Multivariable Models</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/chrissl789/modern-regression/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/Lec02.review.html">Course Notes</a></li><li class="breadcrumb-item"><a href="../notes/Lec03.SimpleLinearRegression.html">Simple Linear Regression</a></li></ol></nav><h1 class="title display-7">Simple Linear Regression</h1></header>


<header id="title-block-header">

<div class="right">
<!--
<a href="https://github.com/chrissl789/modern-regression/raw/main/Lec03.SimpleLinearRegression.qmd" target="_blank">View Code</a>
-->
<a href="https://statcomp2.app.vumc.org/modern-regression/lectures/Lec03.SimpleLinearRegression.qmd" target="_blank">Download Code</a>

</div>

<div class="quarto-title-block d-none d-lg-block"><div><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Lecture 03</p>
<p class="author">Chris Slaughter</p>

<p class="date">December 8, 2025</p>

</header>


<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstanarm)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(finalfit)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rms)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gglm)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">tryCatch</span>(<span class="fu">source</span>(<span class="st">'pander_registry.R'</span>), <span class="at">error =</span> <span class="cf">function</span>(e) <span class="fu">invisible</span>(e))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="general-regression-setting" class="level2 page-columns page-full" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="general-regression-setting"><span class="header-section-number">1</span> General Regression Setting</h2>
<section id="two-variable-setting" class="level3 page-columns page-full" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="two-variable-setting"><span class="header-section-number">1.1</span> Two variable setting</h3>
<ul>
<li><p>Many statistical problems examine the association between two variables</p>
<ul>
<li><p>Outcome variable (response variable, <del>dependent variable</del>)</p></li>
<li><p>Grouping variable (covariate, predictor variable, <del>independent variable</del>)</p></li>
<li><p>(While “dependent variable” and “independent variable” are commonly used, these imply that a modifiable independent variable is <em>causing</em> a dependent variable to change. We are fitting models focused on association, not causation.)</p></li>
</ul></li>
<li><p>General goal is to compare distribution of the outcome variable across levels of the grouping variable</p></li>
<li><p>Groups are defined by the grouping variable</p>
<ul>
<li>Within each group, the grouping variable is constant</li>
<li>Treatment and control groups</li>
<li>Age: Continuous (days), broadly categorized (years), or wide categories (e.g.&nbsp;0-18, 18-65, 65+)</li>
</ul></li>
<li><p>In intro course, statistical analysis is characterized by two factors</p>
<ul>
<li><p>Number of groups (samples)</p></li>
<li><p>If subjects in groups are independent</p></li>
</ul></li>
<li><p>In the two variable setting, statistical analysis is more generally characterized by the grouping variable. If the grouping variable is</p>
<ul>
<li><p>Constant: One sample problem</p></li>
<li><p>Binary: Two sample problem</p></li>
<li><p>Categorical: <span class="math inline">\(k\)</span> sample problem (e.g.&nbsp;ANOVA)</p></li>
<li><p>Continuous: Infinite sample problem (analyzed with regression)</p></li>
</ul></li>
<li><p>Regression thus <em>extends</em> the one- and two-sample problems up to infinite sample problems</p>
<ul>
<li><p>Of course, in reality we never have <em>infinite</em> samples, but models that can handle this case are the ultimate generalization</p></li>
<li><p>Continuous predictors of interest</p></li>
<li><p>Continuous adjustment variables</p></li>
</ul></li>
</ul>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  <span class="do">### Make a cholesterol and age dataframe.  Set the random number seed so everything is reproducible</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">19</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">age=</span><span class="fu">c</span>(<span class="dv">63</span>, <span class="dv">63</span>, <span class="fu">rep</span>(<span class="dv">65</span><span class="sc">:</span><span class="dv">80</span>,<span class="dv">15</span>), <span class="fu">rep</span>(<span class="dv">81</span><span class="sc">:</span><span class="dv">85</span>,<span class="dv">10</span>), <span class="dv">86</span>,<span class="dv">86</span>,<span class="dv">86</span>, <span class="dv">87</span>,<span class="dv">89</span>, <span class="dv">90</span>, <span class="dv">93</span>, <span class="dv">95</span>, <span class="dv">100</span>),</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">chol=</span><span class="cn">NA</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plotdata<span class="sc">$</span>chol <span class="ot">&lt;-</span> <span class="dv">190</span> <span class="sc">+</span> .<span class="dv">5</span><span class="sc">*</span>plotdata<span class="sc">$</span>age <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(plotdata<span class="sc">$</span>age), <span class="dv">0</span>, <span class="dv">15</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-chol-age" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-chol-age-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-chol-age-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-chol-age-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Scatterplot of cholesterol and age. Age is a continuous grouping variable.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="regression-versus-two-sample-approaches" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="regression-versus-two-sample-approaches"><span class="header-section-number">1.2</span> Regression versus two sample approaches</h3>
<ul>
<li><p>With a binary grouping variable, regression models reduce to the corresponding two variable methods</p></li>
<li><p>Linear regression with a binary predictor</p>
<ul>
<li>t-test, equal variance: Classic linear regression</li>
<li>t-test, unequal variance: Linear regression with robust standard errors (approximately)</li>
</ul></li>
<li><p>Logistic regression with a binary predictor</p>
<ul>
<li>(Pearson) Chi-squared test: Score test from logistic regression</li>
</ul></li>
<li><p>Proportional odds regression with a binary predictor</p>
<ul>
<li>Wilcoxon Rank Sum Test</li>
</ul></li>
<li><p>Cox (proportional hazards) regression with a binary predictor</p>
<ul>
<li>Log-rank test: Score test from Cox regression</li>
</ul></li>
</ul>
</section>
<section id="guiding-principle" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="guiding-principle"><span class="header-section-number">1.3</span> Guiding principle</h3>
<ul>
<li>Everything can be recast as a regression problem.</li>
</ul>
</section>
</section>
<section id="motivating-problem-cholesterol-and-age" class="level2 page-columns page-full" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="motivating-problem-cholesterol-and-age"><span class="header-section-number">2</span> Motivating Problem: Cholesterol and Age</h2>
<section id="definitions" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="definitions"><span class="header-section-number">2.1</span> Definitions</h3>
<ul>
<li><p>Is there an association between cholesterol and age?</p></li>
<li><p>Scientific question: Does aging effect cholesterol?</p></li>
<li><p>Statistical question: Does the distribution of cholesterol differ across age groups?</p>
<ul>
<li><p>Acknowledges variability in the response (cholesterol)</p></li>
<li><p>Acknowledges cause-effect relationship is uncertain</p></li>
<li><p>Association does not imply causation</p>
<ul>
<li>Any observed differences could be due to other factors. For example, the association could be with year of birth rather than age.</li>
</ul></li>
</ul></li>
<li><p>Continuous response variable: Cholesterol</p></li>
<li><p>Continuous grouping variable (predictor of interest): Age</p>
<ul>
<li>An infinite number of ages are possible</li>
<li>We will not sample every possible age, and may round for simplicity</li>
</ul></li>
</ul>
</section>
<section id="simple-regression-model" class="level3 page-columns page-full" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="simple-regression-model"><span class="header-section-number">2.2</span> Simple Regression Model</h3>
<ul>
<li><p>Attempt to answer scientific question by assessing linear trends in average cholesterol</p></li>
<li><p>Estimate the best fitting line to average cholesterol within age groups</p></li>
</ul>
<p><span class="math display">\[
E[\textrm{Chol} | \textrm{Age}] = \beta_0 + \beta_1 \times \textrm{Age}
\]</span></p>
<ul>
<li><p>The expected value of cholesterol given age is modeled using an intercept (<span class="math inline">\(\beta_0\)</span>) and slope (<span class="math inline">\(\beta_1\)</span>)</p>
<ul>
<li><p>An association exists if the slope is nonzero</p></li>
<li><p>A non-zero slope indicates that the average cholesterol will be different across different age groups</p></li>
</ul></li>
</ul>
<section id="descriptive-plots-of-cholesterol-and-age" class="level4 page-columns page-full" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="descriptive-plots-of-cholesterol-and-age"><span class="header-section-number">2.2.1</span> Descriptive plots of cholesterol and age</h4>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-chol-age-lowess" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-chol-age-lowess-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-chol-age-lowess-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-chol-age-lowess-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Scatterplot of cholesterol and age. Association is described using a lowess smooth line.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-chol-age-linear" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-chol-age-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-chol-age-linear-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-chol-age-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Scatterplot of cholesterol and age. Association is described using a linear trend line.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="simple-linear-regression-model" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="simple-linear-regression-model"><span class="header-section-number">2.2.2</span> Simple linear regression model</h4>
<ul>
<li><p>The simple regression model produces an easy to remember (but approximate) rule of thumb.</p>
<ul>
<li><p>“Normal cholesterol is 190 plus half your age”</p></li>
<li><p><span class="math inline">\(E[\textrm{Chol} | \textrm{Age}] = 190 + 0.50 \times \textrm{Age}\)</span></p></li>
<li><p>Note that data were generated using this model. Estimates, below, will be different.</p></li>
</ul></li>
</ul>
</section>
<section id="frequentist-estimates-and-interpretation" class="level4" data-number="2.2.3">
<h4 data-number="2.2.3" class="anchored" data-anchor-id="frequentist-estimates-and-interpretation"><span class="header-section-number">2.2.3</span> Frequentist Estimates and Interpretation</h4>
<ul>
<li>Raw, unformatted estimates, model summary, and confidence intervals for age</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>m.chol <span class="ot">&lt;-</span> <span class="fu">lm</span>(chol <span class="sc">~</span> age, <span class="at">data=</span>plotdata)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m.chol)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = chol ~ age, data = plotdata)

Residuals:
    Min      1Q  Median      3Q     Max 
-39.591 -10.524  -0.234  11.154  41.819 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 203.2259    10.3138  19.704   &lt;2e-16 ***
age           0.3209     0.1375   2.333   0.0203 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 15.34 on 299 degrees of freedom
Multiple R-squared:  0.01788,   Adjusted R-squared:  0.0146 
F-statistic: 5.444 on 1 and 299 DF,  p-value: 0.0203</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.default</span>(m.chol, <span class="st">"age"</span>) <span class="co"># Based on asymptotic Normality</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %    97.5 %
age 0.051334 0.5904842</code></pre>
</div>
</div>
<p><span class="math inline">\(E[\textrm{Chol} | \textrm{Age}] = 203.2 + 0.32 \times \textrm{Age}\)</span></p>
<ul>
<li>Using finalfit to create a nicer output table of the slope coefficient for age and confidence intervals</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>explanatory <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"age"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>dependent <span class="ot">=</span> <span class="st">'chol'</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">label</span>(plotdata<span class="sc">$</span>chol) <span class="ot">&lt;-</span> <span class="st">"Cholesterol"</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">label</span>(plotdata<span class="sc">$</span>age) <span class="ot">&lt;-</span> <span class="st">"Age (years)"</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">finalfit</span>(plotdata, dependent, explanatory)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> Dependent: Cholesterol                   unit        value
            Age (years) [63.0,100.0] Mean (sd) 227.2 (15.5)
    Coefficient (univariable)  Coefficient (multivariable)
 0.32 (0.05 to 0.59, p=0.020) 0.32 (0.05 to 0.59, p=0.020)</code></pre>
</div>
</div>
</section>
<section id="bayesian-estimates-and-interpretation" class="level4" data-number="2.2.4">
<h4 data-number="2.2.4" class="anchored" data-anchor-id="bayesian-estimates-and-interpretation"><span class="header-section-number">2.2.4</span> Bayesian Estimates and Interpretation</h4>
<ul>
<li><p>Bayesian approach to the linear model requires specifying</p>
<ul>
<li><p>The model, e.g.&nbsp;a linear model with intercept and slope for age, Normally distributed errors and constant variance</p></li>
<li><p>Prior distributions on parameters</p>
<ul>
<li><p>For the simple linear regression model, we have parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\sigma\)</span>.</p></li>
<li><p>For now, we will use default prior distributions that are are intended to be <em>weakly informative</em> in that they provide moderate regularization and help stabilize computation. See the <a href="https://mc-stan.org/rstanarm/reference/priors.html">STAN documentation</a> for more details</p></li>
<li><p>Appropriate priors can be based on scientific considerations</p></li>
<li><p>Sensitivity analyses can evaluate the the robustness of finding to different prior assumptions</p></li>
</ul></li>
</ul></li>
<li><p>Output from Bayesian linear regression</p></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(chol <span class="sc">~</span> age,</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>plotdata, <span class="at">family=</span><span class="fu">gaussian</span>(),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">seed=</span><span class="dv">1234</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">refresh=</span><span class="dv">0</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1, <span class="at">digits=</span><span class="dv">2</span>, <span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Model Info:
 function:     stan_glm
 family:       gaussian [identity]
 formula:      chol ~ age
 algorithm:    sampling
 sample:       4000 (posterior sample size)
 priors:       see help('prior_summary')
 observations: 301
 predictors:   2

Estimates:
              mean   sd     2.5%   50%    97.5%
(Intercept) 203.28  10.69 182.56 203.18 224.80 
age           0.32   0.14   0.04   0.32   0.60 
sigma        15.39   0.63  14.25  15.37  16.74 

Fit Diagnostics:
           mean   sd     2.5%   50%    97.5%
mean_PPD 227.19   1.24 224.79 227.19 229.63 

The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).

MCMC diagnostics
              mcse Rhat n_eff
(Intercept)   0.18 1.00 3721 
age           0.00 1.00 3735 
sigma         0.01 1.00 3469 
mean_PPD      0.02 1.00 3911 
log-posterior 0.03 1.00 1638 

For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>
</div>
</div>
<ul>
<li>And a summary of the prior distributions used</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prior_summary</span>(fit1, <span class="at">digits =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Priors for model 'fit1' 
------
Intercept (after predictors centered)
  Specified prior:
    ~ normal(location = 227, scale = 2.5)
  Adjusted prior:
    ~ normal(location = 227, scale = 39)

Coefficients
  Specified prior:
    ~ normal(location = 0, scale = 2.5)
  Adjusted prior:
    ~ normal(location = 0, scale = 6)

Auxiliary (sigma)
  Specified prior:
    ~ exponential(rate = 1)
  Adjusted prior:
    ~ exponential(rate = 0.065)
------
See help('prior_summary.stanreg') for more details</code></pre>
</div>
</div>
<ul>
<li><p>Interpretation</p>
<ul>
<li><p>Slope for age is of primary scientific importance</p></li>
<li><p><em>A priori</em> we assume that no association between age and cholesterol. Specifically, we assumed a Normal prior with location (mean) of 0 and scale (standard devation) of 6 for <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>Conditional on the data, we estimate that for every 1 year increase in age, cholesterol increases by 0.32 mg/dl (95% credible interval 0.04 to 0.60).</p></li>
</ul></li>
</ul>
</section>
<section id="comparison-of-frequentist-and-bayesian-interpretation-of-the-slope" class="level4 page-columns page-full" data-number="2.2.5">
<h4 data-number="2.2.5" class="anchored" data-anchor-id="comparison-of-frequentist-and-bayesian-interpretation-of-the-slope"><span class="header-section-number">2.2.5</span> Comparison of Frequentist and Bayesian interpretation of the slope</h4>
<ul>
<li>Following was given by gpt-4.0 <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Query “Explain how a slope from simple linear regression is interpreted using language a college graduate could understand. Provide a Bayesian and Frequentist interpretation.” VUMC aiChat tool, GPT-4. Retrieved 12/28/2023.</p></div></div><div class="classname" style="color: gray">
<p>In simple linear regression, the slope (often denoted as “b” or “beta”) is interpreted as the expected change in the dependent (or response) variable for a one-unit increase in the independent (or predictor) variable, assuming all other variables are held constant.</p>
<p>From a Frequentist perspective, the slope is considered a fixed but unknown value which is estimated from the sample data. If the slope is found to be 2, for instance, it would suggest that for every one-unit increase in our predictor variable, we expect, on average, a 2-unit increase in the response variable. This is based on the data at hand and is subject to sampling variability. Confidence intervals can be constructed around this estimate to provide a range of plausible values for this unknown fixed parameter. If a 95% confidence interval for the slope is (1.5, 2.5), it would suggest that we are 95% confident that the true slope falls within this range.</p>
<p>In contrast, a Bayesian approach treats the slope as a random variable. Rather than a single fixed value, the slope has a distribution of possible values. This distribution combines our prior beliefs about what the slope might be (prior distribution) and the observed data (likelihood). The resulting distribution (posterior distribution) reflects our updated belief about the slope after seeing the data. If the mean of the posterior distribution is 2, it suggests that, given the prior and the data, our best guess is that a one-unit increase in the predictor variable corresponds to a 2-unit increase in the response variable on average. A credible interval, say a 95% credible interval of (1.5, 2.5), suggests that there is a 95% probability that the true value of the slope falls within this range, given our prior and the observed data.</p>
</div>
<ul>
<li><p>When to use Bayesian or frequentist approaches to estimation<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<ul>
<li><p>On many occasions, if one is careful in execution, both approaches to analysis will yield essentially equivalent inference</p></li>
<li><p>For small sample sizes, Bayesian approaches with carefully considered priors are often the only way to go because it is difficult to obtain well-calibrated frequentist intervals</p></li>
<li><p>For medium to large samples, unless there is strong prior information that one wants to incorporate, robust frequentist estimation using sandwich estimation is very appealing because its consistency is guaranteed under mild conditions</p></li>
<li><p>For highly complex models, a Bayesian approach is often the most convenient way to formulate the model, and computation under the Bayesian approach is the most straightforward</p></li>
<li><p>In summary, in many instances carefully considered Bayesian and frequentist approach will lead to similar scientific conclusions. My goal is describe the advantages and shortcoming of each approach, but a strong recommendation of one over the other is not given as there is often no reason for stating a preference.</p></li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Wakefield, Jon. Bayesian and Frequentist Regression Methods. Section 1.6, Executive Summary</p></div></div></section>
</section>
<section id="uses-of-regression" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="uses-of-regression"><span class="header-section-number">2.3</span> Uses of Regression</h3>
<ul>
<li><p>Borrowing information</p>
<ul>
<li><p>Use other groups to make estimates in groups with sparse data</p></li>
<li><p>Intuitively, 67 and 69 year olds would provide some relevant information about 68 year olds</p></li>
<li><p>Assuming a straight line relationship tells us about other, even more distant, individuals</p></li>
<li><p>If we do not want to assume a straight line, we may only want to borrow information from nearby groups</p></li>
<li><p>Locally weighted scatterplot smooth line (lowess) added to the previous figures</p></li>
<li><p>Splines discussed in future lectures</p></li>
<li><p>May not want to borrow too much information</p></li>
</ul></li>
<li><p>Linear relationship is an assumption, with often low power to detect departures from linearity</p></li>
<li><p>Always avoid extrapolating beyond the range of the data (e.g.&nbsp;ages under 65 or over 100)</p></li>
<li><p>Defining “Contrasts”</p>
<ul>
<li><p>Define a comparison across groups to use when answering scientific questions</p></li>
<li><p>If the straight line relationship holds, the slope is the difference in mean cholesterol levels between groups differing by 1 year in age</p></li>
<li><p>Do we want to assume that comparisons of 65 to 66 year old subjects are the same as comparisons of 95 to 96 year old subjects?</p></li>
<li><p>If a non-linear relationship, the slope is still the average difference in mean cholesterol levels between groups differing by 1 year in age</p></li>
<li><p>Slope is a (first order or linear) test for trend</p></li>
</ul></li>
</ul>
</section>
<section id="linear-regression-inference" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="linear-regression-inference"><span class="header-section-number">2.4</span> Linear Regression Inference</h3>
<ul>
<li><p>Regression output provides</p>
<ul>
<li><p>Estimates</p>
<ul>
<li><p>Intercept: Estimated mean cholesterol when age is 0</p></li>
<li><p>Slope: Estimated average difference in average cholesterol for two groups differing by 1 year in age</p></li>
<li><p>Standard errors</p></li>
</ul></li>
<li><p>Confidence intervals</p></li>
<li><p>P-values for testing</p>
<ul>
<li><p>Intercept is zero (usually unimportant)</p></li>
<li><p>Slope is zero (test for linear trend in means)</p></li>
</ul></li>
</ul></li>
<li><p>(Frequentist) Interpretation</p></li>
</ul>
<p>From linear regression analysis, we estimate that for each year difference in age, the difference in mean cholesterol is 0.32 mg/dL. A 95% confidence interval (CI) suggests that this observation is not unusual if the true difference in mean cholesterol per year difference in age were between 0.05 and 0.59 mg/dL. Because <span class="math inline">\(p = 0.02\)</span>, we reject the null hypothesis that there is no linear trend in the average cholesterol across age groups using a significance level, <span class="math inline">\(\alpha\)</span>, of <span class="math inline">\(0.05\)</span>.</p>
</section>
</section>
<section id="simple-linear-regression" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="simple-linear-regression"><span class="header-section-number">3</span> Simple Linear Regression</h2>
<section id="ingredients" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="ingredients"><span class="header-section-number">3.1</span> Ingredients</h3>
<ul>
<li><p>Response</p>
<ul>
<li><p>The distribution of this variable will be compared across groups</p></li>
<li><p>Linear regression models the mean of the response variable</p></li>
<li><p>Log transformation of the response corresponds to modeling the geometric mean</p></li>
<li><p>Notation: It is extremely common to use <span class="math inline">\(Y\)</span> to denote the response variable when discussing general methods</p></li>
</ul></li>
<li><p>Predictor</p>
<ul>
<li><p>Group membership is measured by this variable</p></li>
<li><p>Notation</p>
<ul>
<li><p>When not using mnemonics, will be referred to as the <span class="math inline">\(X\)</span> variable in simple linear regression (linear regression with one predictor)</p></li>
<li><p>Later, when we discuss multiple regression, will refer to <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span> when there are up to <span class="math inline">\(p\)</span> predictors</p></li>
</ul></li>
</ul></li>
<li><p>Regression Model</p>
<ul>
<li><p>We typically consider a “linear predictor function” that is linear in the modeled predictors</p></li>
<li><p>Expected value (i.e.&nbsp;mean) of <span class="math inline">\(Y\)</span> for a particular value of <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(E[Y | X] = \beta_0 + \beta_1 \times X\)</span></p></li>
<li><p>In a deterministic world, a line is of the form <span class="math inline">\(y = mx + b\)</span></p>
<ul>
<li><p>With no variation in the data, each value of <span class="math inline">\(y\)</span> would like exactly on a straight line</p></li>
<li><p>Intercept <span class="math inline">\(b\)</span> is values of <span class="math inline">\(y\)</span> when <span class="math inline">\(x = 0\)</span></p></li>
<li><p>Slope <span class="math inline">\(m\)</span> is the difference in <span class="math inline">\(y\)</span> for a one unit difference in <span class="math inline">\(x\)</span></p></li>
</ul></li>
<li><p>Statistics in not completely deterministic. The real world has variability</p>
<ul>
<li><p>Response within groups is variable (people born on the same day will have different cholesterol levels!)</p>
<ul>
<li><p>Randomness due to other variables impacting cholesterol</p></li>
<li><p>Inherent randomness</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>The regression line thus describes the central tendency of the data in a scatterplot of the response versus the predictor</p></li>
<li><p>Interpretation of regression parameters</p>
<ul>
<li><p>Intercept <span class="math inline">\(\beta_0\)</span>: Mean <span class="math inline">\(Y\)</span> for a group with <span class="math inline">\(X=0\)</span></p>
<ul>
<li><p>Often <span class="math inline">\(\beta_0\)</span> is not of scientific interest</p></li>
<li><p>May be out of the range of data, or even impossible to observe <span class="math inline">\(X=0\)</span></p></li>
</ul></li>
<li><p>Slope <span class="math inline">\(\beta_1\)</span>: Difference in mean <span class="math inline">\(Y\)</span> across groups differing in <span class="math inline">\(X\)</span> by 1 unit</p>
<ul>
<li><p>Usually measures association between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(E[Y | X] = \beta_0 + \beta_1 \times X\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Derivation of interpretation</p>
<ul>
<li><p>Simple linear regression of response <span class="math inline">\(Y\)</span> on predictor <span class="math inline">\(X\)</span></p></li>
<li><p>Mean of any arbitrary group can be derived from the equation <span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i
\]</span></p></li>
<li><p>Interpretation determined by considering possible values of <span class="math inline">\(X\)</span></p></li>
<li><p>Model: <span class="math inline">\(E[Y_i | X_i] = \beta_0 + \beta_1 \times X_i\)</span></p>
<ul>
<li><p>When <span class="math inline">\(X_i = 0\)</span>, <span class="math inline">\(E[Y_i | X_i = 0 ] = \beta_0\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x\)</span>, <span class="math inline">\(E[Y_i | X_i = x ] = \beta_0 + \beta_1 x\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x + 1\)</span>, <span class="math inline">\(E[Y_i | X_i = x + 1 ] = \beta_0 + \beta_1 x + \beta_1\)</span></p></li>
<li><p>We can use the above to get an equation for <span class="math inline">\(\beta_1\)</span></p></li>
</ul>
<p><span class="math display">\[
E[Y_i | X_i = x + 1 ] - E[Y_i | X_i = x ] = \\
(\beta_0 + \beta_1 x + \beta_1) - (\beta_0 + \beta_1 x) \\
= \beta_1
\]</span></p>
<ul>
<li>Thus, <span class="math inline">\(\beta_1\)</span> is the expected change in <span class="math inline">\(Y\)</span> per one unit increase in <span class="math inline">\(x\)</span></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="matrix-notation" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="matrix-notation"><span class="header-section-number">3.2</span> Matrix Notation</h3>
<ul>
<li><p>Using scalars, the simple linear regression model can be written as</p>
<ul>
<li><p><span class="math inline">\(Y_i = \beta_0 + \beta_1 \times X_i + \epsilon_i\)</span></p></li>
<li><p><span class="math inline">\(i = 1, \ldots, n\)</span></p></li>
<li><p><span class="math inline">\(i\)</span> indexes the independent sampling units (e.g.&nbsp;subjects)</p></li>
<li><p><span class="math inline">\(n\)</span> is the total number of independent sampling units</p></li>
<li><p>This formulauation drops the expected value notation, add in <span class="math inline">\(\epsilon_i\)</span></p>
<ul>
<li><p><span class="math inline">\(\epsilon_i\)</span> are the “Residuals” or “Errors”</p></li>
<li><p><span class="math inline">\(E[\epsilon_i] = 0\)</span></p></li>
<li><p><span class="math inline">\(V[\epsilon_i] = \sigma^2\)</span> (constant variance assumption)</p></li>
</ul></li>
</ul></li>
</ul>
<ul>
<li>Matrix notation: <span class="math inline">\({\boldsymbol{Y}}= {\boldsymbol{X}}{\boldsymbol{\beta}}+ {\boldsymbol{\epsilon}}\)</span></li>
</ul>
<p><span class="math inline">\({\boldsymbol{Y}}= \left( \begin{array}{c} Y_1 \\ Y_2 \\ \vdots \\ Y_n \end{array} \right)_{n\times1}\)</span> <span class="math inline">\({\boldsymbol{X}}= \left( \begin{array}{cc} 1 &amp; x_1 \\ 1 &amp; x_2 \\ \vdots &amp; \vdots \\ 1 &amp; x_n \end{array} \right)_{n\times2}\)</span> <span class="math inline">\({\boldsymbol{\beta}}= \left( \begin{array}{c} \beta_0 \\ \beta_1 \\ \end{array} \right)_{2\times1}\)</span> <span class="math inline">\({\boldsymbol{\epsilon}}= \left( \begin{array}{c} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{array} \right)_{n\times1}\)</span></p>
<p><span class="math inline">\(E[{\boldsymbol{\epsilon}}] = {\boldsymbol{0}}\)</span>, where <span class="math inline">\({\boldsymbol{0}}= \left( \begin{array}{c} 0 \\ 0 \\ \vdots \\0 \end{array} \right)_{n\times1}\)</span></p>
<p><span class="math inline">\(V[{\boldsymbol{\epsilon}}] = \sigma^2 {\boldsymbol{I}}\)</span>, where <span class="math inline">\({\boldsymbol{I}}= \left( \begin{array}{cccc} 1 &amp; 0 &amp; \ldots &amp; 0 \\ 0 &amp; 1 &amp; \ldots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \ldots &amp; 1 \end{array} \right)_{n\times n}\)</span></p>
<p><span class="math inline">\(E[{\boldsymbol{Y}}] = {\boldsymbol{X}}{\boldsymbol{\beta}}\)</span></p>
<ul>
<li><p>I am using standard notation to indicate matrices/vectors and scalars</p></li>
<li><p>Boldface indicates a vector or matrix (<span class="math inline">\({\boldsymbol{Y}}\)</span>, <span class="math inline">\({\boldsymbol{X}}\)</span>, <span class="math inline">\({\boldsymbol{\beta}}\)</span>, <span class="math inline">\({\boldsymbol{\epsilon}}\)</span>, <span class="math inline">\({\boldsymbol{0}}\)</span>, <span class="math inline">\({\boldsymbol{I}}\)</span>)</p></li>
<li><p>Normal typeface indicates a scalar (<span class="math inline">\(Y_i\)</span>, <span class="math inline">\(x_i\)</span>, <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\epsilon_i\)</span>, <span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>)</p></li>
</ul>
</section>
</section>
<section id="example-analysis-of-bmi-part-1" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="example-analysis-of-bmi-part-1"><span class="header-section-number">4</span> Example Analysis of BMI (Part 1)</h2>
<ul>
<li><p>Example analysis conducted in class involving BMI (response) with gender (predictor 1) and age (predictor 2)</p></li>
<li><p>This is “Lab 1” and will serve as an example of how future labs will proceed</p></li>
</ul>
</section>
<section id="residuals" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="residuals"><span class="header-section-number">5</span> Residuals</h2>
<ul>
<li><p>Often linear regression models are specified in terms of the response instead of the mean response</p>
<ul>
<li><p>Include an error term in the model, <span class="math inline">\(\epsilon_i\)</span></p></li>
<li><p>Model <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span></p></li>
</ul></li>
<li><p>The linear regression model is divided into two parts</p>
<ul>
<li><p>The mean, or systematic, part (the “signal”)</p></li>
<li><p>The error, or random, part (the “noise”)</p></li>
</ul></li>
<li><p>Residuals</p>
<ul>
<li><p><span class="math inline">\(\hat{\epsilon}_i = Y_i - \left(\hat{\beta_0} + \hat{\beta_1} X_i\right)\)</span></p></li>
<li><p><span class="math inline">\(\hat{{\boldsymbol{\epsilon}}} = {\boldsymbol{Y}}- {\boldsymbol{X}}\hat{{\boldsymbol{\beta}}}\)</span></p></li>
<li><p><span class="math inline">\(\hat{{\boldsymbol{\beta}}} = \left({\boldsymbol{X}}'{\boldsymbol{X}}\right)^{-1} \left({\boldsymbol{X}}'{\boldsymbol{Y}}\right)\)</span></p></li>
</ul></li>
<li><p>The mean of the residuals is <span class="math inline">\(0\)</span></p></li>
<li><p>The standard deviation of the residuals is the “Root Mean Square Error”</p>
<ul>
<li><p>In our example analysis of BMI and gender, the RMSE is exactly equal to the pooled estimate of the standard deviation from a two-sample, equal variance t-test</p></li>
<li><p>In our example analysis of BMI and age, the RMSE is the square root of the average variances across the age groups</p></li>
</ul></li>
<li><p>In many textbooks, <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span></p>
<ul>
<li><p>A common <span class="math inline">\(\sigma^2\)</span> implies constant variance across all levels of the grouping variable, “homoscedasticity”</p></li>
<li><p>Normality of the residuals is a nice property, but it is not necessary (and rarely observed in practice)</p></li>
<li><p>We will discuss how lack of Normality and heteroscedasticity impact statistical inference</p></li>
</ul></li>
</ul>
</section>
<section id="assumptions-and-inference-with-linear-regression" class="level2 page-columns page-full" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="assumptions-and-inference-with-linear-regression"><span class="header-section-number">6</span> Assumptions and Inference with Linear Regression</h2>
<section id="the-big-three-assumptions" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="the-big-three-assumptions"><span class="header-section-number">6.1</span> The Big Three Assumptions</h3>
<ul>
<li><p>Most common uses of regression</p>
<ul>
<li><p>Prediction: Estimating what a future value of <span class="math inline">\(Y\)</span> will be based on observed <span class="math inline">\(X\)</span></p></li>
<li><p>Comparisons within groups: Describing the distribution of <span class="math inline">\(Y\)</span> across levels of the grouping variable <span class="math inline">\(X\)</span> by estimating the mean <span class="math inline">\(E[Y | X]\)</span></p></li>
<li><p>Comparisons across groups: Differences appear across groups if the regression parameter slope estimate <span class="math inline">\(\beta_1\)</span> is non-zero</p></li>
</ul></li>
<li><p>Valid statistical inference (CIs, p-values) about <em>associations</em> requires three general assumptions</p></li>
<li><p>Assumption 1: Approximately Normal distributions for the parameter estimates</p>
<ul>
<li><p>Normal data or “large” N</p></li>
<li><p>It is often surprising how small “large” can be</p>
<ul>
<li><p>Definition of large depends on the error distribution and relative sample sizes within each group</p></li>
<li><p>With exactly Normally distributed errors, only need one observation (or two to estimate a slope)</p></li>
<li><p>With very heavy tails, “large” can be very large</p></li>
<li><p>See Lumley, et al., Ann Rev Pub Hlth, 2002</p></li>
</ul></li>
</ul></li>
<li><p>Assumption 2: Independence of observations</p>
<ul>
<li><p>Classic regression: Independence of all observation (now)</p></li>
<li><p>Robust standard errors: Correlated observations within identified clusters (later)</p></li>
</ul></li>
<li><p>Assumption 3: Assumption about the variance of observations within groups</p>
<ul>
<li><p>Classic regression: Homoscedasticity (equal variance across groups)</p></li>
<li><p>Robust standard errors: Allows for unequal variance across groups</p></li>
</ul></li>
</ul>
</section>
<section id="additional-assumptions-for-additional-inference" class="level3 page-columns page-full" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="additional-assumptions-for-additional-inference"><span class="header-section-number">6.2</span> Additional Assumptions for Additional Inference</h3>
<ul>
<li><p>Note that some textbooks will claim there are more than three assumptions. In truth, additional assumptions are not needed to make the aforementioned statistical inference about <em>associations</em>. However …</p></li>
<li><p>Valid statistical inference (CIs, p-values) about <em>mean responses in specific groups</em> requires a further assumption</p></li>
<li><p>Assumption 4: Adequacy of the linear model</p>
<ul>
<li><p>If we are trying to borrow information about the mean from neighboring groups, and we are assuming a straight line relationship, the straight line needs to be true</p></li>
<li><p>No longer saying there is just a linear trend in the means, but now need to believe that all the means lie on a straight line</p></li>
<li><p>Note that we can model transformations of the measured predictor</p></li>
</ul></li>
<li><p>For inference about <em>individual observations</em> (prediction intervals, P-values) in specific groups requires another assumption</p></li>
<li><p>Assumption 5: Assumptions about the distribution of the errors within each group (a very strong assumption)</p>
<ul>
<li><p>Classically: Errors have the same Normal distribution within each grouping variable</p></li>
<li><p>Robust standard error will not help</p></li>
<li><p>Prediction intervals assume a common error distribution across groups (homoscedasticity)</p></li>
</ul></li>
<li><p>Possible extension: Errors have the same distribution, but not necessarily Normal (rarely implemented in frequentist software)</p>
<ul>
<li><p>Bootstrapping</p></li>
<li><p>Bayesian analysis</p></li>
<li><p>Other flexible approaches</p></li>
</ul></li>
</ul>
<section id="scenario-1-all-model-assumptions-hold" class="level4 page-columns page-full" data-number="6.2.1">
<h4 data-number="6.2.1" class="anchored" data-anchor-id="scenario-1-all-model-assumptions-hold"><span class="header-section-number">6.2.1</span> Scenario 1: All model assumptions hold</h4>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>regassumptions <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>, <span class="at">to=</span><span class="dv">100</span>, <span class="at">length=</span>n))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, Normal errors</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y1 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, Skewed errors</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y2 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rlnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, errors increasing with predictor (so increasing with Y too)</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y3 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span><span class="sc">+</span>regassumptions<span class="sc">$</span>x<span class="sc">*</span>.<span class="dv">1</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model incorrect, Normal error</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y4<span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fl">0.02</span><span class="sc">*</span>(regassumptions<span class="sc">$</span>x)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y1)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-true" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-true-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-true-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-true-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Scatterplot with best fit line where assumptions of Normality, linearity, homoskedasticity all hold
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>model.y1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y1 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-true-diag" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-true-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-true-diag-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-true-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Diagnostic plots where assumptions of Normality, linearity, homoskedasticity all hold
</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>Can estimate the mean of Y at a given value of X</li>
<li>Can make inference about the association between X and Y (based on the slope)</li>
<li>Can predict new values of Y given X</li>
</ul>
</section>
<section id="scenario-2-error-distribution-is-not-normally-distributed" class="level4 page-columns page-full" data-number="6.2.2">
<h4 data-number="6.2.2" class="anchored" data-anchor-id="scenario-2-error-distribution-is-not-normally-distributed"><span class="header-section-number">6.2.2</span> Scenario 2: Error distribution is not Normally distributed</h4>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y2)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-error-distribution" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-error-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-error-distribution-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-error-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Scatterplot with best fit line where the error distribution is skewed to the right
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model.y2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-error-distribution-diag" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-error-distribution-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-error-distribution-diag-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-error-distribution-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Diagnostic plots where the error distribution is skewed to the right
</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>If the sample size is large enough, we can estimate the mean of Y at a given value of X (Central Limit Theorem)</li>
<li>If we use “robust” standard errors, we can make inference about the association between X and Y (based on the slope)
<ul>
<li>Robust standard error relax the assumption of homoskedasticity/common variance</li>
</ul></li>
<li>We <em>cannot</em> predict new values of Y given X. This requires the correct error distribution.</li>
</ul>
</section>
<section id="scenario-3-variance-increasing-with-predictor-and-expected-value-of-y-heteroskedasticity" class="level4 page-columns page-full" data-number="6.2.3">
<h4 data-number="6.2.3" class="anchored" data-anchor-id="scenario-3-variance-increasing-with-predictor-and-expected-value-of-y-heteroskedasticity"><span class="header-section-number">6.2.3</span> Scenario 3: Variance increasing with predictor and expected value of Y (heteroskedasticity)</h4>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y3)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-heteroskedasticity" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-heteroskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-heteroskedasticity-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-heteroskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Scatterplot with best fit line where the error distribution variance is increasing
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model.y3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-heteroskedasticity-diag" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-heteroskedasticity-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-heteroskedasticity-diag-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-heteroskedasticity-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Diagnostic plot where the error distribution variance is increasing
</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>If the sample size is large enough, we can estimate the mean of Y at a given value of X (Central Limit Theorem)</li>
<li>If we use “robust” standard errors, we can make inference about the association between X and Y (based on the slope)
<ul>
<li>Robust standard error relax the assumption of homoskedasticity/common variance</li>
</ul></li>
<li>We <em>cannot</em> predict new values of Y given X. This requires the correct error distribution (and mean model, but that is correct)</li>
</ul>
</section>
<section id="scenario-4-mean-model-incorrectly-specified" class="level4 page-columns page-full" data-number="6.2.4">
<h4 data-number="6.2.4" class="anchored" data-anchor-id="scenario-4-mean-model-incorrectly-specified"><span class="header-section-number">6.2.4</span> Scenario 4: Mean model incorrectly specified</h4>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y4)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-mean-incorrect" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-mean-incorrect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-mean-incorrect-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-mean-incorrect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Scatterplot with best fit line where the mean model is not correctly specified
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell page-columns page-full">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model.y4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y4 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div id="fig-assumptions-mean-incorrect-diag" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-assumptions-mean-incorrect-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Lec03.SimpleLinearRegression_files/figure-html/fig-assumptions-mean-incorrect-diag-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-assumptions-mean-incorrect-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Diagnostic plots where the mean model is not correctly specified
</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>Because our model is wrong, we <em>cannot</em> estimate the mean of Y at a given value of X. It will be biased, even if the sample size is large, the model will still be incorrect
<ul>
<li>The good news is that we can fix our mean model to more flexibly model the association.
<ul>
<li>Here, we have just included a single slope term to model the association with <span class="math inline">\(X\)</span>, <span class="math inline">\(E[Y|X] = \beta_0 + \beta_1*X\)</span>.</li>
<li>The correct model in this simple example is <span class="math inline">\(E[Y|X] = \beta_0 + \beta_1*X + \beta_2*X^2\)</span>. Note that this model is still a “linear model”. A “linear model” is linear <em>in the parameters</em> (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>). We can included the quadratic predictor <span class="math inline">\(X^2\)</span> in the model and still have a model that is linear in the parameters.</li>
</ul></li>
</ul></li>
<li>If we use “robust” standard errors, we can make inference about the association between X and Y (based on the slope, <span class="math inline">\(\beta_1\)</span>)
<ul>
<li>Robust standard error relax the assumption of homoskedasticity</li>
<li>While the model is not a great fit, <span class="math inline">\(\beta_1\)</span> may summarize a first-order trend</li>
</ul></li>
<li>We <em>cannot</em> predict new values of Y given X. This requires the correct mean model and error distribution.</li>
</ul>
</section>
<section id="summary" class="level4" data-number="6.2.5">
<h4 data-number="6.2.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.2.5</span> Summary</h4>
<ul>
<li><p>Regression based inference about <em>associations</em> is far more trustworthy than estimation of group means or individual predictions.</p></li>
<li><p>There is much to be gained by using robust variance estimates</p></li>
</ul>
<div id="tbl-panel" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Summary of what is required for valid estimates of <span class="math inline">\(\beta\)</span> and the variance of beta using the classical, non-robust (NR) and robust (R) approaches. The classic (non-robust) variance is <span class="math inline">\(\hat{\textrm{Var}}_{NR}(\hat{\beta})\)</span> and the robust variance is <span class="math inline">\(\hat{\textrm{Var}}_R(\hat{\beta})\)</span>
</figcaption>
<div aria-describedby="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Assumption Holds (Yes/No)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Linearity</th>
<th style="text-align: left;">Homoskedasticity</th>
<th style="text-align: left;">Normality</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">N</td>
</tr>
<tr class="odd">
<td style="text-align: left;">N</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">N</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
</tr>
<tr class="odd">
<td style="text-align: left;">N</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">N</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">N</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Valid Inference (Yes/No/Maybe)</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(\hat{\beta}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(\hat{\textrm {Var}}_{NR}(\hat{\beta})\)</span></th>
<th style="text-align: left;"><span class="math inline">\(\hat{\textrm{ Var}}_R(\hat{\beta})\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">M<sup>2</sup></td>
<td style="text-align: left;">M<sup>2</sup></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">Y</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">M<sup>2</sup></td>
</tr>
<tr class="odd">
<td style="text-align: left;">M<sup>1</sup></td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">M<sup>3</sup></td>
</tr>
<tr class="even">
<td style="text-align: left;">M<sup>1</sup></td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">M<sup>2,3</sup></td>
</tr>
<tr class="odd">
<td style="text-align: left;">M<sup>1</sup></td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">M<sup>2</sup></td>
</tr>
<tr class="even">
<td style="text-align: left;">M<sup>1</sup></td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">M<sup>2,3</sup></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</figure>
</div>
<ul>
<li><sup>1</sup> First-order trend, if appropriate</li>
<li><sup>2</sup> Approximately valid under large sample sizes</li>
<li><sup>3</sup> If <span class="math inline">\(X\)</span> is random, but not if <span class="math inline">\(X\)</span> is fixed</li>
</ul>
</section>
</section>
<section id="interpreting-positive-results" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="interpreting-positive-results"><span class="header-section-number">6.3</span> Interpreting “Positive” Results</h3>
<ul>
<li><p>Slope is statistically different from 0 using robust standard errors</p></li>
<li><p>Observed data is atypical of a setting with no linear trend in mean response across groups</p></li>
<li><p>Data suggests evidence of a trend toward larger (or smaller) means in groups having larger values of the predictor</p></li>
<li><p>(To the extent the data appears linear, estimates of the group means will be reliable)</p></li>
</ul>
</section>
<section id="interpreting-negative-results" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="interpreting-negative-results"><span class="header-section-number">6.4</span> Interpreting “Negative” Results</h3>
<ul>
<li><p>Many possible reasons why the slope is not statistically different from 0 using robust standard errors</p></li>
<li><p>There may be no association between the response and predictor</p></li>
<li><p>There may be an association, but not in the parameter considered (the mean response)</p></li>
<li><p>There may be an association in the parameter considered, but the best fitting line has zero slope</p></li>
<li><p>There may be a first order trend in the parameter considered, but we lacked the precision to be confident that it truly exists (a type II error)</p></li>
</ul>
</section>
</section>
<section id="model-checking" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="model-checking"><span class="header-section-number">7</span> Model Checking</h2>
<ul>
<li><p>Much statistical literature has been devoted to methods for checking the assumptions for regression models</p></li>
<li><p>My philosophy: Model checking is generally fraught with peril as it necessarily involves multiple comparisons</p>
<ul>
<li><p>We cannot reliably use the sampled data to assess whether it accurately portrays the population</p></li>
<li><p>We are more worried about the data from the population that we might not have sampled</p></li>
<li><p>It is not so much the abnormal points that we see, but the ones that are hiding in the population that will make our model perform badly</p></li>
<li><p>But, do tend to worry more when we see a tendency to extreme outliers in the sample or clear departures from model assumptions</p></li>
<li><p>If we over-check our model and make adjustments to the model based on our observed data, we will inflate the type I error rate (i.e.&nbsp;will be more likely to claim statistical significance when it doesn’t really exist). We run the risk of creating a model that fits our data well but does not generalize.</p>
<ul>
<li><p>Estimates are biased away from the null</p></li>
<li><p>Reported standard errors are too small</p></li>
<li><p>If we fish through the data, we will always find significant results</p></li>
<li><p>In clinical trials, often Phase II results are not able to be replicated in Phase III trials</p></li>
</ul></li>
</ul></li>
<li><p>Instead of extensive model checking, go back to our choices of inference when planning our analysis</p>
<ul>
<li><p>Best to plan for unusual data</p></li>
<li><p>There is often little to be lost and much to be gained by using the robust standard error estimates</p></li>
<li><p>By using robust errors, avoids much of the need for model checking</p></li>
<li><p>Model checking is almost entirely data driven</p></li>
<li><p>Robust standard errors is a more logical scientific approach</p>
<ul>
<li><p>Minimize the need to presume more knowledge than the question we are trying to answer</p></li>
<li><p>E.g., if we don’t know how the means might differ, why should we presume to know how the variances or the shape of the distribution might behave?</p></li>
</ul></li>
</ul></li>
</ul>
<section id="residuals-versus-fitted-values" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="residuals-versus-fitted-values"><span class="header-section-number">7.1</span> Residuals versus fitted values</h3>
<ul>
<li><p>Plot of <span class="math inline">\(\hat{\epsilon_i}\)</span> versus <span class="math inline">\(\hat{y_i}\)</span></p></li>
<li><p>If assumptions hold, should be a random pattern about zero. See <a href="#fig-assumptions-true-diag" class="quarto-xref">Figure&nbsp;5</a> for example.</p></li>
<li><p>If you have <em>a priori</em> concerns about non-constant variance, this is one potential check</p>
<ul>
<li>E.g., it is fairly common for uncertainty to increase with outcome. See <a href="#fig-assumptions-heteroskedasticity-diag" class="quarto-xref">Figure&nbsp;9</a> for the resulting “fan” pattern that would appear</li>
</ul></li>
</ul>
</section>
<section id="scale-location-plot" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="scale-location-plot"><span class="header-section-number">7.2</span> Scale-location plot</h3>
<ul>
<li><p>The scale-location plot is very similar to residuals vs fitted values, and is used to evaluate the homoskedasticity assumption</p></li>
<li><p>It uses the square root of the absolute value of standardized residuals instead of plotting the residuals themselves</p></li>
<li><p>We want to check two things</p>
<ul>
<li><p>That the best fit line is approximately horizontal. If it is, then the average magnitude of the standardized residuals isn’t changing much as a function of the fitted values.</p></li>
<li><p>That the spread around the fit line doesn’t vary with the fitted values. If so, then the variability of magnitudes doesn’t vary much as a function of the fitted values.</p></li>
</ul></li>
</ul>
</section>
<section id="qq-plot" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="qq-plot"><span class="header-section-number">7.3</span> QQ plot</h3>
<ul>
<li><p>Used to evaluate Normality of the residuals</p>
<ul>
<li>If assumptions hold, points should lie on a 1:1 line</li>
</ul></li>
<li><p>Plot of standardized residuals versus theoretical quantities from a N(0,1) distribution</p>
<ul>
<li><p>If assumptions hold, the standardized residuals should be a random sample from a N(0,1) distribution</p></li>
<li><p>We can use quantiles of the Normal distribution to check how closely the observed matches the expected</p>
<ul>
<li>The 50th percentile of the residuals should be 0</li>
<li>The 75th percentile of the residuals should be 0.67</li>
<li>The 90th percentile of the residuals should be 1.28</li>
<li>The 95th percentile of the residuals should be 1.64</li>
<li>The 97.5th percentil of the residuals should be 1.96</li>
</ul></li>
</ul></li>
<li><p>Similar idea would be a histogram or density plot of the (standardized) residuals that could be visually evaluated for Normality</p></li>
</ul>
</section>
<section id="residuals-versus-leverage" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="residuals-versus-leverage"><span class="header-section-number">7.4</span> Residuals versus leverage</h3>
<ul>
<li><p>Used to check for outliers</p></li>
<li><p>Plot can help us to identify influential observations, if there are any</p></li>
<li><p>Influence differs from leverage. Not all outliers influence the regression coefficient estimates</p></li>
</ul>
</section>
</section>
<section id="linear-regression-with-robust-standard-error-estimates" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="linear-regression-with-robust-standard-error-estimates"><span class="header-section-number">8</span> Linear Regression with Robust Standard Error estimates</h2>
<ul>
<li><p>There are several libraries available in R for fitting models with robust error estimates</p></li>
<li><p>There are also several different flavors of robust estimators</p>
<ul>
<li><p>For now, we are going to consider the default “Huber-White sandwich estimator”</p></li>
<li><p>In Stata, the Huber-White robust estimate of the standard error can be obtained using the ‘robust’ option</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode stata code-with-copy"><code class="sourceCode stata"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">regress</span> chol age, <span class="kw">robust</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><p>In the following examples I provide estimates using classical linear regression and linear regression estimate using robust standard errors. For each of these example compare</p>
<ul>
<li><p>Estimates of the intercept, <span class="math inline">\(\hat{\beta_0}\)</span></p></li>
<li><p>Estimates of the slope, <span class="math inline">\(\hat{\beta_1}\)</span></p></li>
<li><p>Estimates of the standard errors, <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_0})\)</span> and <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_1})\)</span></p></li>
</ul></li>
</ul>
<section id="comparison-when-normality-constant-variance-holds" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="comparison-when-normality-constant-variance-holds"><span class="header-section-number">8.1</span> Comparison when Normality, constant variance holds</h3>
<section id="age-and-cholesterol" class="level4" data-number="8.1.1">
<h4 data-number="8.1.1" class="anchored" data-anchor-id="age-and-cholesterol"><span class="header-section-number">8.1.1</span> Age and Cholesterol</h4>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>fit.ols <span class="ot">&lt;-</span> <span class="fu">ols</span>(chol <span class="sc">~</span> age, <span class="at">data=</span>plotdata, <span class="at">x=</span><span class="cn">TRUE</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>fit.ols</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = chol ~ age, data = plotdata, x = TRUE)

                 Model Likelihood    Discrimination    
                       Ratio Test           Indexes    
Obs      301    LR chi2      5.43    R2       0.018    
sigma15.3405    d.f.            1    R2 adj   0.015    
d.f.     299    Pr(&gt; chi2) 0.0198    g        2.344    

Residuals

    Min      1Q  Median      3Q     Max 
-39.591 -10.524  -0.234  11.154  41.819 

          Coef     S.E.    t     Pr(&gt;|t|)
Intercept 203.2259 10.3138 19.70 &lt;0.0001 
age         0.3209  0.1375  2.33 0.0203  </code></pre>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(fit.ols)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = chol ~ age, data = plotdata, x = TRUE)

                 Model Likelihood    Discrimination    
                       Ratio Test           Indexes    
Obs      301    LR chi2      5.43    R2       0.018    
sigma15.3405    d.f.            1    R2 adj   0.015    
d.f.     299    Pr(&gt; chi2) 0.0198    g        2.344    

Residuals

    Min      1Q  Median      3Q     Max 
-39.591 -10.524  -0.234  11.154  41.819 

          Coef     S.E.    t     Pr(&gt;|t|)
Intercept 203.2259 10.3790 19.58 &lt;0.0001 
age         0.3209  0.1378  2.33 0.0205  </code></pre>
</div>
</div>
</section>
<section id="scenario-1-dataset" class="level4" data-number="8.1.2">
<h4 data-number="8.1.2" class="anchored" data-anchor-id="scenario-1-dataset"><span class="header-section-number">8.1.2</span> Scenario 1 dataset</h4>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y1 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y1 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2    200.34    R2       0.633    
sigma5.0531    d.f.            1    R2 adj   0.631    
d.f.    198    Pr(&gt; chi2) 0.0000    g        7.659    

Residuals

     Min       1Q   Median       3Q      Max 
-15.2533  -3.2042  -0.4963   3.0693  14.4377 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 3.3375 0.7119  4.69 &lt;0.0001 
x         0.2275 0.0123 18.47 &lt;0.0001 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y1 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y1 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2    200.34    R2       0.633    
sigma5.0531    d.f.            1    R2 adj   0.631    
d.f.    198    Pr(&gt; chi2) 0.0000    g        7.659    

Residuals

     Min       1Q   Median       3Q      Max 
-15.2533  -3.2042  -0.4963   3.0693  14.4377 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 3.3375 0.7002  4.77 &lt;0.0001 
x         0.2275 0.0132 17.20 &lt;0.0001 </code></pre>
</div>
</div>
</section>
</section>
<section id="comparison-when-variance-is-increasing-with-predictor-scenario-3" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="comparison-when-variance-is-increasing-with-predictor-scenario-3"><span class="header-section-number">8.2</span> Comparison when variance is increasing with predictor (Scenario 3)</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y3 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y3 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2     95.93    R2       0.381    
sigma6.5232    d.f.            1    R2 adj   0.378    
d.f.    198    Pr(&gt; chi2) 0.0000    g        5.909    

Residuals

     Min       1Q   Median       3Q      Max 
-24.1947  -3.7861  -0.1145   4.1816  17.2286 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 5.6640 0.9191  6.16 &lt;0.0001 
x         0.1755 0.0159 11.04 &lt;0.0001 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y3 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y3 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2     95.93    R2       0.381    
sigma6.5232    d.f.            1    R2 adj   0.378    
d.f.    198    Pr(&gt; chi2) 0.0000    g        5.909    

Residuals

     Min       1Q   Median       3Q      Max 
-24.1947  -3.7861  -0.1145   4.1816  17.2286 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 5.6640 0.5955  9.51 &lt;0.0001 
x         0.1755 0.0153 11.49 &lt;0.0001 </code></pre>
</div>
</div>
</section>
<section id="comparison-when-error-variance-is-skewed-to-the-right-scenario-2" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="comparison-when-error-variance-is-skewed-to-the-right-scenario-2"><span class="header-section-number">8.3</span> Comparison when error variance is skewed to the right (Scenario 2)</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y2 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y2 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2    431.83    R2       0.885    
sigma2.0635    d.f.            1    R2 adj   0.884    
d.f.    198    Pr(&gt; chi2) 0.0000    g        6.596    

Residuals

    Min      1Q  Median      3Q     Max 
-1.8206 -1.1341 -0.6103  0.1731 16.6448 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 6.9339 0.2907 23.85 &lt;0.0001 
x         0.1959 0.0050 38.95 &lt;0.0001 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y2 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Regression Model

ols(formula = y2 ~ x, data = regassumptions, x = TRUE)

                Model Likelihood    Discrimination    
                      Ratio Test           Indexes    
Obs     200    LR chi2    431.83    R2       0.885    
sigma2.0635    d.f.            1    R2 adj   0.884    
d.f.    198    Pr(&gt; chi2) 0.0000    g        6.596    

Residuals

    Min      1Q  Median      3Q     Max 
-1.8206 -1.1341 -0.6103  0.1731 16.6448 

          Coef   S.E.   t     Pr(&gt;|t|)
Intercept 6.9339 0.3526 19.67 &lt;0.0001 
x         0.1959 0.0056 35.18 &lt;0.0001 </code></pre>
</div>
</div>
</section>
<section id="comments" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="comments"><span class="header-section-number">8.4</span> Comments</h3>
{{()}}
<p>{()}</p>
<table class="caption-top table">
<caption>Comparison of point estimates, <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span></caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Classical Intercept</th>
<th>Robust Intercept</th>
<th>Classical Slope</th>
<th>Robust Slope</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Age-chol All Assump. hold</td>
<td>203.2</td>
<td>203.2</td>
<td>0.32</td>
<td>0.32</td>
</tr>
<tr class="even">
<td>Scenario 1 Assump hold</td>
<td>3.34</td>
<td>3.34</td>
<td>0.23</td>
<td>0.23</td>
</tr>
<tr class="odd">
<td>Scenario 3 Increase Variance</td>
<td>5.66</td>
<td>5.66</td>
<td>0.18</td>
<td>0.18</td>
</tr>
<tr class="even">
<td>Scenario 2 Skewed Variance</td>
<td>6.93</td>
<td>6.93</td>
<td>0.20</td>
<td>0.20</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<caption>Comparison of standard error estimates, <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_0})\)</span> and <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_1})\)</span></caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Classical Intercept</th>
<th>Robust Intercept</th>
<th>Classical Slope</th>
<th>Robust Slope</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Age-chol All Assump. hold</td>
<td>10.31</td>
<td>10.38</td>
<td>0.137</td>
<td>0.138</td>
</tr>
<tr class="even">
<td>Scenario 1 Assump hold</td>
<td>0.712</td>
<td>0.700</td>
<td>0.0123</td>
<td>0.0132</td>
</tr>
<tr class="odd">
<td>Scenario 3 Increase Variance</td>
<td>0.919</td>
<td>0.596</td>
<td>0.0159</td>
<td>0.0153</td>
</tr>
<tr class="even">
<td>Scenario 2 Skewed Variance</td>
<td>0.291</td>
<td>0.353</td>
<td>0.00503</td>
<td>0.00557</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Point estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> were the same for robust and classical standard error</p></li>
<li><p>Point estimates <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_0})\)</span> and <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_1})\)</span> were different for robust and classical standard error</p>
<ul>
<li><p>In general, it is hard to predict the effect of using robust standard errors</p></li>
<li><p>These were just a a couple of examples and do not constitute a thorough examination of the impact of using robust standard errors</p></li>
</ul></li>
<li><p>When the model assumptions hold, for these two scenarios, robust standard error estimates were larger than classical standard error estimates</p>
<ul>
<li><p>While this is not unexpected, to formally evaluate the amount of increase would require a statistical simulation</p>
<ul>
<li><p>Simulate many datasets where the Normality and constant variance assumption holds</p></li>
<li><p>For each dataset, estimate <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_0})\)</span> and <span class="math inline">\(\hat{\textrm{se}}(\hat{\beta_1})\)</span></p></li>
<li><p>Summarize the results</p></li>
<li><p>Approach will be covered in a future lab</p></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="linear-regression-and-correlation" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="linear-regression-and-correlation"><span class="header-section-number">9</span> Linear Regression and Correlation</h2>
<section id="pearsons-correlation" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="pearsons-correlation"><span class="header-section-number">9.1</span> Pearson’s Correlation</h3>
<ul>
<li><p>Notation</p>
<ul>
<li><p><span class="math inline">\(\rho\)</span> signifies the population value</p></li>
<li><p><span class="math inline">\(r\)</span> (or <span class="math inline">\(\hat{\rho}\)</span>) is the estimated correlation from data</p></li>
</ul></li>
<li><p>Formula</p>
<ul>
<li><p><span class="math inline">\(r = \frac{\Sigma(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\Sigma(x_i - \bar{x})^2\Sigma(y_i - \bar{y})^2}}\)</span></p></li>
<li><p>Range: <span class="math inline">\(-1 \leq r \leq 1\)</span></p></li>
</ul></li>
<li><p>Interpretation</p>
<ul>
<li><p>Measures the linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p></li>
<li><p>Correlation coefficient is a unitless index of strength of association between two variables (+ = positive association, - = negative, 0 = no association)</p></li>
<li><p>Can test for significant association by testing whether the population correlation is zero t = which is identical to the <span class="math inline">\(t\)</span>-test used to test whether the population <span class="math inline">\(r\)</span> is zero; <span class="math inline">\(\textrm{d.f.} = n-2\)</span></p></li>
<li><p>Use probability calculator for <span class="math inline">\(t\)</span> distribution to get a 2-tailed <span class="math inline">\(P\)</span>-value</p></li>
<li><p>Confidence intervals for population <span class="math inline">\(r\)</span> calculated using Fisher’s <span class="math inline">\(Z\)</span> transformation</p></li>
</ul>
<p><span class="math display">\[Z = \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right)\]</span></p>
<ul>
<li><p>For large <span class="math inline">\(n\)</span>, <span class="math inline">\(Z\)</span> follows a Normal distribution with standard error <span class="math inline">\(\frac{1}{\sqrt{n-3}}\)</span></p></li>
<li><p>To calculate a confidence interval for <span class="math inline">\(r\)</span>, first find the confidence interval for <span class="math inline">\(Z\)</span> then transform back to the <span class="math inline">\(r\)</span> scale</p></li>
</ul></li>
</ul>
<p><span class="math display">\[\begin{aligned}
Z &amp; = &amp; \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) \\
2*Z &amp; = &amp; \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) \\
\textrm{exp}(2*Z) &amp; = &amp; \left( \frac{1+r}{1-r} \right) \\
\textrm{exp}(2*Z) * (1-r) &amp; = &amp; 1 + r \\
\textrm{exp}(2*Z) - r * \textrm{exp}(2*Z) &amp; = &amp; 1 + r \\
\textrm{exp}(2*Z) - 1 &amp; = &amp; r * \textrm{exp}(2*Z) + r \\
\textrm{exp}(2*Z) - 1 &amp; = &amp; r \left(\textrm{exp}(2*Z) + 1\right) \\
\frac{\textrm{exp}(2*Z) - 1}{\textrm{exp}(2*Z) + 1} &amp; = &amp; r \\
\end{aligned}\]</span></p>
<ul>
<li><p>Example (Altman 89-90): Pearson’s <span class="math inline">\(r\)</span> for a study investigating the association of basal metabolic rate with total energy expenditure was calculated to be <span class="math inline">\(0.7283\)</span> in a study of <span class="math inline">\(13\)</span> women. Derive a 95% confidence interval for <span class="math inline">\(r\)</span></p>
<p><span class="math display">\[Z = \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) = 0.9251\]</span></p></li>
<li><p>The lower limit of a 95% CI for <span class="math inline">\(Z\)</span> is given by <span class="math inline">\(0.9251 + 1.96*\frac{1}{\sqrt{n-3}} = 0.3053\)</span></p></li>
<li><p>The upper limit is <span class="math inline">\(0.9251 + 1.96*\frac{1}{\sqrt{n-3}} = 1.545\)</span></p></li>
<li><p>A 95% CI for the population correlation coefficient is given by transforming these limits from the <span class="math inline">\(Z\)</span> scale back to the <span class="math inline">\(r\)</span> scale.</p></li>
</ul>
<p><span class="math display">\[\frac{\textrm{exp}(2*0.3053) - 1}{\textrm{exp}(2*0.3053) + 1} \hspace{.5cm} \textrm{to} \hspace{.5cm}  \frac{\textrm{exp}(2*1.545) - 1}{\textrm{exp}(2*1.545) + 1}\]</span></p>
<ul>
<li>Which gives a 95% CI from 0.30 to 0.91 for the population correlation</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>fisher.z <span class="ot">&lt;-</span> <span class="cf">function</span>(r) {.<span class="dv">5</span> <span class="sc">*</span> <span class="fu">log</span>((<span class="dv">1</span><span class="sc">+</span>r)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>r))}</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>fisher.z.inv <span class="ot">&lt;-</span> <span class="cf">function</span>(z) {(<span class="fu">exp</span>(<span class="dv">2</span><span class="sc">*</span>z)<span class="sc">-</span><span class="dv">1</span>) <span class="sc">/</span> (<span class="fu">exp</span>(<span class="dv">2</span><span class="sc">*</span>z)<span class="sc">+</span><span class="dv">1</span>)}</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>fisher.z.se <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {<span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(n<span class="dv">-3</span>)}</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z.inv</span>(<span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)) <span class="co">#Should be original value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7283</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9250975</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">-</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3052911</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">+</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.544904</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z.inv</span>(<span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.96</span>, <span class="fl">1.96</span>)<span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2961472 0.9129407</code></pre>
</div>
</div>
</section>
<section id="relationship-to-regression" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="relationship-to-regression"><span class="header-section-number">9.2</span> Relationship to regression</h3>
<ul>
<li><p>Pearson’s correlation (<span class="math inline">\(\rho\)</span>) is directly related to linear regression</p></li>
<li><p>Correlation treats <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> symmetrically, but we can relate</p>
<ul>
<li><p><span class="math inline">\(E[Y | X]\)</span> as a function of <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(E[Y | X] = \beta_0 + \beta_1 X\)</span></p></li>
<li><p><span class="math inline">\(\beta_1 = \rho \frac{\sigma_Y}{\sigma_X}\)</span></p></li>
<li><p><span class="math inline">\(E[Y | X]\)</span>: mean <span class="math inline">\(Y\)</span> withing groups having equal <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: difference in mean <span class="math inline">\(Y\)</span> per 1 unit difference in <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\rho\)</span>: true correlation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\sigma_Y\)</span>: standard deviation of <span class="math inline">\(Y\)</span></p></li>
<li><p><span class="math inline">\(\sigma_X\)</span>: standard deviation of <span class="math inline">\(X\)</span></p></li>
</ul></li>
<li><p>More interpretable formulation of <span class="math inline">\(\rho\)</span></p>
<ul>
<li><p><span class="math inline">\(\rho \approx \beta \sqrt{\frac{\textrm{Var}(X)}{\beta^2\textrm{Var}(X) + \textrm{Var}(Y | X = x)}}\)</span></p></li>
<li><p><span class="math inline">\(\beta\)</span>: slope between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\textrm{Var}(X)\)</span>: variance of <span class="math inline">\(X\)</span> in the sample</p></li>
<li><p><span class="math inline">\(\textrm{Var}(Y | X = x)\)</span>: variance of <span class="math inline">\(Y\)</span> in groups having the same value of <span class="math inline">\(X\)</span> (the vertical spread of data)</p></li>
</ul></li>
<li><p>Correlation tends to increase in absolute value as</p>
<ul>
<li><p>The absolute value of the slope of the line increases</p></li>
<li><p>The variance of data decreases within groups that share a common value of <span class="math inline">\(X\)</span></p></li>
<li><p>The variance of <span class="math inline">\(X\)</span> increases</p></li>
</ul></li>
<li><p>Scientific uses of correlation</p>
<ul>
<li><p>The slope between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is of scientific interest</p></li>
<li><p>The variance of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span> is partly of scientific interest, but can also be impacted by restricting sampling to certain values of another variable</p>
<ul>
<li><p>The variance of height given age is less if sampling just males than if sampling both sexes</p></li>
<li><p>The variance of <span class="math inline">\(X\)</span> is often set by study design (which is often not of scientific interest)</p></li>
</ul></li>
<li><p>Hypothesis tests for a nonzero correlation are exactly the same as a test for a nonzero slope in classical linear regression</p></li>
<li><p>The statistical significance of a given value of <span class="math inline">\(\rho\)</span> depends only on the sample size</p></li>
</ul></li>
<li><p>Correlation is more of a statistical measure than a scientific measure</p></li>
</ul>
</section>
</section>
<section id="regression-on-geometric-means-log-transformations" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="regression-on-geometric-means-log-transformations"><span class="header-section-number">10</span> Regression on Geometric Means: Log transformations</h2>
<ul>
<li><p>Geometric means of distributions are typically analyzed by using linear regression on the log transformed outcome</p></li>
<li><p>Used for inference under the following circumstances</p>
<ul>
<li><p>We are (scientifically) interested in multiplicative rather than additive models</p></li>
<li><p>We want to down-weight the impact of outliers</p></li>
<li><p>The standard deviation of the response in a groups is proportional to the mean</p>
<ul>
<li>“Error is <span class="math inline">\(\pm 10\%\)</span>” instead of “Error is <span class="math inline">\(\pm 10\)</span>”</li>
</ul></li>
</ul></li>
</ul>
<section id="interpretation-of-parameters" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="interpretation-of-parameters"><span class="header-section-number">10.1</span> Interpretation of Parameters</h3>
<ul>
<li><p>Linear regression on the log transformed <span class="math inline">\(Y\)</span></p></li>
<li><p>Note that in statistics <span class="math inline">\(\textrm{log}\)</span> almost always refers the the natural log (<span class="math inline">\(\textrm{log}_e\)</span>)</p></li>
<li><p>Model: <span class="math inline">\(E[\textrm{log} Y_i | X_i] = \beta_0 + \beta_1 \times X_i\)</span></p>
<ul>
<li><p>When <span class="math inline">\(X_i = 0\)</span>: <span class="math inline">\(E[\textrm{log} Y_i | X_i = 0] = \beta_0\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x\)</span>: <span class="math inline">\(E[\textrm{log} Y_i | X_i = x] = \beta_0 + \beta_1 \times x\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x+1\)</span>: <span class="math inline">\(E[\textrm{log} Y_i | X_i = x + 1] = \beta_0 + \beta_1 \times x + \beta_1\)</span></p></li>
<li><p>Restate the model as log link for geometric mean</p></li>
</ul></li>
<li><p>Model: <span class="math inline">\(\textrm{log GM}[Y_i | X_i] = \beta_0 + \beta_1 \times X_i\)</span></p>
<ul>
<li><p>When <span class="math inline">\(X_i = 0\)</span>: <span class="math inline">\(\textrm{log GM}[Y_i | X_i = 0] = \beta_0\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x\)</span>: <span class="math inline">\(\textrm{log GM}[Y_i | X_i = x] = \beta_0 + \beta_1 \times x\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x+1\)</span>: <span class="math inline">\(\textrm{log GM}[Y_i | X_i = x + 1] = \beta_0 + \beta_1 \times x + \beta_1\)</span></p></li>
</ul></li>
<li><p>Interpretation of parameters by back-transforming model</p>
<ul>
<li><p>Model: <span class="math inline">\(\textrm{GM}[Y_i | X_i] = e^{\beta_0} \times e^{\beta_1 \times X_i}\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = 0\)</span>: <span class="math inline">\(\textrm{GM}[Y_i | X_i = 0] = e^{\beta_0}\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x\)</span>: <span class="math inline">\(\textrm{GM}[Y_i | X_i = x] = e^{\beta_0} \times e^{\beta_1 \times x}\)</span></p></li>
<li><p>When <span class="math inline">\(X_i = x+1\)</span>: <span class="math inline">\(\textrm{GM}[Y_i | X_i = x + 1] = e^{\beta_0} \times e^{\beta_1 \times x} \times e^{\beta_1}\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="example-fev-with-height" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="example-fev-with-height"><span class="header-section-number">10.2</span> Example: FEV with Height</h3>
<ul>
<li><p>Question: How does FEV differ across height groups?</p></li>
<li><p>Scientific justification for summarizing with geometric mean</p>
<ul>
<li><p>FEV is a volume</p></li>
<li><p>Height is a linear dimension</p></li>
<li><p>Each dimension of lung size is proportional to height</p></li>
<li><p>Standard deviation is likely proportional to height</p></li>
<li><p>Science: <span class="math inline">\(FEV \propto Height^3\)</span> or <span class="math inline">\(\sqrt[3]{FEV} \propto Height\)</span></p></li>
</ul></li>
<li><p>Statistics: <span class="math inline">\(\textrm{log}(FEV) \propto 3 \textrm{ log}(Height)\)</span></p>
<ul>
<li>Science dictates model choice</li>
</ul></li>
<li><p>Statistical preference for (any) transformations of response</p>
<ul>
<li><p>May transform to equal variance across groups</p></li>
<li><p>Homoscedasticity allows for easier inference</p></li>
</ul></li>
<li><p>Statistical preference for a log transformation</p>
<ul>
<li><p>Easier interpretation: multiplicative model</p></li>
<li><p>Compare groups using ratios</p></li>
</ul></li>
</ul>
</section>
<section id="log-transformed-predictors" class="level3" data-number="10.3">
<h3 data-number="10.3" class="anchored" data-anchor-id="log-transformed-predictors"><span class="header-section-number">10.3</span> Log Transformed Predictors</h3>
<ul>
<li><p>Interpretation of log predictor and log link for response</p></li>
<li><p>Log link used to model the geometric mean of <span class="math inline">\(Y\)</span></p></li>
<li><p>Exponentiated slope estimates ratio of geometric means across groups</p></li>
<li><p>Log transformation of predictor compares groups with a <span class="math inline">\(k\)</span>-fold difference in there measured predictors</p></li>
<li><p>Estimated ratio of geometric means</p>
<ul>
<li><span class="math inline">\(\exp (\textrm{log}(k) \times \beta_1) = k^{\beta_1}\)</span></li>
</ul></li>
<li><p>Interpretation of model</p>
<ul>
<li><span class="math inline">\(\textrm{log GM}[FEV_i | log (height_i)] = -11.9 + 3.12 \times log(height_i)\)</span></li>
</ul></li>
<li><p>Estimate ratio of geometric mean FEV for two groups differing by <span class="math inline">\(10\%\)</span> in height (a 1.1 fold difference in height)</p></li>
<li><p>To find: Exponentiate <span class="math inline">\(1.1\)</span> to the slope: <span class="math inline">\(1.1^{3.12} = 1.35\)</span></p>
<ul>
<li>“Group that is 10% taller is estimated to have a geometric mean FEV that is 1.35 times higher (35% higher)”</li>
</ul></li>
<li><p>Why transform the predictor?</p>
<ul>
<li><p>Typically chosen according to whether the data are likely to follow a straight line relationship</p></li>
<li><p>Linearity necessary to predict the values of the parameter in individual groups</p></li>
<li><p>Linearity is not necessary to estimate existence of an association</p></li>
<li><p>Linearity is not necessary to estimate a first order trend in the parameter across groups having the sampled distribution of the predictor</p></li>
<li><p>(Inference about these two questions will tend to be conservative if linearity does not hold)</p></li>
<li><p>Rarely do we know which transformation of the predictor provides the best linear fit</p></li>
<li><p>As always, there is significant danger in using the data to estimate the best transformation to use</p></li>
<li><p>If there is no association of any kind between the response and the predictor, a linear fit (with a zero slope) is correct</p></li>
<li><p>Trying to detect a transformation is thus an informal test for an association (multiple testing, which inflates type I error rate)</p></li>
<li><p>It is best to choose transformations of the predictor on scientific grounds</p></li>
<li><p>In practice, it is often true that mean functions are well approximated by a straight line over a small range of the data</p></li>
</ul></li>
<li><p>Example: In the FEV dataset, the logarithm of height is approximately linear over the range of heights sampled (look at the plot)</p></li>
<li><p>We can often choose untransformed predictors when science would suggest a non-linear association</p></li>
<li><p>Can have major advantages in interpreting the results of the analysis</p></li>
<li><p>In the FEV example, it is far more natural to compare heights by difference than by ratios</p>
<ul>
<li>We would rather characterize two children as differing by 4 inches in height rather than as the 44 inch child being 10% taller than the 40 inch child</li>
</ul></li>
</ul>
</section>
<section id="looking-ahead-to-multivariable-models" class="level3" data-number="10.4">
<h3 data-number="10.4" class="anchored" data-anchor-id="looking-ahead-to-multivariable-models"><span class="header-section-number">10.4</span> Looking Ahead to Multivariable Models</h3>
<ul>
<li><p>The relative importance of having the “true” transformation for a predictor depends on the statistical role</p>
<ul>
<li><p>Predictor of Interest</p></li>
<li><p>Effect Modifiers</p></li>
<li><p>Confounders</p></li>
<li><p>Precision variables</p></li>
</ul></li>
<li><p>We treat these variables different when planning our analysis</p>
<ul>
<li><p>Predictor of Interest (should be pre-specified)</p>
<ul>
<li><p>In general, don’t worry about modeling the exact association until you have even established an association (binary search)</p></li>
<li><p>Need to have a prespecified model for the POI</p></li>
<li><p>Searching for the best fit can inflate the type I error</p></li>
<li><p>Make most accurate, precise inference about the presence of the association first</p></li>
<li><p>Exploratory models can suggest models for future analyses</p></li>
</ul></li>
<li><p>Effect Modifiers (difficult to do right anyway)</p>
<ul>
<li><p>Modeling of effect modifiers is invariably just a test for the existence of an interaction</p></li>
<li><p>We rarely have a lot of precision to answer questions in subgroups of the data</p></li>
<li><p>Patterns of interaction can be so complex that it is unlikely that we will really capture the interactions across all subgroups in a single model</p></li>
<li><p>Typically, we would restrict future studies to analyses treating subgroups separately</p></li>
</ul></li>
<li><p>Confounders (matters the most)</p>
<ul>
<li><p>It is important to have an appropriate model of the association between the confounder and the response</p></li>
<li><p>Failure to accurately model the confounder means that some residual confounding will exist</p></li>
<li><p>However, searching for the best model may inflate the type I error for inference about the predictor of interest by overstating the precision of the study</p></li>
<li><p>Luckily, we rarely care about inference for the confounder, so we are free to use inefficient means of adjustment (e.g.&nbsp;a stratified analysis)</p></li>
</ul></li>
<li><p>Precision Variables</p>
<ul>
<li><p>When modeling precision variables, it is rarely worth the effort to use the “best” transformation</p></li>
<li><p>We usually capture the largest part of the added precision using crude models</p></li>
<li><p>We generally do not care about estimating association between the response and the precision variable</p>
<ul>
<li>Most often, precision variables represent known effects on the response</li>
</ul></li>
</ul></li>
</ul></li>
</ul>


<!-- -->

</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/chrissl789\.github\.io\/modern-regression\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notes/Lec02.review.html" class="pagination-link" aria-label="Review of Key Concepts">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Review of Key Concepts</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notes/Lec04.Logistic.html" class="pagination-link" aria-label="Logistic Regression">
        <span class="nav-page-text">Logistic Regression</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb50" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Simple Linear Regression"</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Lecture 03"</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="an">name:</span><span class="co"> Lec03.SimpleLinearRegression.qmd</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstanarm)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(finalfit)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rms)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gglm)</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a><span class="fu">tryCatch</span>(<span class="fu">source</span>(<span class="st">'pander_registry.R'</span>), <span class="at">error =</span> <span class="cf">function</span>(e) <span class="fu">invisible</span>(e))</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## General Regression Setting</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two variable setting</span></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Many statistical problems examine the association between two variables</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Outcome variable (response variable, ~~dependent variable~~)</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Grouping variable (covariate, predictor variable, ~~independent variable~~)</span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>(While "dependent variable" and "independent variable" are commonly used, these imply that a modifiable independent variable is *causing* a dependent variable to change. We are fitting models focused on association, not causation.)</span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>General goal is to compare distribution of the outcome variable across levels of the grouping variable</span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Groups are defined by the grouping variable</span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Within each group, the grouping variable is constant</span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Treatment and control groups</span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Age: Continuous (days), broadly categorized (years), or wide categories (e.g. 0-18, 18-65, 65+)</span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-41"><a href="#cb50-41" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In intro course, statistical analysis is characterized by two factors</span>
<span id="cb50-42"><a href="#cb50-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-43"><a href="#cb50-43" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Number of groups (samples)</span>
<span id="cb50-44"><a href="#cb50-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-45"><a href="#cb50-45" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If subjects in groups are independent</span>
<span id="cb50-46"><a href="#cb50-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-47"><a href="#cb50-47" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In the two variable setting, statistical analysis is more generally characterized by the grouping variable. If the grouping variable is</span>
<span id="cb50-48"><a href="#cb50-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-49"><a href="#cb50-49" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Constant: One sample problem</span>
<span id="cb50-50"><a href="#cb50-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-51"><a href="#cb50-51" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Binary: Two sample problem</span>
<span id="cb50-52"><a href="#cb50-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-53"><a href="#cb50-53" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Categorical: $k$ sample problem (e.g. ANOVA)</span>
<span id="cb50-54"><a href="#cb50-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-55"><a href="#cb50-55" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continuous: Infinite sample problem (analyzed with regression)</span>
<span id="cb50-56"><a href="#cb50-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-57"><a href="#cb50-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Regression thus *extends* the one- and two-sample problems up to infinite sample problems</span>
<span id="cb50-58"><a href="#cb50-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-59"><a href="#cb50-59" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Of course, in reality we never have *infinite* samples, but models that can handle this case are the ultimate generalization</span>
<span id="cb50-60"><a href="#cb50-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-61"><a href="#cb50-61" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continuous predictors of interest</span>
<span id="cb50-62"><a href="#cb50-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-63"><a href="#cb50-63" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continuous adjustment variables</span>
<span id="cb50-64"><a href="#cb50-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-67"><a href="#cb50-67" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-68"><a href="#cb50-68" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-chol-age</span></span>
<span id="cb50-69"><a href="#cb50-69" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Scatterplot of cholesterol and age. Age is a continuous grouping variable."</span></span>
<span id="cb50-70"><a href="#cb50-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-71"><a href="#cb50-71" aria-hidden="true" tabindex="-1"></a>  <span class="do">### Make a cholesterol and age dataframe.  Set the random number seed so everything is reproducible</span></span>
<span id="cb50-72"><a href="#cb50-72" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">19</span>)</span>
<span id="cb50-73"><a href="#cb50-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-74"><a href="#cb50-74" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">age=</span><span class="fu">c</span>(<span class="dv">63</span>, <span class="dv">63</span>, <span class="fu">rep</span>(<span class="dv">65</span><span class="sc">:</span><span class="dv">80</span>,<span class="dv">15</span>), <span class="fu">rep</span>(<span class="dv">81</span><span class="sc">:</span><span class="dv">85</span>,<span class="dv">10</span>), <span class="dv">86</span>,<span class="dv">86</span>,<span class="dv">86</span>, <span class="dv">87</span>,<span class="dv">89</span>, <span class="dv">90</span>, <span class="dv">93</span>, <span class="dv">95</span>, <span class="dv">100</span>),</span>
<span id="cb50-75"><a href="#cb50-75" aria-hidden="true" tabindex="-1"></a>                       <span class="at">chol=</span><span class="cn">NA</span>)</span>
<span id="cb50-76"><a href="#cb50-76" aria-hidden="true" tabindex="-1"></a>plotdata<span class="sc">$</span>chol <span class="ot">&lt;-</span> <span class="dv">190</span> <span class="sc">+</span> .<span class="dv">5</span><span class="sc">*</span>plotdata<span class="sc">$</span>age <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(plotdata<span class="sc">$</span>age), <span class="dv">0</span>, <span class="dv">15</span>)</span>
<span id="cb50-77"><a href="#cb50-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-78"><a href="#cb50-78" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span>
<span id="cb50-79"><a href="#cb50-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-80"><a href="#cb50-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-81"><a href="#cb50-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regression versus two sample approaches</span></span>
<span id="cb50-82"><a href="#cb50-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-83"><a href="#cb50-83" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>With a binary grouping variable, regression models reduce to the corresponding two variable methods</span>
<span id="cb50-84"><a href="#cb50-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-85"><a href="#cb50-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Linear regression with a binary predictor</span>
<span id="cb50-86"><a href="#cb50-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-87"><a href="#cb50-87" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>t-test, equal variance: Classic linear regression</span>
<span id="cb50-88"><a href="#cb50-88" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>t-test, unequal variance: Linear regression with robust standard errors (approximately)</span>
<span id="cb50-89"><a href="#cb50-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-90"><a href="#cb50-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Logistic regression with a binary predictor</span>
<span id="cb50-91"><a href="#cb50-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-92"><a href="#cb50-92" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>(Pearson) Chi-squared test: Score test from logistic regression</span>
<span id="cb50-93"><a href="#cb50-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-94"><a href="#cb50-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Proportional odds regression with a binary predictor</span>
<span id="cb50-95"><a href="#cb50-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-96"><a href="#cb50-96" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Wilcoxon Rank Sum Test</span>
<span id="cb50-97"><a href="#cb50-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-98"><a href="#cb50-98" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Cox (proportional hazards) regression with a binary predictor</span>
<span id="cb50-99"><a href="#cb50-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-100"><a href="#cb50-100" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Log-rank test: Score test from Cox regression</span>
<span id="cb50-101"><a href="#cb50-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-102"><a href="#cb50-102" aria-hidden="true" tabindex="-1"></a><span class="fu">### Guiding principle</span></span>
<span id="cb50-103"><a href="#cb50-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-104"><a href="#cb50-104" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Everything can be recast as a regression problem.</span>
<span id="cb50-105"><a href="#cb50-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-106"><a href="#cb50-106" aria-hidden="true" tabindex="-1"></a><span class="fu">## Motivating Problem: Cholesterol and Age</span></span>
<span id="cb50-107"><a href="#cb50-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-108"><a href="#cb50-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Definitions</span></span>
<span id="cb50-109"><a href="#cb50-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-110"><a href="#cb50-110" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Is there an association between cholesterol and age?</span>
<span id="cb50-111"><a href="#cb50-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-112"><a href="#cb50-112" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Scientific question: Does aging effect cholesterol?</span>
<span id="cb50-113"><a href="#cb50-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-114"><a href="#cb50-114" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical question: Does the distribution of cholesterol differ across age groups?</span>
<span id="cb50-115"><a href="#cb50-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-116"><a href="#cb50-116" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Acknowledges variability in the response (cholesterol)</span>
<span id="cb50-117"><a href="#cb50-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-118"><a href="#cb50-118" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Acknowledges cause-effect relationship is uncertain</span>
<span id="cb50-119"><a href="#cb50-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-120"><a href="#cb50-120" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Association does not imply causation</span>
<span id="cb50-121"><a href="#cb50-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-122"><a href="#cb50-122" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Any observed differences could be due to other factors. For example, the association could be with year of birth rather than age.</span>
<span id="cb50-123"><a href="#cb50-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-124"><a href="#cb50-124" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Continuous response variable: Cholesterol</span>
<span id="cb50-125"><a href="#cb50-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-126"><a href="#cb50-126" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Continuous grouping variable (predictor of interest): Age</span>
<span id="cb50-127"><a href="#cb50-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-128"><a href="#cb50-128" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>An infinite number of ages are possible</span>
<span id="cb50-129"><a href="#cb50-129" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We will not sample every possible age, and may round for simplicity</span>
<span id="cb50-130"><a href="#cb50-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-131"><a href="#cb50-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple Regression Model</span></span>
<span id="cb50-132"><a href="#cb50-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-133"><a href="#cb50-133" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Attempt to answer scientific question by assessing linear trends in average cholesterol</span>
<span id="cb50-134"><a href="#cb50-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-135"><a href="#cb50-135" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimate the best fitting line to average cholesterol within age groups</span>
<span id="cb50-136"><a href="#cb50-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-137"><a href="#cb50-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-138"><a href="#cb50-138" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">\textrm{Chol} | \textrm{Age}</span><span class="co">]</span> = \beta_0 + \beta_1 \times \textrm{Age}</span>
<span id="cb50-139"><a href="#cb50-139" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-140"><a href="#cb50-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-141"><a href="#cb50-141" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The expected value of cholesterol given age is modeled using an intercept ($\beta_0$) and slope ($\beta_1$)</span>
<span id="cb50-142"><a href="#cb50-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-143"><a href="#cb50-143" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>An association exists if the slope is nonzero</span>
<span id="cb50-144"><a href="#cb50-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-145"><a href="#cb50-145" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>A non-zero slope indicates that the average cholesterol will be different across different age groups</span>
<span id="cb50-146"><a href="#cb50-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-147"><a href="#cb50-147" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Descriptive plots of cholesterol and age</span></span>
<span id="cb50-148"><a href="#cb50-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-151"><a href="#cb50-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-152"><a href="#cb50-152" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-chol-age-lowess</span></span>
<span id="cb50-153"><a href="#cb50-153" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Scatterplot of cholesterol and age. Association is described using a lowess smooth line."</span></span>
<span id="cb50-154"><a href="#cb50-154" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span>
<span id="cb50-155"><a href="#cb50-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-156"><a href="#cb50-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-159"><a href="#cb50-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-160"><a href="#cb50-160" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-chol-age-linear</span></span>
<span id="cb50-161"><a href="#cb50-161" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Scatterplot of cholesterol and age. Association is described using a linear trend line."</span></span>
<span id="cb50-162"><a href="#cb50-162" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>chol)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Cholesterol"</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Age (years)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span>
<span id="cb50-163"><a href="#cb50-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-164"><a href="#cb50-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-165"><a href="#cb50-165" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Simple linear regression model</span></span>
<span id="cb50-166"><a href="#cb50-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-167"><a href="#cb50-167" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The simple regression model produces an easy to remember (but approximate) rule of thumb.</span>
<span id="cb50-168"><a href="#cb50-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-169"><a href="#cb50-169" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>"Normal cholesterol is 190 plus half your age"</span>
<span id="cb50-170"><a href="#cb50-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-171"><a href="#cb50-171" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E<span class="co">[</span><span class="ot">\textrm{Chol} | \textrm{Age}</span><span class="co">]</span> = 190 + 0.50 \times \textrm{Age}$</span>
<span id="cb50-172"><a href="#cb50-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-173"><a href="#cb50-173" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Note that data were generated using this model. Estimates, below, will be different.</span>
<span id="cb50-174"><a href="#cb50-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-175"><a href="#cb50-175" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Frequentist Estimates and Interpretation</span></span>
<span id="cb50-176"><a href="#cb50-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-177"><a href="#cb50-177" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Raw, unformatted estimates, model summary, and confidence intervals for age</span>
<span id="cb50-178"><a href="#cb50-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-181"><a href="#cb50-181" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-182"><a href="#cb50-182" aria-hidden="true" tabindex="-1"></a>m.chol <span class="ot">&lt;-</span> <span class="fu">lm</span>(chol <span class="sc">~</span> age, <span class="at">data=</span>plotdata)</span>
<span id="cb50-183"><a href="#cb50-183" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m.chol)</span>
<span id="cb50-184"><a href="#cb50-184" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.default</span>(m.chol, <span class="st">"age"</span>) <span class="co"># Based on asymptotic Normality</span></span>
<span id="cb50-185"><a href="#cb50-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-186"><a href="#cb50-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-187"><a href="#cb50-187" aria-hidden="true" tabindex="-1"></a>$E<span class="co">[</span><span class="ot">\textrm{Chol} | \textrm{Age}</span><span class="co">]</span> = 203.2 + 0.32 \times \textrm{Age}$</span>
<span id="cb50-188"><a href="#cb50-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-189"><a href="#cb50-189" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Using finalfit to create a nicer output table of the slope coefficient for age and confidence intervals</span>
<span id="cb50-190"><a href="#cb50-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-193"><a href="#cb50-193" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-194"><a href="#cb50-194" aria-hidden="true" tabindex="-1"></a>explanatory <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"age"</span>)</span>
<span id="cb50-195"><a href="#cb50-195" aria-hidden="true" tabindex="-1"></a>dependent <span class="ot">=</span> <span class="st">'chol'</span></span>
<span id="cb50-196"><a href="#cb50-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-197"><a href="#cb50-197" aria-hidden="true" tabindex="-1"></a><span class="fu">label</span>(plotdata<span class="sc">$</span>chol) <span class="ot">&lt;-</span> <span class="st">"Cholesterol"</span></span>
<span id="cb50-198"><a href="#cb50-198" aria-hidden="true" tabindex="-1"></a><span class="fu">label</span>(plotdata<span class="sc">$</span>age) <span class="ot">&lt;-</span> <span class="st">"Age (years)"</span></span>
<span id="cb50-199"><a href="#cb50-199" aria-hidden="true" tabindex="-1"></a><span class="fu">finalfit</span>(plotdata, dependent, explanatory)</span>
<span id="cb50-200"><a href="#cb50-200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-201"><a href="#cb50-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-202"><a href="#cb50-202" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Bayesian Estimates and Interpretation</span></span>
<span id="cb50-203"><a href="#cb50-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-204"><a href="#cb50-204" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Bayesian approach to the linear model requires specifying</span>
<span id="cb50-205"><a href="#cb50-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-206"><a href="#cb50-206" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The model, e.g. a linear model with intercept and slope for age, Normally distributed errors and constant variance</span>
<span id="cb50-207"><a href="#cb50-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-208"><a href="#cb50-208" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Prior distributions on parameters</span>
<span id="cb50-209"><a href="#cb50-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-210"><a href="#cb50-210" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>For the simple linear regression model, we have parameters $\beta_0$, $\beta_1$, and $\sigma$.</span>
<span id="cb50-211"><a href="#cb50-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-212"><a href="#cb50-212" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>For now, we will use default prior distributions that are are intended to be *weakly informative* in that they provide moderate regularization and help stabilize computation. See the <span class="co">[</span><span class="ot">STAN documentation</span><span class="co">](https://mc-stan.org/rstanarm/reference/priors.html)</span> for more details</span>
<span id="cb50-213"><a href="#cb50-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-214"><a href="#cb50-214" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Appropriate priors can be based on scientific considerations</span>
<span id="cb50-215"><a href="#cb50-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-216"><a href="#cb50-216" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Sensitivity analyses can evaluate the the robustness of finding to different prior assumptions</span>
<span id="cb50-217"><a href="#cb50-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-218"><a href="#cb50-218" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Output from Bayesian linear regression</span>
<span id="cb50-219"><a href="#cb50-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-222"><a href="#cb50-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-223"><a href="#cb50-223" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(chol <span class="sc">~</span> age,</span>
<span id="cb50-224"><a href="#cb50-224" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>plotdata, <span class="at">family=</span><span class="fu">gaussian</span>(),</span>
<span id="cb50-225"><a href="#cb50-225" aria-hidden="true" tabindex="-1"></a>                 <span class="at">seed=</span><span class="dv">1234</span>,</span>
<span id="cb50-226"><a href="#cb50-226" aria-hidden="true" tabindex="-1"></a>                 <span class="at">refresh=</span><span class="dv">0</span>)</span>
<span id="cb50-227"><a href="#cb50-227" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1, <span class="at">digits=</span><span class="dv">2</span>, <span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>))</span>
<span id="cb50-228"><a href="#cb50-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-229"><a href="#cb50-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-230"><a href="#cb50-230" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>And a summary of the prior distributions used</span>
<span id="cb50-231"><a href="#cb50-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-234"><a href="#cb50-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-235"><a href="#cb50-235" aria-hidden="true" tabindex="-1"></a><span class="fu">prior_summary</span>(fit1, <span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb50-236"><a href="#cb50-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-237"><a href="#cb50-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-238"><a href="#cb50-238" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation</span>
<span id="cb50-239"><a href="#cb50-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-240"><a href="#cb50-240" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Slope for age is of primary scientific importance</span>
<span id="cb50-241"><a href="#cb50-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-242"><a href="#cb50-242" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>*A priori* we assume that no association between age and cholesterol. Specifically, we assumed a Normal prior with location (mean) of 0 and scale (standard devation) of 6 for $\beta_1$.</span>
<span id="cb50-243"><a href="#cb50-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-244"><a href="#cb50-244" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Conditional on the data, we estimate that for every 1 year increase in age, cholesterol increases by 0.32 mg/dl (95% credible interval 0.04 to 0.60).</span>
<span id="cb50-245"><a href="#cb50-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-246"><a href="#cb50-246" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Comparison of Frequentist and Bayesian interpretation of the slope</span></span>
<span id="cb50-247"><a href="#cb50-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-248"><a href="#cb50-248" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Following was given by gpt-4.0 <span class="ot">[^1]</span></span>
<span id="cb50-249"><a href="#cb50-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-250"><a href="#cb50-250" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Query "Explain how a slope from simple linear regression is interpreted using language a college graduate could understand. Provide a Bayesian and Frequentist interpretation." VUMC aiChat tool, GPT-4. Retrieved 12/28/2023.</span>
<span id="cb50-251"><a href="#cb50-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-252"><a href="#cb50-252" aria-hidden="true" tabindex="-1"></a>::: {.classname style="color: gray"}</span>
<span id="cb50-253"><a href="#cb50-253" aria-hidden="true" tabindex="-1"></a>In simple linear regression, the slope (often denoted as "b" or "beta") is interpreted as the expected change in the dependent (or response) variable for a one-unit increase in the independent (or predictor) variable, assuming all other variables are held constant.</span>
<span id="cb50-254"><a href="#cb50-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-255"><a href="#cb50-255" aria-hidden="true" tabindex="-1"></a>From a Frequentist perspective, the slope is considered a fixed but unknown value which is estimated from the sample data. If the slope is found to be 2, for instance, it would suggest that for every one-unit increase in our predictor variable, we expect, on average, a 2-unit increase in the response variable. This is based on the data at hand and is subject to sampling variability. Confidence intervals can be constructed around this estimate to provide a range of plausible values for this unknown fixed parameter. If a 95% confidence interval for the slope is (1.5, 2.5), it would suggest that we are 95% confident that the true slope falls within this range.</span>
<span id="cb50-256"><a href="#cb50-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-257"><a href="#cb50-257" aria-hidden="true" tabindex="-1"></a>In contrast, a Bayesian approach treats the slope as a random variable. Rather than a single fixed value, the slope has a distribution of possible values. This distribution combines our prior beliefs about what the slope might be (prior distribution) and the observed data (likelihood). The resulting distribution (posterior distribution) reflects our updated belief about the slope after seeing the data. If the mean of the posterior distribution is 2, it suggests that, given the prior and the data, our best guess is that a one-unit increase in the predictor variable corresponds to a 2-unit increase in the response variable on average. A credible interval, say a 95% credible interval of (1.5, 2.5), suggests that there is a 95% probability that the true value of the slope falls within this range, given our prior and the observed data.</span>
<span id="cb50-258"><a href="#cb50-258" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb50-259"><a href="#cb50-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-260"><a href="#cb50-260" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>When to use Bayesian or frequentist approaches to estimation<span class="ot">[^2]</span></span>
<span id="cb50-261"><a href="#cb50-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-262"><a href="#cb50-262" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>On many occasions, if one is careful in execution, both approaches to analysis will yield essentially equivalent inference</span>
<span id="cb50-263"><a href="#cb50-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-264"><a href="#cb50-264" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For small sample sizes, Bayesian approaches with carefully considered priors are often the only way to go because it is difficult to obtain well-calibrated frequentist intervals</span>
<span id="cb50-265"><a href="#cb50-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-266"><a href="#cb50-266" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For medium to large samples, unless there is strong prior information that one wants to incorporate, robust frequentist estimation using sandwich estimation is very appealing because its consistency is guaranteed under mild conditions</span>
<span id="cb50-267"><a href="#cb50-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-268"><a href="#cb50-268" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For highly complex models, a Bayesian approach is often the most convenient way to formulate the model, and computation under the Bayesian approach is the most straightforward</span>
<span id="cb50-269"><a href="#cb50-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-270"><a href="#cb50-270" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In summary, in many instances carefully considered Bayesian and frequentist approach will lead to similar scientific conclusions. My goal is describe the advantages and shortcoming of each approach, but a strong recommendation of one over the other is not given as there is often no reason for stating a preference.</span>
<span id="cb50-271"><a href="#cb50-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-272"><a href="#cb50-272" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Wakefield, Jon. Bayesian and Frequentist Regression Methods. Section 1.6, Executive Summary</span>
<span id="cb50-273"><a href="#cb50-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-274"><a href="#cb50-274" aria-hidden="true" tabindex="-1"></a><span class="fu">### Uses of Regression</span></span>
<span id="cb50-275"><a href="#cb50-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-276"><a href="#cb50-276" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Borrowing information</span>
<span id="cb50-277"><a href="#cb50-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-278"><a href="#cb50-278" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Use other groups to make estimates in groups with sparse data</span>
<span id="cb50-279"><a href="#cb50-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-280"><a href="#cb50-280" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Intuitively, 67 and 69 year olds would provide some relevant information about 68 year olds</span>
<span id="cb50-281"><a href="#cb50-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-282"><a href="#cb50-282" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Assuming a straight line relationship tells us about other, even more distant, individuals</span>
<span id="cb50-283"><a href="#cb50-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-284"><a href="#cb50-284" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If we do not want to assume a straight line, we may only want to borrow information from nearby groups</span>
<span id="cb50-285"><a href="#cb50-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-286"><a href="#cb50-286" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Locally weighted scatterplot smooth line (lowess) added to the previous figures</span>
<span id="cb50-287"><a href="#cb50-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-288"><a href="#cb50-288" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Splines discussed in future lectures</span>
<span id="cb50-289"><a href="#cb50-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-290"><a href="#cb50-290" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>May not want to borrow too much information</span>
<span id="cb50-291"><a href="#cb50-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-292"><a href="#cb50-292" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Linear relationship is an assumption, with often low power to detect departures from linearity</span>
<span id="cb50-293"><a href="#cb50-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-294"><a href="#cb50-294" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Always avoid extrapolating beyond the range of the data (e.g. ages under 65 or over 100)</span>
<span id="cb50-295"><a href="#cb50-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-296"><a href="#cb50-296" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Defining "Contrasts"</span>
<span id="cb50-297"><a href="#cb50-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-298"><a href="#cb50-298" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Define a comparison across groups to use when answering scientific questions</span>
<span id="cb50-299"><a href="#cb50-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-300"><a href="#cb50-300" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If the straight line relationship holds, the slope is the difference in mean cholesterol levels between groups differing by 1 year in age</span>
<span id="cb50-301"><a href="#cb50-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-302"><a href="#cb50-302" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Do we want to assume that comparisons of 65 to 66 year old subjects are the same as comparisons of 95 to 96 year old subjects?</span>
<span id="cb50-303"><a href="#cb50-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-304"><a href="#cb50-304" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If a non-linear relationship, the slope is still the average difference in mean cholesterol levels between groups differing by 1 year in age</span>
<span id="cb50-305"><a href="#cb50-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-306"><a href="#cb50-306" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Slope is a (first order or linear) test for trend</span>
<span id="cb50-307"><a href="#cb50-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-308"><a href="#cb50-308" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linear Regression Inference</span></span>
<span id="cb50-309"><a href="#cb50-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-310"><a href="#cb50-310" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Regression output provides</span>
<span id="cb50-311"><a href="#cb50-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-312"><a href="#cb50-312" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimates</span>
<span id="cb50-313"><a href="#cb50-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-314"><a href="#cb50-314" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Intercept: Estimated mean cholesterol when age is 0</span>
<span id="cb50-315"><a href="#cb50-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-316"><a href="#cb50-316" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Slope: Estimated average difference in average cholesterol for two groups differing by 1 year in age</span>
<span id="cb50-317"><a href="#cb50-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-318"><a href="#cb50-318" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Standard errors</span>
<span id="cb50-319"><a href="#cb50-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-320"><a href="#cb50-320" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Confidence intervals</span>
<span id="cb50-321"><a href="#cb50-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-322"><a href="#cb50-322" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>P-values for testing</span>
<span id="cb50-323"><a href="#cb50-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-324"><a href="#cb50-324" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Intercept is zero (usually unimportant)</span>
<span id="cb50-325"><a href="#cb50-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-326"><a href="#cb50-326" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Slope is zero (test for linear trend in means)</span>
<span id="cb50-327"><a href="#cb50-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-328"><a href="#cb50-328" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>(Frequentist) Interpretation</span>
<span id="cb50-329"><a href="#cb50-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-330"><a href="#cb50-330" aria-hidden="true" tabindex="-1"></a>From linear regression analysis, we estimate that for each year difference in age, the difference in mean cholesterol is 0.32 mg/dL. A 95% confidence interval (CI) suggests that this observation is not unusual if the true difference in mean cholesterol per year difference in age were between 0.05 and 0.59 mg/dL. Because $p = 0.02$, we reject the null hypothesis that there is no linear trend in the average cholesterol across age groups using a significance level, $\alpha$, of $0.05$.</span>
<span id="cb50-331"><a href="#cb50-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-332"><a href="#cb50-332" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simple Linear Regression</span></span>
<span id="cb50-333"><a href="#cb50-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-334"><a href="#cb50-334" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ingredients</span></span>
<span id="cb50-335"><a href="#cb50-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-336"><a href="#cb50-336" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Response</span>
<span id="cb50-337"><a href="#cb50-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-338"><a href="#cb50-338" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The distribution of this variable will be compared across groups</span>
<span id="cb50-339"><a href="#cb50-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-340"><a href="#cb50-340" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Linear regression models the mean of the response variable</span>
<span id="cb50-341"><a href="#cb50-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-342"><a href="#cb50-342" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Log transformation of the response corresponds to modeling the geometric mean</span>
<span id="cb50-343"><a href="#cb50-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-344"><a href="#cb50-344" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Notation: It is extremely common to use $Y$ to denote the response variable when discussing general methods</span>
<span id="cb50-345"><a href="#cb50-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-346"><a href="#cb50-346" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Predictor</span>
<span id="cb50-347"><a href="#cb50-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-348"><a href="#cb50-348" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Group membership is measured by this variable</span>
<span id="cb50-349"><a href="#cb50-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-350"><a href="#cb50-350" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Notation</span>
<span id="cb50-351"><a href="#cb50-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-352"><a href="#cb50-352" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>When not using mnemonics, will be referred to as the $X$ variable in simple linear regression (linear regression with one predictor)</span>
<span id="cb50-353"><a href="#cb50-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-354"><a href="#cb50-354" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Later, when we discuss multiple regression, will refer to $X_1, X_2, \ldots, X_p$ when there are up to $p$ predictors</span>
<span id="cb50-355"><a href="#cb50-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-356"><a href="#cb50-356" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Regression Model</span>
<span id="cb50-357"><a href="#cb50-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-358"><a href="#cb50-358" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We typically consider a "linear predictor function" that is linear in the modeled predictors</span>
<span id="cb50-359"><a href="#cb50-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-360"><a href="#cb50-360" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Expected value (i.e. mean) of $Y$ for a particular value of $X$</span>
<span id="cb50-361"><a href="#cb50-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-362"><a href="#cb50-362" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span> = \beta_0 + \beta_1 \times X$</span>
<span id="cb50-363"><a href="#cb50-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-364"><a href="#cb50-364" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In a deterministic world, a line is of the form $y = mx + b$</span>
<span id="cb50-365"><a href="#cb50-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-366"><a href="#cb50-366" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>With no variation in the data, each value of $y$ would like exactly on a straight line</span>
<span id="cb50-367"><a href="#cb50-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-368"><a href="#cb50-368" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Intercept $b$ is values of $y$ when $x = 0$</span>
<span id="cb50-369"><a href="#cb50-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-370"><a href="#cb50-370" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Slope $m$ is the difference in $y$ for a one unit difference in $x$</span>
<span id="cb50-371"><a href="#cb50-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-372"><a href="#cb50-372" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Statistics in not completely deterministic. The real world has variability</span>
<span id="cb50-373"><a href="#cb50-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-374"><a href="#cb50-374" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Response within groups is variable (people born on the same day will have different cholesterol levels!)</span>
<span id="cb50-375"><a href="#cb50-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-376"><a href="#cb50-376" aria-hidden="true" tabindex="-1"></a><span class="ss">            -   </span>Randomness due to other variables impacting cholesterol</span>
<span id="cb50-377"><a href="#cb50-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-378"><a href="#cb50-378" aria-hidden="true" tabindex="-1"></a><span class="ss">            -   </span>Inherent randomness</span>
<span id="cb50-379"><a href="#cb50-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-380"><a href="#cb50-380" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The regression line thus describes the central tendency of the data in a scatterplot of the response versus the predictor</span>
<span id="cb50-381"><a href="#cb50-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-382"><a href="#cb50-382" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation of regression parameters</span>
<span id="cb50-383"><a href="#cb50-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-384"><a href="#cb50-384" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Intercept $\beta_0$: Mean $Y$ for a group with $X=0$</span>
<span id="cb50-385"><a href="#cb50-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-386"><a href="#cb50-386" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Often $\beta_0$ is not of scientific interest</span>
<span id="cb50-387"><a href="#cb50-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-388"><a href="#cb50-388" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>May be out of the range of data, or even impossible to observe $X=0$</span>
<span id="cb50-389"><a href="#cb50-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-390"><a href="#cb50-390" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Slope $\beta_1$: Difference in mean $Y$ across groups differing in $X$ by 1 unit</span>
<span id="cb50-391"><a href="#cb50-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-392"><a href="#cb50-392" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Usually measures association between $Y$ and $X$</span>
<span id="cb50-393"><a href="#cb50-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-394"><a href="#cb50-394" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span> = \beta_0 + \beta_1 \times X$</span>
<span id="cb50-395"><a href="#cb50-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-396"><a href="#cb50-396" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Derivation of interpretation</span>
<span id="cb50-397"><a href="#cb50-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-398"><a href="#cb50-398" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Simple linear regression of response $Y$ on predictor $X$</span>
<span id="cb50-399"><a href="#cb50-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-400"><a href="#cb50-400" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Mean of any arbitrary group can be derived from the equation $$</span>
<span id="cb50-401"><a href="#cb50-401" aria-hidden="true" tabindex="-1"></a>         Y_i = \beta_0 + \beta_1 X_i</span>
<span id="cb50-402"><a href="#cb50-402" aria-hidden="true" tabindex="-1"></a>         $$</span>
<span id="cb50-403"><a href="#cb50-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-404"><a href="#cb50-404" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Interpretation determined by considering possible values of $X$</span>
<span id="cb50-405"><a href="#cb50-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-406"><a href="#cb50-406" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Model: $E<span class="co">[</span><span class="ot">Y_i | X_i</span><span class="co">]</span> = \beta_0 + \beta_1 \times X_i$</span>
<span id="cb50-407"><a href="#cb50-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-408"><a href="#cb50-408" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>When $X_i = 0$, $E<span class="co">[</span><span class="ot">Y_i | X_i = 0 </span><span class="co">]</span> = \beta_0$</span>
<span id="cb50-409"><a href="#cb50-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-410"><a href="#cb50-410" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>When $X_i = x$, $E<span class="co">[</span><span class="ot">Y_i | X_i = x </span><span class="co">]</span> = \beta_0 + \beta_1 x$</span>
<span id="cb50-411"><a href="#cb50-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-412"><a href="#cb50-412" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>When $X_i = x + 1$, $E<span class="co">[</span><span class="ot">Y_i | X_i = x + 1 </span><span class="co">]</span> = \beta_0 + \beta_1 x + \beta_1$</span>
<span id="cb50-413"><a href="#cb50-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-414"><a href="#cb50-414" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>We can use the above to get an equation for $\beta_1$</span>
<span id="cb50-415"><a href="#cb50-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-416"><a href="#cb50-416" aria-hidden="true" tabindex="-1"></a>        $$</span>
<span id="cb50-417"><a href="#cb50-417" aria-hidden="true" tabindex="-1"></a>         E<span class="co">[</span><span class="ot">Y_i | X_i = x + 1 </span><span class="co">]</span> - E<span class="co">[</span><span class="ot">Y_i | X_i = x </span><span class="co">]</span> = <span class="sc">\\</span></span>
<span id="cb50-418"><a href="#cb50-418" aria-hidden="true" tabindex="-1"></a>         (\beta_0 + \beta_1 x + \beta_1) - (\beta_0 + \beta_1 x) <span class="sc">\\</span></span>
<span id="cb50-419"><a href="#cb50-419" aria-hidden="true" tabindex="-1"></a>         = \beta_1</span>
<span id="cb50-420"><a href="#cb50-420" aria-hidden="true" tabindex="-1"></a>         $$</span>
<span id="cb50-421"><a href="#cb50-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-422"><a href="#cb50-422" aria-hidden="true" tabindex="-1"></a><span class="in">        -   Thus, $\beta_1$ is the expected change in $Y$ per one unit increase in $x$</span></span>
<span id="cb50-423"><a href="#cb50-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-424"><a href="#cb50-424" aria-hidden="true" tabindex="-1"></a><span class="fu">### Matrix Notation</span></span>
<span id="cb50-425"><a href="#cb50-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-426"><a href="#cb50-426" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Using scalars, the simple linear regression model can be written as</span>
<span id="cb50-427"><a href="#cb50-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-428"><a href="#cb50-428" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$Y_i = \beta_0 + \beta_1 \times X_i + \epsilon_i$</span>
<span id="cb50-429"><a href="#cb50-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-430"><a href="#cb50-430" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$i = 1, \ldots, n$</span>
<span id="cb50-431"><a href="#cb50-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-432"><a href="#cb50-432" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$i$ indexes the independent sampling units (e.g. subjects)</span>
<span id="cb50-433"><a href="#cb50-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-434"><a href="#cb50-434" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$n$ is the total number of independent sampling units</span>
<span id="cb50-435"><a href="#cb50-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-436"><a href="#cb50-436" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>This formulauation drops the expected value notation, add in $\epsilon_i$</span>
<span id="cb50-437"><a href="#cb50-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-438"><a href="#cb50-438" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$\epsilon_i$ are the "Residuals" or "Errors"</span>
<span id="cb50-439"><a href="#cb50-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-440"><a href="#cb50-440" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$E<span class="co">[</span><span class="ot">\epsilon_i</span><span class="co">]</span> = 0$</span>
<span id="cb50-441"><a href="#cb50-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-442"><a href="#cb50-442" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>$V<span class="co">[</span><span class="ot">\epsilon_i</span><span class="co">]</span> = \sigma^2$ (constant variance assumption)</span>
<span id="cb50-443"><a href="#cb50-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-444"><a href="#cb50-444" aria-hidden="true" tabindex="-1"></a>\newcommand\Ybd{{\boldsymbol{Y}}}</span>
<span id="cb50-445"><a href="#cb50-445" aria-hidden="true" tabindex="-1"></a>\newcommand\Xbd{{\boldsymbol{X}}}</span>
<span id="cb50-446"><a href="#cb50-446" aria-hidden="true" tabindex="-1"></a>\newcommand\betabd{{\boldsymbol{\beta}}}</span>
<span id="cb50-447"><a href="#cb50-447" aria-hidden="true" tabindex="-1"></a>\newcommand\epsilonbd{{\boldsymbol{\epsilon}}}</span>
<span id="cb50-448"><a href="#cb50-448" aria-hidden="true" tabindex="-1"></a>\newcommand\zerovec{{\boldsymbol{0}}}</span>
<span id="cb50-449"><a href="#cb50-449" aria-hidden="true" tabindex="-1"></a>\newcommand\onevec{{\boldsymbol{1}}}</span>
<span id="cb50-450"><a href="#cb50-450" aria-hidden="true" tabindex="-1"></a>\newcommand\eye{{\boldsymbol{I}}}</span>
<span id="cb50-451"><a href="#cb50-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-452"><a href="#cb50-452" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Matrix notation: ${\boldsymbol{Y}}= {\boldsymbol{X}}{\boldsymbol{\beta}}+ {\boldsymbol{\epsilon}}$</span>
<span id="cb50-453"><a href="#cb50-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-454"><a href="#cb50-454" aria-hidden="true" tabindex="-1"></a>${\boldsymbol{Y}}= \left( \begin{array}{c} Y_1 <span class="sc">\\</span> Y_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> Y_n \end{array} \right)_{n\times1}$ ${\boldsymbol{X}}= \left( \begin{array}{cc} 1 &amp; x_1 \\ 1 &amp; x_2 \\ \vdots &amp; \vdots \\ 1 &amp; x_n \end{array} \right)_{n\times2}$ ${\boldsymbol{\beta}}= \left( \begin{array}{c} \beta_0 \\ \beta_1 \\ \end{array} \right)_{2\times1}$ ${\boldsymbol{\epsilon}}= \left( \begin{array}{c} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n \end{array} \right)_{n\times1}$</span>
<span id="cb50-455"><a href="#cb50-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-456"><a href="#cb50-456" aria-hidden="true" tabindex="-1"></a>$E<span class="co">[</span><span class="ot">{\boldsymbol{\epsilon}}</span><span class="co">]</span> = {\boldsymbol{0}}$, where ${\boldsymbol{0}}= \left( \begin{array}{c} 0 <span class="sc">\\</span> 0 <span class="sc">\\</span> \vdots <span class="sc">\\</span>0 \end{array} \right)_{n\times1}$</span>
<span id="cb50-457"><a href="#cb50-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-458"><a href="#cb50-458" aria-hidden="true" tabindex="-1"></a>$V<span class="co">[</span><span class="ot">{\boldsymbol{\epsilon}}</span><span class="co">]</span> = \sigma^2 {\boldsymbol{I}}$, where ${\boldsymbol{I}}= \left( \begin{array}{cccc} 1 &amp; 0 &amp; \ldots &amp; 0 <span class="sc">\\</span> 0 &amp; 1 &amp; \ldots &amp; 0 <span class="sc">\\</span> \vdots &amp; \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span> 0 &amp; 0 &amp; \ldots &amp; 1 \end{array} \right)_{n\times n}$</span>
<span id="cb50-459"><a href="#cb50-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-460"><a href="#cb50-460" aria-hidden="true" tabindex="-1"></a>$E<span class="co">[</span><span class="ot">{\boldsymbol{Y}}</span><span class="co">]</span> = {\boldsymbol{X}}{\boldsymbol{\beta}}$</span>
<span id="cb50-461"><a href="#cb50-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-462"><a href="#cb50-462" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>I am using standard notation to indicate matrices/vectors and scalars</span>
<span id="cb50-463"><a href="#cb50-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-464"><a href="#cb50-464" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Boldface indicates a vector or matrix (${\boldsymbol{Y}}$, ${\boldsymbol{X}}$, ${\boldsymbol{\beta}}$, ${\boldsymbol{\epsilon}}$, ${\boldsymbol{0}}$, ${\boldsymbol{I}}$)</span>
<span id="cb50-465"><a href="#cb50-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-466"><a href="#cb50-466" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Normal typeface indicates a scalar ($Y_i$, $x_i$, $\beta_0$, $\beta_1$, $\epsilon_i$, $0$, $1$)</span>
<span id="cb50-467"><a href="#cb50-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-468"><a href="#cb50-468" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example Analysis of BMI (Part 1)</span></span>
<span id="cb50-469"><a href="#cb50-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-470"><a href="#cb50-470" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Example analysis conducted in class involving BMI (response) with gender (predictor 1) and age (predictor 2)</span>
<span id="cb50-471"><a href="#cb50-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-472"><a href="#cb50-472" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This is "Lab 1" and will serve as an example of how future labs will proceed</span>
<span id="cb50-473"><a href="#cb50-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-474"><a href="#cb50-474" aria-hidden="true" tabindex="-1"></a><span class="fu">## Residuals</span></span>
<span id="cb50-475"><a href="#cb50-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-476"><a href="#cb50-476" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Often linear regression models are specified in terms of the response instead of the mean response</span>
<span id="cb50-477"><a href="#cb50-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-478"><a href="#cb50-478" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Include an error term in the model, $\epsilon_i$</span>
<span id="cb50-479"><a href="#cb50-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-480"><a href="#cb50-480" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Model $Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$</span>
<span id="cb50-481"><a href="#cb50-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-482"><a href="#cb50-482" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The linear regression model is divided into two parts</span>
<span id="cb50-483"><a href="#cb50-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-484"><a href="#cb50-484" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The mean, or systematic, part (the "signal")</span>
<span id="cb50-485"><a href="#cb50-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-486"><a href="#cb50-486" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The error, or random, part (the "noise")</span>
<span id="cb50-487"><a href="#cb50-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-488"><a href="#cb50-488" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Residuals</span>
<span id="cb50-489"><a href="#cb50-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-490"><a href="#cb50-490" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\hat{\epsilon}_i = Y_i - \left(\hat{\beta_0} + \hat{\beta_1} X_i\right)$</span>
<span id="cb50-491"><a href="#cb50-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-492"><a href="#cb50-492" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\hat{{\boldsymbol{\epsilon}}} = {\boldsymbol{Y}}- {\boldsymbol{X}}\hat{{\boldsymbol{\beta}}}$</span>
<span id="cb50-493"><a href="#cb50-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-494"><a href="#cb50-494" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\hat{{\boldsymbol{\beta}}} = \left({\boldsymbol{X}}'{\boldsymbol{X}}\right)^{-1} \left({\boldsymbol{X}}'{\boldsymbol{Y}}\right)$</span>
<span id="cb50-495"><a href="#cb50-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-496"><a href="#cb50-496" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The mean of the residuals is $0$</span>
<span id="cb50-497"><a href="#cb50-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-498"><a href="#cb50-498" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The standard deviation of the residuals is the "Root Mean Square Error"</span>
<span id="cb50-499"><a href="#cb50-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-500"><a href="#cb50-500" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In our example analysis of BMI and gender, the RMSE is exactly equal to the pooled estimate of the standard deviation from a two-sample, equal variance t-test</span>
<span id="cb50-501"><a href="#cb50-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-502"><a href="#cb50-502" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In our example analysis of BMI and age, the RMSE is the square root of the average variances across the age groups</span>
<span id="cb50-503"><a href="#cb50-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-504"><a href="#cb50-504" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In many textbooks, $\epsilon_i \sim N(0, \sigma^2)$</span>
<span id="cb50-505"><a href="#cb50-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-506"><a href="#cb50-506" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>A common $\sigma^2$ implies constant variance across all levels of the grouping variable, "homoscedasticity"</span>
<span id="cb50-507"><a href="#cb50-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-508"><a href="#cb50-508" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Normality of the residuals is a nice property, but it is not necessary (and rarely observed in practice)</span>
<span id="cb50-509"><a href="#cb50-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-510"><a href="#cb50-510" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We will discuss how lack of Normality and heteroscedasticity impact statistical inference</span>
<span id="cb50-511"><a href="#cb50-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-512"><a href="#cb50-512" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assumptions and Inference with Linear Regression</span></span>
<span id="cb50-513"><a href="#cb50-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-514"><a href="#cb50-514" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Big Three Assumptions</span></span>
<span id="cb50-515"><a href="#cb50-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-516"><a href="#cb50-516" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Most common uses of regression</span>
<span id="cb50-517"><a href="#cb50-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-518"><a href="#cb50-518" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Prediction: Estimating what a future value of $Y$ will be based on observed $X$</span>
<span id="cb50-519"><a href="#cb50-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-520"><a href="#cb50-520" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Comparisons within groups: Describing the distribution of $Y$ across levels of the grouping variable $X$ by estimating the mean $E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span>$</span>
<span id="cb50-521"><a href="#cb50-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-522"><a href="#cb50-522" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Comparisons across groups: Differences appear across groups if the regression parameter slope estimate $\beta_1$ is non-zero</span>
<span id="cb50-523"><a href="#cb50-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-524"><a href="#cb50-524" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Valid statistical inference (CIs, p-values) about *associations* requires three general assumptions</span>
<span id="cb50-525"><a href="#cb50-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-526"><a href="#cb50-526" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assumption 1: Approximately Normal distributions for the parameter estimates</span>
<span id="cb50-527"><a href="#cb50-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-528"><a href="#cb50-528" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Normal data or "large" N</span>
<span id="cb50-529"><a href="#cb50-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-530"><a href="#cb50-530" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>It is often surprising how small "large" can be</span>
<span id="cb50-531"><a href="#cb50-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-532"><a href="#cb50-532" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Definition of large depends on the error distribution and relative sample sizes within each group</span>
<span id="cb50-533"><a href="#cb50-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-534"><a href="#cb50-534" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>With exactly Normally distributed errors, only need one observation (or two to estimate a slope)</span>
<span id="cb50-535"><a href="#cb50-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-536"><a href="#cb50-536" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>With very heavy tails, "large" can be very large</span>
<span id="cb50-537"><a href="#cb50-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-538"><a href="#cb50-538" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>See Lumley, et al., Ann Rev Pub Hlth, 2002</span>
<span id="cb50-539"><a href="#cb50-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-540"><a href="#cb50-540" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assumption 2: Independence of observations</span>
<span id="cb50-541"><a href="#cb50-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-542"><a href="#cb50-542" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Classic regression: Independence of all observation (now)</span>
<span id="cb50-543"><a href="#cb50-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-544"><a href="#cb50-544" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard errors: Correlated observations within identified clusters (later)</span>
<span id="cb50-545"><a href="#cb50-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-546"><a href="#cb50-546" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assumption 3: Assumption about the variance of observations within groups</span>
<span id="cb50-547"><a href="#cb50-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-548"><a href="#cb50-548" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Classic regression: Homoscedasticity (equal variance across groups)</span>
<span id="cb50-549"><a href="#cb50-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-550"><a href="#cb50-550" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard errors: Allows for unequal variance across groups</span>
<span id="cb50-551"><a href="#cb50-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-552"><a href="#cb50-552" aria-hidden="true" tabindex="-1"></a><span class="fu">### Additional Assumptions for Additional Inference</span></span>
<span id="cb50-553"><a href="#cb50-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-554"><a href="#cb50-554" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note that some textbooks will claim there are more than three assumptions. In truth, additional assumptions are not needed to make the aforementioned statistical inference about *associations*. However ...</span>
<span id="cb50-555"><a href="#cb50-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-556"><a href="#cb50-556" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Valid statistical inference (CIs, p-values) about *mean responses in specific groups* requires a further assumption</span>
<span id="cb50-557"><a href="#cb50-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-558"><a href="#cb50-558" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assumption 4: Adequacy of the linear model</span>
<span id="cb50-559"><a href="#cb50-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-560"><a href="#cb50-560" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If we are trying to borrow information about the mean from neighboring groups, and we are assuming a straight line relationship, the straight line needs to be true</span>
<span id="cb50-561"><a href="#cb50-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-562"><a href="#cb50-562" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>No longer saying there is just a linear trend in the means, but now need to believe that all the means lie on a straight line</span>
<span id="cb50-563"><a href="#cb50-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-564"><a href="#cb50-564" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Note that we can model transformations of the measured predictor</span>
<span id="cb50-565"><a href="#cb50-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-566"><a href="#cb50-566" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For inference about *individual observations* (prediction intervals, P-values) in specific groups requires another assumption</span>
<span id="cb50-567"><a href="#cb50-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-568"><a href="#cb50-568" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assumption 5: Assumptions about the distribution of the errors within each group (a very strong assumption)</span>
<span id="cb50-569"><a href="#cb50-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-570"><a href="#cb50-570" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Classically: Errors have the same Normal distribution within each grouping variable</span>
<span id="cb50-571"><a href="#cb50-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-572"><a href="#cb50-572" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard error will not help</span>
<span id="cb50-573"><a href="#cb50-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-574"><a href="#cb50-574" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Prediction intervals assume a common error distribution across groups (homoscedasticity)</span>
<span id="cb50-575"><a href="#cb50-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-576"><a href="#cb50-576" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Possible extension: Errors have the same distribution, but not necessarily Normal (rarely implemented in frequentist software)</span>
<span id="cb50-577"><a href="#cb50-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-578"><a href="#cb50-578" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Bootstrapping</span>
<span id="cb50-579"><a href="#cb50-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-580"><a href="#cb50-580" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Bayesian analysis</span>
<span id="cb50-581"><a href="#cb50-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-582"><a href="#cb50-582" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Other flexible approaches</span>
<span id="cb50-583"><a href="#cb50-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-584"><a href="#cb50-584" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scenario 1: All model assumptions hold</span></span>
<span id="cb50-585"><a href="#cb50-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-588"><a href="#cb50-588" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-589"><a href="#cb50-589" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-true</span></span>
<span id="cb50-590"><a href="#cb50-590" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Scatterplot with best fit line where assumptions of Normality, linearity, homoskedasticity all hold</span></span>
<span id="cb50-591"><a href="#cb50-591" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb50-592"><a href="#cb50-592" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb50-593"><a href="#cb50-593" aria-hidden="true" tabindex="-1"></a>regassumptions <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>, <span class="at">to=</span><span class="dv">100</span>, <span class="at">length=</span>n))</span>
<span id="cb50-594"><a href="#cb50-594" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, Normal errors</span></span>
<span id="cb50-595"><a href="#cb50-595" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y1 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb50-596"><a href="#cb50-596" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, Skewed errors</span></span>
<span id="cb50-597"><a href="#cb50-597" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y2 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rlnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb50-598"><a href="#cb50-598" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model correct, errors increasing with predictor (so increasing with Y too)</span></span>
<span id="cb50-599"><a href="#cb50-599" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y3 <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span><span class="sc">+</span>regassumptions<span class="sc">$</span>x<span class="sc">*</span>.<span class="dv">1</span>)</span>
<span id="cb50-600"><a href="#cb50-600" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model incorrect, Normal error</span></span>
<span id="cb50-601"><a href="#cb50-601" aria-hidden="true" tabindex="-1"></a>regassumptions<span class="sc">$</span>y4<span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.2</span><span class="sc">*</span>regassumptions<span class="sc">$</span>x <span class="sc">+</span> <span class="fl">0.02</span><span class="sc">*</span>(regassumptions<span class="sc">$</span>x)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb50-602"><a href="#cb50-602" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y1)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span>
<span id="cb50-603"><a href="#cb50-603" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-604"><a href="#cb50-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-607"><a href="#cb50-607" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-608"><a href="#cb50-608" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-true-diag</span></span>
<span id="cb50-609"><a href="#cb50-609" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Diagnostic plots where assumptions of Normality, linearity, homoskedasticity all hold</span></span>
<span id="cb50-610"><a href="#cb50-610" aria-hidden="true" tabindex="-1"></a>model.y1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y1 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb50-611"><a href="#cb50-611" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y1)</span>
<span id="cb50-612"><a href="#cb50-612" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-613"><a href="#cb50-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-614"><a href="#cb50-614" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can estimate the mean of Y at a given value of X</span>
<span id="cb50-615"><a href="#cb50-615" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can make inference about the association between X and Y (based on the slope)</span>
<span id="cb50-616"><a href="#cb50-616" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can predict new values of Y given X</span>
<span id="cb50-617"><a href="#cb50-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-618"><a href="#cb50-618" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scenario 2: Error distribution is not Normally distributed</span></span>
<span id="cb50-619"><a href="#cb50-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-622"><a href="#cb50-622" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-623"><a href="#cb50-623" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-error-distribution</span></span>
<span id="cb50-624"><a href="#cb50-624" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Scatterplot with best fit line where the error distribution is skewed to the right</span></span>
<span id="cb50-625"><a href="#cb50-625" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y2)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span>
<span id="cb50-626"><a href="#cb50-626" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-627"><a href="#cb50-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-630"><a href="#cb50-630" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-631"><a href="#cb50-631" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-error-distribution-diag</span></span>
<span id="cb50-632"><a href="#cb50-632" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Diagnostic plots where the error distribution is skewed to the right</span></span>
<span id="cb50-633"><a href="#cb50-633" aria-hidden="true" tabindex="-1"></a>model.y2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb50-634"><a href="#cb50-634" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y2)</span>
<span id="cb50-635"><a href="#cb50-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-636"><a href="#cb50-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-637"><a href="#cb50-637" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the sample size is large enough, we can estimate the mean of Y at a given value of X (Central Limit Theorem)</span>
<span id="cb50-638"><a href="#cb50-638" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If we use "robust" standard errors, we can make inference about the association between X and Y (based on the slope)</span>
<span id="cb50-639"><a href="#cb50-639" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard error relax the assumption of homoskedasticity/common variance</span>
<span id="cb50-640"><a href="#cb50-640" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We *cannot* predict new values of Y given X. This requires the correct error distribution.</span>
<span id="cb50-641"><a href="#cb50-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-642"><a href="#cb50-642" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scenario 3: Variance increasing with predictor and expected value of Y (heteroskedasticity)</span></span>
<span id="cb50-643"><a href="#cb50-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-646"><a href="#cb50-646" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-647"><a href="#cb50-647" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-heteroskedasticity</span></span>
<span id="cb50-648"><a href="#cb50-648" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Scatterplot with best fit line where the error distribution variance is increasing</span></span>
<span id="cb50-649"><a href="#cb50-649" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y3)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span>
<span id="cb50-650"><a href="#cb50-650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-651"><a href="#cb50-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-654"><a href="#cb50-654" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-655"><a href="#cb50-655" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-heteroskedasticity-diag</span></span>
<span id="cb50-656"><a href="#cb50-656" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Diagnostic plot where the error distribution variance is increasing</span></span>
<span id="cb50-657"><a href="#cb50-657" aria-hidden="true" tabindex="-1"></a>model.y3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb50-658"><a href="#cb50-658" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y3)</span>
<span id="cb50-659"><a href="#cb50-659" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-660"><a href="#cb50-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-661"><a href="#cb50-661" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the sample size is large enough, we can estimate the mean of Y at a given value of X (Central Limit Theorem)</span>
<span id="cb50-662"><a href="#cb50-662" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If we use "robust" standard errors, we can make inference about the association between X and Y (based on the slope)</span>
<span id="cb50-663"><a href="#cb50-663" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard error relax the assumption of homoskedasticity/common variance</span>
<span id="cb50-664"><a href="#cb50-664" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We *cannot* predict new values of Y given X. This requires the correct error distribution (and mean model, but that is correct)</span>
<span id="cb50-665"><a href="#cb50-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-666"><a href="#cb50-666" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scenario 4: Mean model incorrectly specified</span></span>
<span id="cb50-667"><a href="#cb50-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-670"><a href="#cb50-670" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-671"><a href="#cb50-671" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-mean-incorrect</span></span>
<span id="cb50-672"><a href="#cb50-672" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Scatterplot with best fit line where the mean model is not correctly specified</span></span>
<span id="cb50-673"><a href="#cb50-673" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(regassumptions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y4)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)</span>
<span id="cb50-674"><a href="#cb50-674" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-675"><a href="#cb50-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-678"><a href="#cb50-678" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-679"><a href="#cb50-679" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-assumptions-mean-incorrect-diag</span></span>
<span id="cb50-680"><a href="#cb50-680" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Diagnostic plots where the mean model is not correctly specified</span></span>
<span id="cb50-681"><a href="#cb50-681" aria-hidden="true" tabindex="-1"></a>model.y4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y4 <span class="sc">~</span> x, <span class="at">data =</span> regassumptions)</span>
<span id="cb50-682"><a href="#cb50-682" aria-hidden="true" tabindex="-1"></a><span class="fu">gglm</span>(model.y4)</span>
<span id="cb50-683"><a href="#cb50-683" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-684"><a href="#cb50-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-685"><a href="#cb50-685" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Because our model is wrong, we *cannot* estimate the mean of Y at a given value of X. It will be biased, even if the sample size is large, the model will still be incorrect</span>
<span id="cb50-686"><a href="#cb50-686" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The good news is that we can fix our mean model to more flexibly model the association.</span>
<span id="cb50-687"><a href="#cb50-687" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Here, we have just included a single slope term to model the association with $X$, $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span> = \beta_0 + \beta_1*X$.</span>
<span id="cb50-688"><a href="#cb50-688" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The correct model in this simple example is $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span> = \beta_0 + \beta_1*X + \beta_2*X^2$. Note that this model is still a "linear model". A "linear model" is linear *in the parameters* ($\beta_0$, $\beta_1$, $\beta_2$). We can included the quadratic predictor $X^2$ in the model and still have a model that is linear in the parameters.</span>
<span id="cb50-689"><a href="#cb50-689" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If we use "robust" standard errors, we can make inference about the association between X and Y (based on the slope, $\beta_1$)</span>
<span id="cb50-690"><a href="#cb50-690" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard error relax the assumption of homoskedasticity</span>
<span id="cb50-691"><a href="#cb50-691" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>While the model is not a great fit, $\beta_1$ may summarize a first-order trend</span>
<span id="cb50-692"><a href="#cb50-692" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We *cannot* predict new values of Y given X. This requires the correct mean model and error distribution.</span>
<span id="cb50-693"><a href="#cb50-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-694"><a href="#cb50-694" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Summary</span></span>
<span id="cb50-695"><a href="#cb50-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-696"><a href="#cb50-696" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Regression based inference about *associations* is far more trustworthy than estimation of group means or individual predictions.</span>
<span id="cb50-697"><a href="#cb50-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-698"><a href="#cb50-698" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There is much to be gained by using robust variance estimates</span>
<span id="cb50-699"><a href="#cb50-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-700"><a href="#cb50-700" aria-hidden="true" tabindex="-1"></a>::: {#tbl-panel layout-ncol="2"}</span>
<span id="cb50-701"><a href="#cb50-701" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Linearity <span class="pp">|</span> Homoskedasticity <span class="pp">|</span> Normality <span class="pp">|</span></span>
<span id="cb50-702"><a href="#cb50-702" aria-hidden="true" tabindex="-1"></a><span class="pp">|-----------|------------------|-----------|</span></span>
<span id="cb50-703"><a href="#cb50-703" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y         <span class="pp">|</span> Y                <span class="pp">|</span> Y         <span class="pp">|</span></span>
<span id="cb50-704"><a href="#cb50-704" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y         <span class="pp">|</span> Y                <span class="pp">|</span> N         <span class="pp">|</span></span>
<span id="cb50-705"><a href="#cb50-705" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y         <span class="pp">|</span> N                <span class="pp">|</span> Y         <span class="pp">|</span></span>
<span id="cb50-706"><a href="#cb50-706" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y         <span class="pp">|</span> N                <span class="pp">|</span> N         <span class="pp">|</span></span>
<span id="cb50-707"><a href="#cb50-707" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> N         <span class="pp">|</span> Y                <span class="pp">|</span> Y         <span class="pp">|</span></span>
<span id="cb50-708"><a href="#cb50-708" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> N         <span class="pp">|</span> Y                <span class="pp">|</span> N         <span class="pp">|</span></span>
<span id="cb50-709"><a href="#cb50-709" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> N         <span class="pp">|</span> N                <span class="pp">|</span> Y         <span class="pp">|</span></span>
<span id="cb50-710"><a href="#cb50-710" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> N         <span class="pp">|</span> N                <span class="pp">|</span> N         <span class="pp">|</span></span>
<span id="cb50-711"><a href="#cb50-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-712"><a href="#cb50-712" aria-hidden="true" tabindex="-1"></a>: Assumption Holds (Yes/No)</span>
<span id="cb50-713"><a href="#cb50-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-714"><a href="#cb50-714" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\hat{\beta}$ <span class="pp">|</span> $\hat{\textrm {Var}}_{NR}(\hat{\beta})$ <span class="pp">|</span> $\hat{\textrm{ Var}}_R(\hat{\beta})$ <span class="pp">|</span></span>
<span id="cb50-715"><a href="#cb50-715" aria-hidden="true" tabindex="-1"></a><span class="pp">|----|----|----|</span></span>
<span id="cb50-716"><a href="#cb50-716" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y <span class="pp">|</span> Y <span class="pp">|</span> Y <span class="pp">|</span></span>
<span id="cb50-717"><a href="#cb50-717" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y <span class="pp">|</span> M^2^ <span class="pp">|</span> M^2^ <span class="pp">|</span></span>
<span id="cb50-718"><a href="#cb50-718" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y <span class="pp">|</span> N <span class="pp">|</span> Y <span class="pp">|</span></span>
<span id="cb50-719"><a href="#cb50-719" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Y <span class="pp">|</span> N <span class="pp">|</span> M^2^ <span class="pp">|</span></span>
<span id="cb50-720"><a href="#cb50-720" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> M^1^ <span class="pp">|</span> N <span class="pp">|</span> M^3^ <span class="pp">|</span></span>
<span id="cb50-721"><a href="#cb50-721" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> M^1^ <span class="pp">|</span> N <span class="pp">|</span> M^2,3^ <span class="pp">|</span></span>
<span id="cb50-722"><a href="#cb50-722" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> M^1^ <span class="pp">|</span> N <span class="pp">|</span> M^2^ <span class="pp">|</span></span>
<span id="cb50-723"><a href="#cb50-723" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> M^1^ <span class="pp">|</span> N <span class="pp">|</span> M^2,3^ <span class="pp">|</span></span>
<span id="cb50-724"><a href="#cb50-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-725"><a href="#cb50-725" aria-hidden="true" tabindex="-1"></a>: Valid Inference (Yes/No/Maybe)</span>
<span id="cb50-726"><a href="#cb50-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-727"><a href="#cb50-727" aria-hidden="true" tabindex="-1"></a>Summary of what is required for valid estimates of $\beta$ and the variance of beta using the classical, non-robust (NR) and robust (R) approaches. The classic (non-robust) variance is $\hat{\textrm{Var}}_{NR}(\hat{\beta})$ and the robust variance is $\hat{\textrm{Var}}_R(\hat{\beta})$</span>
<span id="cb50-728"><a href="#cb50-728" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb50-729"><a href="#cb50-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-730"><a href="#cb50-730" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>^1^ First-order trend, if appropriate</span>
<span id="cb50-731"><a href="#cb50-731" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>^2^ Approximately valid under large sample sizes</span>
<span id="cb50-732"><a href="#cb50-732" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>^3^ If $X$ is random, but not if $X$ is fixed</span>
<span id="cb50-733"><a href="#cb50-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-734"><a href="#cb50-734" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpreting "Positive" Results</span></span>
<span id="cb50-735"><a href="#cb50-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-736"><a href="#cb50-736" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Slope is statistically different from 0 using robust standard errors</span>
<span id="cb50-737"><a href="#cb50-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-738"><a href="#cb50-738" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Observed data is atypical of a setting with no linear trend in mean response across groups</span>
<span id="cb50-739"><a href="#cb50-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-740"><a href="#cb50-740" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Data suggests evidence of a trend toward larger (or smaller) means in groups having larger values of the predictor</span>
<span id="cb50-741"><a href="#cb50-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-742"><a href="#cb50-742" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>(To the extent the data appears linear, estimates of the group means will be reliable)</span>
<span id="cb50-743"><a href="#cb50-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-744"><a href="#cb50-744" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpreting "Negative" Results</span></span>
<span id="cb50-745"><a href="#cb50-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-746"><a href="#cb50-746" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Many possible reasons why the slope is not statistically different from 0 using robust standard errors</span>
<span id="cb50-747"><a href="#cb50-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-748"><a href="#cb50-748" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There may be no association between the response and predictor</span>
<span id="cb50-749"><a href="#cb50-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-750"><a href="#cb50-750" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There may be an association, but not in the parameter considered (the mean response)</span>
<span id="cb50-751"><a href="#cb50-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-752"><a href="#cb50-752" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There may be an association in the parameter considered, but the best fitting line has zero slope</span>
<span id="cb50-753"><a href="#cb50-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-754"><a href="#cb50-754" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There may be a first order trend in the parameter considered, but we lacked the precision to be confident that it truly exists (a type II error)</span>
<span id="cb50-755"><a href="#cb50-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-756"><a href="#cb50-756" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Checking</span></span>
<span id="cb50-757"><a href="#cb50-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-758"><a href="#cb50-758" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Much statistical literature has been devoted to methods for checking the assumptions for regression models</span>
<span id="cb50-759"><a href="#cb50-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-760"><a href="#cb50-760" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>My philosophy: Model checking is generally fraught with peril as it necessarily involves multiple comparisons</span>
<span id="cb50-761"><a href="#cb50-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-762"><a href="#cb50-762" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We cannot reliably use the sampled data to assess whether it accurately portrays the population</span>
<span id="cb50-763"><a href="#cb50-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-764"><a href="#cb50-764" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We are more worried about the data from the population that we might not have sampled</span>
<span id="cb50-765"><a href="#cb50-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-766"><a href="#cb50-766" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>It is not so much the abnormal points that we see, but the ones that are hiding in the population that will make our model perform badly</span>
<span id="cb50-767"><a href="#cb50-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-768"><a href="#cb50-768" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>But, do tend to worry more when we see a tendency to extreme outliers in the sample or clear departures from model assumptions</span>
<span id="cb50-769"><a href="#cb50-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-770"><a href="#cb50-770" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If we over-check our model and make adjustments to the model based on our observed data, we will inflate the type I error rate (i.e. will be more likely to claim statistical significance when it doesn't really exist). We run the risk of creating a model that fits our data well but does not generalize.</span>
<span id="cb50-771"><a href="#cb50-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-772"><a href="#cb50-772" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Estimates are biased away from the null</span>
<span id="cb50-773"><a href="#cb50-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-774"><a href="#cb50-774" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Reported standard errors are too small</span>
<span id="cb50-775"><a href="#cb50-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-776"><a href="#cb50-776" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>If we fish through the data, we will always find significant results</span>
<span id="cb50-777"><a href="#cb50-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-778"><a href="#cb50-778" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>In clinical trials, often Phase II results are not able to be replicated in Phase III trials</span>
<span id="cb50-779"><a href="#cb50-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-780"><a href="#cb50-780" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Instead of extensive model checking, go back to our choices of inference when planning our analysis</span>
<span id="cb50-781"><a href="#cb50-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-782"><a href="#cb50-782" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Best to plan for unusual data</span>
<span id="cb50-783"><a href="#cb50-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-784"><a href="#cb50-784" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>There is often little to be lost and much to be gained by using the robust standard error estimates</span>
<span id="cb50-785"><a href="#cb50-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-786"><a href="#cb50-786" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>By using robust errors, avoids much of the need for model checking</span>
<span id="cb50-787"><a href="#cb50-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-788"><a href="#cb50-788" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Model checking is almost entirely data driven</span>
<span id="cb50-789"><a href="#cb50-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-790"><a href="#cb50-790" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Robust standard errors is a more logical scientific approach</span>
<span id="cb50-791"><a href="#cb50-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-792"><a href="#cb50-792" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Minimize the need to presume more knowledge than the question we are trying to answer</span>
<span id="cb50-793"><a href="#cb50-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-794"><a href="#cb50-794" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>E.g., if we don't know how the means might differ, why should we presume to know how the variances or the shape of the distribution might behave?</span>
<span id="cb50-795"><a href="#cb50-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-796"><a href="#cb50-796" aria-hidden="true" tabindex="-1"></a><span class="fu">### Residuals versus fitted values</span></span>
<span id="cb50-797"><a href="#cb50-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-798"><a href="#cb50-798" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Plot of $\hat{\epsilon_i}$ versus $\hat{y_i}$</span>
<span id="cb50-799"><a href="#cb50-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-800"><a href="#cb50-800" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If assumptions hold, should be a random pattern about zero. See @fig-assumptions-true-diag for example.</span>
<span id="cb50-801"><a href="#cb50-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-802"><a href="#cb50-802" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If you have *a priori* concerns about non-constant variance, this is one potential check</span>
<span id="cb50-803"><a href="#cb50-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-804"><a href="#cb50-804" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>E.g., it is fairly common for uncertainty to increase with outcome. See @fig-assumptions-heteroskedasticity-diag for the resulting "fan" pattern that would appear</span>
<span id="cb50-805"><a href="#cb50-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-806"><a href="#cb50-806" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scale-location plot</span></span>
<span id="cb50-807"><a href="#cb50-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-808"><a href="#cb50-808" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The scale-location plot is very similar to residuals vs fitted values, and is used to evaluate the homoskedasticity assumption</span>
<span id="cb50-809"><a href="#cb50-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-810"><a href="#cb50-810" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It uses the square root of the absolute value of standardized residuals instead of plotting the residuals themselves</span>
<span id="cb50-811"><a href="#cb50-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-812"><a href="#cb50-812" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We want to check two things</span>
<span id="cb50-813"><a href="#cb50-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-814"><a href="#cb50-814" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>That the best fit line is approximately horizontal. If it is, then the average magnitude of the standardized residuals isn't changing much as a function of the fitted values.</span>
<span id="cb50-815"><a href="#cb50-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-816"><a href="#cb50-816" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>That the spread around the fit line doesn't vary with the fitted values. If so, then the variability of magnitudes doesn't vary much as a function of the fitted values.</span>
<span id="cb50-817"><a href="#cb50-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-818"><a href="#cb50-818" aria-hidden="true" tabindex="-1"></a><span class="fu">### QQ plot</span></span>
<span id="cb50-819"><a href="#cb50-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-820"><a href="#cb50-820" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Used to evaluate Normality of the residuals</span>
<span id="cb50-821"><a href="#cb50-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-822"><a href="#cb50-822" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If assumptions hold, points should lie on a 1:1 line</span>
<span id="cb50-823"><a href="#cb50-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-824"><a href="#cb50-824" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Plot of standardized residuals versus theoretical quantities from a N(0,1) distribution</span>
<span id="cb50-825"><a href="#cb50-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-826"><a href="#cb50-826" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If assumptions hold, the standardized residuals should be a random sample from a N(0,1) distribution</span>
<span id="cb50-827"><a href="#cb50-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-828"><a href="#cb50-828" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We can use quantiles of the Normal distribution to check how closely the observed matches the expected</span>
<span id="cb50-829"><a href="#cb50-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-830"><a href="#cb50-830" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The 50th percentile of the residuals should be <span class="in">`r round(qnorm(.5,0,1),2)`</span></span>
<span id="cb50-831"><a href="#cb50-831" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The 75th percentile of the residuals should be <span class="in">`r round(qnorm(.75,0,1),2)`</span></span>
<span id="cb50-832"><a href="#cb50-832" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The 90th percentile of the residuals should be <span class="in">`r round(qnorm(.90,0,1),2)`</span></span>
<span id="cb50-833"><a href="#cb50-833" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The 95th percentile of the residuals should be <span class="in">`r round(qnorm(.95,0,1),2)`</span></span>
<span id="cb50-834"><a href="#cb50-834" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The 97.5th percentil of the residuals should be <span class="in">`r round(qnorm(.975,0,1),2)`</span></span>
<span id="cb50-835"><a href="#cb50-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-836"><a href="#cb50-836" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Similar idea would be a histogram or density plot of the (standardized) residuals that could be visually evaluated for Normality</span>
<span id="cb50-837"><a href="#cb50-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-838"><a href="#cb50-838" aria-hidden="true" tabindex="-1"></a><span class="fu">### Residuals versus leverage</span></span>
<span id="cb50-839"><a href="#cb50-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-840"><a href="#cb50-840" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Used to check for outliers</span>
<span id="cb50-841"><a href="#cb50-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-842"><a href="#cb50-842" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Plot can help us to identify influential observations, if there are any</span>
<span id="cb50-843"><a href="#cb50-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-844"><a href="#cb50-844" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Influence differs from leverage. Not all outliers influence the regression coefficient estimates</span>
<span id="cb50-845"><a href="#cb50-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-846"><a href="#cb50-846" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear Regression with Robust Standard Error estimates</span></span>
<span id="cb50-847"><a href="#cb50-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-848"><a href="#cb50-848" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There are several libraries available in R for fitting models with robust error estimates</span>
<span id="cb50-849"><a href="#cb50-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-850"><a href="#cb50-850" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There are also several different flavors of robust estimators</span>
<span id="cb50-851"><a href="#cb50-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-852"><a href="#cb50-852" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>For now, we are going to consider the default "Huber-White sandwich estimator"</span>
<span id="cb50-853"><a href="#cb50-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-854"><a href="#cb50-854" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In Stata, the Huber-White robust estimate of the standard error can be obtained using the 'robust' option</span>
<span id="cb50-855"><a href="#cb50-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-856"><a href="#cb50-856" aria-hidden="true" tabindex="-1"></a>        <span class="in">``` stata</span></span>
<span id="cb50-857"><a href="#cb50-857" aria-hidden="true" tabindex="-1"></a><span class="in">        regress chol age, robust</span></span>
<span id="cb50-858"><a href="#cb50-858" aria-hidden="true" tabindex="-1"></a><span class="in">        ```</span></span>
<span id="cb50-859"><a href="#cb50-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-860"><a href="#cb50-860" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In the following examples I provide estimates using classical linear regression and linear regression estimate using robust standard errors. For each of these example compare</span>
<span id="cb50-861"><a href="#cb50-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-862"><a href="#cb50-862" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimates of the intercept, $\hat{\beta_0}$</span>
<span id="cb50-863"><a href="#cb50-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-864"><a href="#cb50-864" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimates of the slope, $\hat{\beta_1}$</span>
<span id="cb50-865"><a href="#cb50-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-866"><a href="#cb50-866" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Estimates of the standard errors, $\hat{\textrm{se}}(\hat{\beta_0})$ and $\hat{\textrm{se}}(\hat{\beta_1})$</span>
<span id="cb50-867"><a href="#cb50-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-868"><a href="#cb50-868" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison when Normality, constant variance holds</span></span>
<span id="cb50-869"><a href="#cb50-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-870"><a href="#cb50-870" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Age and Cholesterol</span></span>
<span id="cb50-871"><a href="#cb50-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-874"><a href="#cb50-874" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-875"><a href="#cb50-875" aria-hidden="true" tabindex="-1"></a>fit.ols <span class="ot">&lt;-</span> <span class="fu">ols</span>(chol <span class="sc">~</span> age, <span class="at">data=</span>plotdata, <span class="at">x=</span><span class="cn">TRUE</span>)</span>
<span id="cb50-876"><a href="#cb50-876" aria-hidden="true" tabindex="-1"></a>fit.ols</span>
<span id="cb50-877"><a href="#cb50-877" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-878"><a href="#cb50-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-881"><a href="#cb50-881" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-882"><a href="#cb50-882" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(fit.ols)</span>
<span id="cb50-883"><a href="#cb50-883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-884"><a href="#cb50-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-885"><a href="#cb50-885" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scenario 1 dataset</span></span>
<span id="cb50-886"><a href="#cb50-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-889"><a href="#cb50-889" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-890"><a href="#cb50-890" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y1 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span>
<span id="cb50-891"><a href="#cb50-891" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y1 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span>
<span id="cb50-892"><a href="#cb50-892" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-893"><a href="#cb50-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-894"><a href="#cb50-894" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison when variance is increasing with predictor (Scenario 3)</span></span>
<span id="cb50-895"><a href="#cb50-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-898"><a href="#cb50-898" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-899"><a href="#cb50-899" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y3 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span>
<span id="cb50-900"><a href="#cb50-900" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y3 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span>
<span id="cb50-901"><a href="#cb50-901" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-902"><a href="#cb50-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-903"><a href="#cb50-903" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison when error variance is skewed to the right (Scenario 2)</span></span>
<span id="cb50-904"><a href="#cb50-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-907"><a href="#cb50-907" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-908"><a href="#cb50-908" aria-hidden="true" tabindex="-1"></a><span class="fu">ols</span>(y2 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>)</span>
<span id="cb50-909"><a href="#cb50-909" aria-hidden="true" tabindex="-1"></a><span class="fu">robcov</span>(<span class="fu">ols</span>(y2 <span class="sc">~</span> x, <span class="at">data=</span>regassumptions, <span class="at">x=</span><span class="cn">TRUE</span>))</span>
<span id="cb50-910"><a href="#cb50-910" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-911"><a href="#cb50-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-912"><a href="#cb50-912" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comments</span></span>
<span id="cb50-913"><a href="#cb50-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-914"><a href="#cb50-914" aria-hidden="true" tabindex="-1"></a>\newcommand\seb0{{\hat{\textrm{se}}(\hat{\beta_0})}}</span>
<span id="cb50-915"><a href="#cb50-915" aria-hidden="true" tabindex="-1"></a>\newcommand\seb1{\hat{\textrm{se}}(\hat{\beta_1})}</span>
<span id="cb50-916"><a href="#cb50-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-917"><a href="#cb50-917" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Model <span class="pp">|</span> Classical Intercept <span class="pp">|</span> Robust Intercept <span class="pp">|</span> Classical Slope <span class="pp">|</span> Robust Slope <span class="pp">|</span></span>
<span id="cb50-918"><a href="#cb50-918" aria-hidden="true" tabindex="-1"></a><span class="pp">|----|----|----|----|----|</span></span>
<span id="cb50-919"><a href="#cb50-919" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Age-chol All Assump. hold <span class="pp">|</span> 203.2 <span class="pp">|</span> 203.2 <span class="pp">|</span> 0.32 <span class="pp">|</span> 0.32 <span class="pp">|</span></span>
<span id="cb50-920"><a href="#cb50-920" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 1 Assump hold <span class="pp">|</span> 3.34 <span class="pp">|</span> 3.34 <span class="pp">|</span> 0.23 <span class="pp">|</span> 0.23 <span class="pp">|</span></span>
<span id="cb50-921"><a href="#cb50-921" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 3 Increase Variance <span class="pp">|</span> 5.66 <span class="pp">|</span> 5.66 <span class="pp">|</span> 0.18 <span class="pp">|</span> 0.18 <span class="pp">|</span></span>
<span id="cb50-922"><a href="#cb50-922" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 2 Skewed Variance <span class="pp">|</span> 6.93 <span class="pp">|</span> 6.93 <span class="pp">|</span> 0.20 <span class="pp">|</span> 0.20 <span class="pp">|</span></span>
<span id="cb50-923"><a href="#cb50-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-924"><a href="#cb50-924" aria-hidden="true" tabindex="-1"></a>: Comparison of point estimates, $\hat{\beta_0}$ and $\hat{\beta_1}$</span>
<span id="cb50-925"><a href="#cb50-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-926"><a href="#cb50-926" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Model <span class="pp">|</span> Classical Intercept <span class="pp">|</span> Robust Intercept <span class="pp">|</span> Classical Slope <span class="pp">|</span> Robust Slope <span class="pp">|</span></span>
<span id="cb50-927"><a href="#cb50-927" aria-hidden="true" tabindex="-1"></a><span class="pp">|----|----|----|----|----|</span></span>
<span id="cb50-928"><a href="#cb50-928" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Age-chol All Assump. hold <span class="pp">|</span> 10.31 <span class="pp">|</span> 10.38 <span class="pp">|</span> 0.137 <span class="pp">|</span> 0.138 <span class="pp">|</span></span>
<span id="cb50-929"><a href="#cb50-929" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 1 Assump hold <span class="pp">|</span> 0.712 <span class="pp">|</span> 0.700 <span class="pp">|</span> 0.0123 <span class="pp">|</span> 0.0132 <span class="pp">|</span></span>
<span id="cb50-930"><a href="#cb50-930" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 3 Increase Variance <span class="pp">|</span> 0.919 <span class="pp">|</span> 0.596 <span class="pp">|</span> 0.0159 <span class="pp">|</span> 0.0153 <span class="pp">|</span></span>
<span id="cb50-931"><a href="#cb50-931" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Scenario 2 Skewed Variance <span class="pp">|</span> 0.291 <span class="pp">|</span> 0.353 <span class="pp">|</span> 0.00503 <span class="pp">|</span> 0.00557 <span class="pp">|</span></span>
<span id="cb50-932"><a href="#cb50-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-933"><a href="#cb50-933" aria-hidden="true" tabindex="-1"></a>: Comparison of standard error estimates, $\hat{\textrm{se}}(\hat{\beta_0})$ and $\hat{\textrm{se}}(\hat{\beta_1})$</span>
<span id="cb50-934"><a href="#cb50-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-935"><a href="#cb50-935" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Point estimates $\hat{\beta_0}$ and $\hat{\beta_1}$ were the same for robust and classical standard error</span>
<span id="cb50-936"><a href="#cb50-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-937"><a href="#cb50-937" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Point estimates $\hat{\textrm{se}}(\hat{\beta_0})$ and $\hat{\textrm{se}}(\hat{\beta_1})$ were different for robust and classical standard error</span>
<span id="cb50-938"><a href="#cb50-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-939"><a href="#cb50-939" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In general, it is hard to predict the effect of using robust standard errors</span>
<span id="cb50-940"><a href="#cb50-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-941"><a href="#cb50-941" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>These were just a a couple of examples and do not constitute a thorough examination of the impact of using robust standard errors</span>
<span id="cb50-942"><a href="#cb50-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-943"><a href="#cb50-943" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>When the model assumptions hold, for these two scenarios, robust standard error estimates were larger than classical standard error estimates</span>
<span id="cb50-944"><a href="#cb50-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-945"><a href="#cb50-945" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>While this is not unexpected, to formally evaluate the amount of increase would require a statistical simulation</span>
<span id="cb50-946"><a href="#cb50-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-947"><a href="#cb50-947" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Simulate many datasets where the Normality and constant variance assumption holds</span>
<span id="cb50-948"><a href="#cb50-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-949"><a href="#cb50-949" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>For each dataset, estimate $\hat{\textrm{se}}(\hat{\beta_0})$ and $\hat{\textrm{se}}(\hat{\beta_1})$</span>
<span id="cb50-950"><a href="#cb50-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-951"><a href="#cb50-951" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Summarize the results</span>
<span id="cb50-952"><a href="#cb50-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-953"><a href="#cb50-953" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Approach will be covered in a future lab</span>
<span id="cb50-954"><a href="#cb50-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-955"><a href="#cb50-955" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear Regression and Correlation</span></span>
<span id="cb50-956"><a href="#cb50-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-957"><a href="#cb50-957" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pearson's Correlation</span></span>
<span id="cb50-958"><a href="#cb50-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-959"><a href="#cb50-959" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Notation</span>
<span id="cb50-960"><a href="#cb50-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-961"><a href="#cb50-961" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\rho$ signifies the population value</span>
<span id="cb50-962"><a href="#cb50-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-963"><a href="#cb50-963" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$r$ (or $\hat{\rho}$) is the estimated correlation from data</span>
<span id="cb50-964"><a href="#cb50-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-965"><a href="#cb50-965" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Formula</span>
<span id="cb50-966"><a href="#cb50-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-967"><a href="#cb50-967" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$r = \frac{\Sigma(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\Sigma(x_i - \bar{x})^2\Sigma(y_i - \bar{y})^2}}$</span>
<span id="cb50-968"><a href="#cb50-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-969"><a href="#cb50-969" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Range: $-1 \leq r \leq 1$</span>
<span id="cb50-970"><a href="#cb50-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-971"><a href="#cb50-971" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation</span>
<span id="cb50-972"><a href="#cb50-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-973"><a href="#cb50-973" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Measures the linear relationship between $X$ and $Y$</span>
<span id="cb50-974"><a href="#cb50-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-975"><a href="#cb50-975" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Correlation coefficient is a unitless index of strength of association between two variables (+ = positive association, - = negative, 0 = no association)</span>
<span id="cb50-976"><a href="#cb50-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-977"><a href="#cb50-977" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Can test for significant association by testing whether the population correlation is zero t = which is identical to the $t$-test used to test whether the population $r$ is zero; $\textrm{d.f.} = n-2$</span>
<span id="cb50-978"><a href="#cb50-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-979"><a href="#cb50-979" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Use probability calculator for $t$ distribution to get a 2-tailed $P$-value</span>
<span id="cb50-980"><a href="#cb50-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-981"><a href="#cb50-981" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Confidence intervals for population $r$ calculated using Fisher's $Z$ transformation</span>
<span id="cb50-982"><a href="#cb50-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-983"><a href="#cb50-983" aria-hidden="true" tabindex="-1"></a>    $$Z = \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right)$$</span>
<span id="cb50-984"><a href="#cb50-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-985"><a href="#cb50-985" aria-hidden="true" tabindex="-1"></a><span class="in">    -   For large $n$, $Z$ follows a Normal distribution with standard error $\frac{1}{\sqrt{n-3}}$</span></span>
<span id="cb50-986"><a href="#cb50-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-987"><a href="#cb50-987" aria-hidden="true" tabindex="-1"></a><span class="in">    -   To calculate a confidence interval for $r$, first find the confidence interval for $Z$ then transform back to the $r$ scale</span></span>
<span id="cb50-988"><a href="#cb50-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-989"><a href="#cb50-989" aria-hidden="true" tabindex="-1"></a>$$\begin{aligned}</span>
<span id="cb50-990"><a href="#cb50-990" aria-hidden="true" tabindex="-1"></a> Z &amp; = &amp; \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) <span class="sc">\\</span></span>
<span id="cb50-991"><a href="#cb50-991" aria-hidden="true" tabindex="-1"></a> 2*Z &amp; = &amp; \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) <span class="sc">\\</span></span>
<span id="cb50-992"><a href="#cb50-992" aria-hidden="true" tabindex="-1"></a> \textrm{exp}(2*Z) &amp; = &amp; \left( \frac{1+r}{1-r} \right) <span class="sc">\\</span></span>
<span id="cb50-993"><a href="#cb50-993" aria-hidden="true" tabindex="-1"></a> \textrm{exp}(2*Z) * (1-r) &amp; = &amp; 1 + r <span class="sc">\\</span></span>
<span id="cb50-994"><a href="#cb50-994" aria-hidden="true" tabindex="-1"></a> \textrm{exp}(2*Z) - r * \textrm{exp}(2*Z) &amp; = &amp; 1 + r <span class="sc">\\</span></span>
<span id="cb50-995"><a href="#cb50-995" aria-hidden="true" tabindex="-1"></a> \textrm{exp}(2*Z) - 1 &amp; = &amp; r * \textrm{exp}(2*Z) + r <span class="sc">\\</span></span>
<span id="cb50-996"><a href="#cb50-996" aria-hidden="true" tabindex="-1"></a> \textrm{exp}(2*Z) - 1 &amp; = &amp; r \left(\textrm{exp}(2*Z) + 1\right) <span class="sc">\\</span></span>
<span id="cb50-997"><a href="#cb50-997" aria-hidden="true" tabindex="-1"></a> \frac{\textrm{exp}(2*Z) - 1}{\textrm{exp}(2*Z) + 1} &amp; = &amp; r <span class="sc">\\</span></span>
<span id="cb50-998"><a href="#cb50-998" aria-hidden="true" tabindex="-1"></a>\end{aligned}$$</span>
<span id="cb50-999"><a href="#cb50-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1000"><a href="#cb50-1000" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Example (Altman 89-90): Pearson's $r$ for a study investigating the association of basal metabolic rate with total energy expenditure was calculated to be $0.7283$ in a study of $13$ women. Derive a 95% confidence interval for $r$</span>
<span id="cb50-1001"><a href="#cb50-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1002"><a href="#cb50-1002" aria-hidden="true" tabindex="-1"></a>    $$Z = \frac{1}{2} \textrm{log}_\textrm{e} \left( \frac{1+r}{1-r} \right) = 0.9251$$</span>
<span id="cb50-1003"><a href="#cb50-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1004"><a href="#cb50-1004" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The lower limit of a 95% CI for $Z$ is given by $0.9251 + 1.96*\frac{1}{\sqrt{n-3}} = 0.3053$</span>
<span id="cb50-1005"><a href="#cb50-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1006"><a href="#cb50-1006" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The upper limit is $0.9251 + 1.96*\frac{1}{\sqrt{n-3}} = 1.545$</span>
<span id="cb50-1007"><a href="#cb50-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1008"><a href="#cb50-1008" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A 95% CI for the population correlation coefficient is given by transforming these limits from the $Z$ scale back to the $r$ scale.</span>
<span id="cb50-1009"><a href="#cb50-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1010"><a href="#cb50-1010" aria-hidden="true" tabindex="-1"></a>$$\frac{\textrm{exp}(2*0.3053) - 1}{\textrm{exp}(2*0.3053) + 1} \hspace{.5cm} \textrm{to} \hspace{.5cm}  \frac{\textrm{exp}(2*1.545) - 1}{\textrm{exp}(2*1.545) + 1}$$</span>
<span id="cb50-1011"><a href="#cb50-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1012"><a href="#cb50-1012" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Which gives a 95% CI from 0.30 to 0.91 for the population correlation</span>
<span id="cb50-1013"><a href="#cb50-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1016"><a href="#cb50-1016" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-1017"><a href="#cb50-1017" aria-hidden="true" tabindex="-1"></a>fisher.z <span class="ot">&lt;-</span> <span class="cf">function</span>(r) {.<span class="dv">5</span> <span class="sc">*</span> <span class="fu">log</span>((<span class="dv">1</span><span class="sc">+</span>r)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>r))}</span>
<span id="cb50-1018"><a href="#cb50-1018" aria-hidden="true" tabindex="-1"></a>fisher.z.inv <span class="ot">&lt;-</span> <span class="cf">function</span>(z) {(<span class="fu">exp</span>(<span class="dv">2</span><span class="sc">*</span>z)<span class="sc">-</span><span class="dv">1</span>) <span class="sc">/</span> (<span class="fu">exp</span>(<span class="dv">2</span><span class="sc">*</span>z)<span class="sc">+</span><span class="dv">1</span>)}</span>
<span id="cb50-1019"><a href="#cb50-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1020"><a href="#cb50-1020" aria-hidden="true" tabindex="-1"></a>fisher.z.se <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {<span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(n<span class="dv">-3</span>)}</span>
<span id="cb50-1021"><a href="#cb50-1021" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z.inv</span>(<span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)) <span class="co">#Should be original value</span></span>
<span id="cb50-1022"><a href="#cb50-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1023"><a href="#cb50-1023" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)</span>
<span id="cb50-1024"><a href="#cb50-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1025"><a href="#cb50-1025" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">-</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>)</span>
<span id="cb50-1026"><a href="#cb50-1026" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">+</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>)</span>
<span id="cb50-1027"><a href="#cb50-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1028"><a href="#cb50-1028" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.z.inv</span>(<span class="fu">fisher.z</span>(<span class="fl">0.7283</span>)<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.96</span>, <span class="fl">1.96</span>)<span class="sc">*</span><span class="fu">fisher.z.se</span>(<span class="dv">13</span>))</span>
<span id="cb50-1029"><a href="#cb50-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1030"><a href="#cb50-1030" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-1031"><a href="#cb50-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1032"><a href="#cb50-1032" aria-hidden="true" tabindex="-1"></a><span class="fu">### Relationship to regression</span></span>
<span id="cb50-1033"><a href="#cb50-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1034"><a href="#cb50-1034" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Pearson's correlation ($\rho$) is directly related to linear regression</span>
<span id="cb50-1035"><a href="#cb50-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1036"><a href="#cb50-1036" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Correlation treats $Y$ and $X$ symmetrically, but we can relate</span>
<span id="cb50-1037"><a href="#cb50-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1038"><a href="#cb50-1038" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span>$ as a function of $X$</span>
<span id="cb50-1039"><a href="#cb50-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1040"><a href="#cb50-1040" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span> = \beta_0 + \beta_1 X$</span>
<span id="cb50-1041"><a href="#cb50-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1042"><a href="#cb50-1042" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\beta_1 = \rho \frac{\sigma_Y}{\sigma_X}$</span>
<span id="cb50-1043"><a href="#cb50-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1044"><a href="#cb50-1044" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$E<span class="co">[</span><span class="ot">Y | X</span><span class="co">]</span>$: mean $Y$ withing groups having equal $X$</span>
<span id="cb50-1045"><a href="#cb50-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1046"><a href="#cb50-1046" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\beta_1$: difference in mean $Y$ per 1 unit difference in $X$</span>
<span id="cb50-1047"><a href="#cb50-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1048"><a href="#cb50-1048" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\rho$: true correlation between $Y$ and $X$</span>
<span id="cb50-1049"><a href="#cb50-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1050"><a href="#cb50-1050" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\sigma_Y$: standard deviation of $Y$</span>
<span id="cb50-1051"><a href="#cb50-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1052"><a href="#cb50-1052" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\sigma_X$: standard deviation of $X$</span>
<span id="cb50-1053"><a href="#cb50-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1054"><a href="#cb50-1054" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>More interpretable formulation of $\rho$</span>
<span id="cb50-1055"><a href="#cb50-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1056"><a href="#cb50-1056" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\rho \approx \beta \sqrt{\frac{\textrm{Var}(X)}{\beta^2\textrm{Var}(X) + \textrm{Var}(Y | X = x)}}$</span>
<span id="cb50-1057"><a href="#cb50-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1058"><a href="#cb50-1058" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\beta$: slope between $Y$ and $X$</span>
<span id="cb50-1059"><a href="#cb50-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1060"><a href="#cb50-1060" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\textrm{Var}(X)$: variance of $X$ in the sample</span>
<span id="cb50-1061"><a href="#cb50-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1062"><a href="#cb50-1062" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\textrm{Var}(Y | X = x)$: variance of $Y$ in groups having the same value of $X$ (the vertical spread of data)</span>
<span id="cb50-1063"><a href="#cb50-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1064"><a href="#cb50-1064" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Correlation tends to increase in absolute value as</span>
<span id="cb50-1065"><a href="#cb50-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1066"><a href="#cb50-1066" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The absolute value of the slope of the line increases</span>
<span id="cb50-1067"><a href="#cb50-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1068"><a href="#cb50-1068" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The variance of data decreases within groups that share a common value of $X$</span>
<span id="cb50-1069"><a href="#cb50-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1070"><a href="#cb50-1070" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The variance of $X$ increases</span>
<span id="cb50-1071"><a href="#cb50-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1072"><a href="#cb50-1072" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Scientific uses of correlation</span>
<span id="cb50-1073"><a href="#cb50-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1074"><a href="#cb50-1074" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The slope between $X$ and $Y$ is of scientific interest</span>
<span id="cb50-1075"><a href="#cb50-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1076"><a href="#cb50-1076" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The variance of $Y$ given $X=x$ is partly of scientific interest, but can also be impacted by restricting sampling to certain values of another variable</span>
<span id="cb50-1077"><a href="#cb50-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1078"><a href="#cb50-1078" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The variance of height given age is less if sampling just males than if sampling both sexes</span>
<span id="cb50-1079"><a href="#cb50-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1080"><a href="#cb50-1080" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>The variance of $X$ is often set by study design (which is often not of scientific interest)</span>
<span id="cb50-1081"><a href="#cb50-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1082"><a href="#cb50-1082" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Hypothesis tests for a nonzero correlation are exactly the same as a test for a nonzero slope in classical linear regression</span>
<span id="cb50-1083"><a href="#cb50-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1084"><a href="#cb50-1084" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The statistical significance of a given value of $\rho$ depends only on the sample size</span>
<span id="cb50-1085"><a href="#cb50-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1086"><a href="#cb50-1086" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Correlation is more of a statistical measure than a scientific measure</span>
<span id="cb50-1087"><a href="#cb50-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1088"><a href="#cb50-1088" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression on Geometric Means: Log transformations</span></span>
<span id="cb50-1089"><a href="#cb50-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1090"><a href="#cb50-1090" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Geometric means of distributions are typically analyzed by using linear regression on the log transformed outcome</span>
<span id="cb50-1091"><a href="#cb50-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1092"><a href="#cb50-1092" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Used for inference under the following circumstances</span>
<span id="cb50-1093"><a href="#cb50-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1094"><a href="#cb50-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We are (scientifically) interested in multiplicative rather than additive models</span>
<span id="cb50-1095"><a href="#cb50-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1096"><a href="#cb50-1096" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We want to down-weight the impact of outliers</span>
<span id="cb50-1097"><a href="#cb50-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1098"><a href="#cb50-1098" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The standard deviation of the response in a groups is proportional to the mean</span>
<span id="cb50-1099"><a href="#cb50-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1100"><a href="#cb50-1100" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>"Error is $\pm 10\%$" instead of "Error is $\pm 10$"</span>
<span id="cb50-1101"><a href="#cb50-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1102"><a href="#cb50-1102" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of Parameters</span></span>
<span id="cb50-1103"><a href="#cb50-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1104"><a href="#cb50-1104" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Linear regression on the log transformed $Y$</span>
<span id="cb50-1105"><a href="#cb50-1105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1106"><a href="#cb50-1106" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Note that in statistics $\textrm{log}$ almost always refers the the natural log ($\textrm{log}_e$)</span>
<span id="cb50-1107"><a href="#cb50-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1108"><a href="#cb50-1108" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Model: $E<span class="co">[</span><span class="ot">\textrm{log} Y_i | X_i</span><span class="co">]</span> = \beta_0 + \beta_1 \times X_i$</span>
<span id="cb50-1109"><a href="#cb50-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1110"><a href="#cb50-1110" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = 0$: $E<span class="co">[</span><span class="ot">\textrm{log} Y_i | X_i = 0</span><span class="co">]</span> = \beta_0$</span>
<span id="cb50-1111"><a href="#cb50-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1112"><a href="#cb50-1112" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x$: $E<span class="co">[</span><span class="ot">\textrm{log} Y_i | X_i = x</span><span class="co">]</span> = \beta_0 + \beta_1 \times x$</span>
<span id="cb50-1113"><a href="#cb50-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1114"><a href="#cb50-1114" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x+1$: $E<span class="co">[</span><span class="ot">\textrm{log} Y_i | X_i = x + 1</span><span class="co">]</span> = \beta_0 + \beta_1 \times x + \beta_1$</span>
<span id="cb50-1115"><a href="#cb50-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1116"><a href="#cb50-1116" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Restate the model as log link for geometric mean</span>
<span id="cb50-1117"><a href="#cb50-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1118"><a href="#cb50-1118" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Model: $\textrm{log GM}<span class="co">[</span><span class="ot">Y_i | X_i</span><span class="co">]</span> = \beta_0 + \beta_1 \times X_i$</span>
<span id="cb50-1119"><a href="#cb50-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1120"><a href="#cb50-1120" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = 0$: $\textrm{log GM}<span class="co">[</span><span class="ot">Y_i | X_i = 0</span><span class="co">]</span> = \beta_0$</span>
<span id="cb50-1121"><a href="#cb50-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1122"><a href="#cb50-1122" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x$: $\textrm{log GM}<span class="co">[</span><span class="ot">Y_i | X_i = x</span><span class="co">]</span> = \beta_0 + \beta_1 \times x$</span>
<span id="cb50-1123"><a href="#cb50-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1124"><a href="#cb50-1124" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x+1$: $\textrm{log GM}<span class="co">[</span><span class="ot">Y_i | X_i = x + 1</span><span class="co">]</span> = \beta_0 + \beta_1 \times x + \beta_1$</span>
<span id="cb50-1125"><a href="#cb50-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1126"><a href="#cb50-1126" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation of parameters by back-transforming model</span>
<span id="cb50-1127"><a href="#cb50-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1128"><a href="#cb50-1128" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Model: $\textrm{GM}<span class="co">[</span><span class="ot">Y_i | X_i</span><span class="co">]</span> = e^{\beta_0} \times e^{\beta_1 \times X_i}$</span>
<span id="cb50-1129"><a href="#cb50-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1130"><a href="#cb50-1130" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = 0$: $\textrm{GM}<span class="co">[</span><span class="ot">Y_i | X_i = 0</span><span class="co">]</span> = e^{\beta_0}$</span>
<span id="cb50-1131"><a href="#cb50-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1132"><a href="#cb50-1132" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x$: $\textrm{GM}<span class="co">[</span><span class="ot">Y_i | X_i = x</span><span class="co">]</span> = e^{\beta_0} \times e^{\beta_1 \times x}$</span>
<span id="cb50-1133"><a href="#cb50-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1134"><a href="#cb50-1134" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>When $X_i = x+1$: $\textrm{GM}<span class="co">[</span><span class="ot">Y_i | X_i = x + 1</span><span class="co">]</span> = e^{\beta_0} \times e^{\beta_1 \times x} \times e^{\beta_1}$</span>
<span id="cb50-1135"><a href="#cb50-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1136"><a href="#cb50-1136" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example: FEV with Height</span></span>
<span id="cb50-1137"><a href="#cb50-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1138"><a href="#cb50-1138" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Question: How does FEV differ across height groups?</span>
<span id="cb50-1139"><a href="#cb50-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1140"><a href="#cb50-1140" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Scientific justification for summarizing with geometric mean</span>
<span id="cb50-1141"><a href="#cb50-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1142"><a href="#cb50-1142" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>FEV is a volume</span>
<span id="cb50-1143"><a href="#cb50-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1144"><a href="#cb50-1144" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Height is a linear dimension</span>
<span id="cb50-1145"><a href="#cb50-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1146"><a href="#cb50-1146" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Each dimension of lung size is proportional to height</span>
<span id="cb50-1147"><a href="#cb50-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1148"><a href="#cb50-1148" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Standard deviation is likely proportional to height</span>
<span id="cb50-1149"><a href="#cb50-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1150"><a href="#cb50-1150" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Science: $FEV \propto Height^3$ or $\sqrt<span class="co">[</span><span class="ot">3</span><span class="co">]</span>{FEV} \propto Height$</span>
<span id="cb50-1151"><a href="#cb50-1151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1152"><a href="#cb50-1152" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistics: $\textrm{log}(FEV) \propto 3 \textrm{ log}(Height)$</span>
<span id="cb50-1153"><a href="#cb50-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1154"><a href="#cb50-1154" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Science dictates model choice</span>
<span id="cb50-1155"><a href="#cb50-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1156"><a href="#cb50-1156" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical preference for (any) transformations of response</span>
<span id="cb50-1157"><a href="#cb50-1157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1158"><a href="#cb50-1158" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>May transform to equal variance across groups</span>
<span id="cb50-1159"><a href="#cb50-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1160"><a href="#cb50-1160" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Homoscedasticity allows for easier inference</span>
<span id="cb50-1161"><a href="#cb50-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1162"><a href="#cb50-1162" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical preference for a log transformation</span>
<span id="cb50-1163"><a href="#cb50-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1164"><a href="#cb50-1164" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Easier interpretation: multiplicative model</span>
<span id="cb50-1165"><a href="#cb50-1165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1166"><a href="#cb50-1166" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Compare groups using ratios</span>
<span id="cb50-1167"><a href="#cb50-1167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1168"><a href="#cb50-1168" aria-hidden="true" tabindex="-1"></a><span class="fu">### Log Transformed Predictors</span></span>
<span id="cb50-1169"><a href="#cb50-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1170"><a href="#cb50-1170" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation of log predictor and log link for response</span>
<span id="cb50-1171"><a href="#cb50-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1172"><a href="#cb50-1172" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Log link used to model the geometric mean of $Y$</span>
<span id="cb50-1173"><a href="#cb50-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1174"><a href="#cb50-1174" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Exponentiated slope estimates ratio of geometric means across groups</span>
<span id="cb50-1175"><a href="#cb50-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1176"><a href="#cb50-1176" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Log transformation of predictor compares groups with a $k$-fold difference in there measured predictors</span>
<span id="cb50-1177"><a href="#cb50-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1178"><a href="#cb50-1178" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimated ratio of geometric means</span>
<span id="cb50-1179"><a href="#cb50-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1180"><a href="#cb50-1180" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\exp (\textrm{log}(k) \times \beta_1) = k^{\beta_1}$</span>
<span id="cb50-1181"><a href="#cb50-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1182"><a href="#cb50-1182" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpretation of model</span>
<span id="cb50-1183"><a href="#cb50-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1184"><a href="#cb50-1184" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>$\textrm{log GM}<span class="co">[</span><span class="ot">FEV_i | log (height_i)</span><span class="co">]</span> = -11.9 + 3.12 \times log(height_i)$</span>
<span id="cb50-1185"><a href="#cb50-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1186"><a href="#cb50-1186" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Estimate ratio of geometric mean FEV for two groups differing by $10\%$ in height (a 1.1 fold difference in height)</span>
<span id="cb50-1187"><a href="#cb50-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1188"><a href="#cb50-1188" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>To find: Exponentiate $1.1$ to the slope: $1.1^{3.12} = 1.35$</span>
<span id="cb50-1189"><a href="#cb50-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1190"><a href="#cb50-1190" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>"Group that is 10% taller is estimated to have a geometric mean FEV that is 1.35 times higher (35% higher)"</span>
<span id="cb50-1191"><a href="#cb50-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1192"><a href="#cb50-1192" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Why transform the predictor?</span>
<span id="cb50-1193"><a href="#cb50-1193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1194"><a href="#cb50-1194" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Typically chosen according to whether the data are likely to follow a straight line relationship</span>
<span id="cb50-1195"><a href="#cb50-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1196"><a href="#cb50-1196" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Linearity necessary to predict the values of the parameter in individual groups</span>
<span id="cb50-1197"><a href="#cb50-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1198"><a href="#cb50-1198" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Linearity is not necessary to estimate existence of an association</span>
<span id="cb50-1199"><a href="#cb50-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1200"><a href="#cb50-1200" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Linearity is not necessary to estimate a first order trend in the parameter across groups having the sampled distribution of the predictor</span>
<span id="cb50-1201"><a href="#cb50-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1202"><a href="#cb50-1202" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>(Inference about these two questions will tend to be conservative if linearity does not hold)</span>
<span id="cb50-1203"><a href="#cb50-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1204"><a href="#cb50-1204" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Rarely do we know which transformation of the predictor provides the best linear fit</span>
<span id="cb50-1205"><a href="#cb50-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1206"><a href="#cb50-1206" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>As always, there is significant danger in using the data to estimate the best transformation to use</span>
<span id="cb50-1207"><a href="#cb50-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1208"><a href="#cb50-1208" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>If there is no association of any kind between the response and the predictor, a linear fit (with a zero slope) is correct</span>
<span id="cb50-1209"><a href="#cb50-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1210"><a href="#cb50-1210" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Trying to detect a transformation is thus an informal test for an association (multiple testing, which inflates type I error rate)</span>
<span id="cb50-1211"><a href="#cb50-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1212"><a href="#cb50-1212" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>It is best to choose transformations of the predictor on scientific grounds</span>
<span id="cb50-1213"><a href="#cb50-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1214"><a href="#cb50-1214" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>In practice, it is often true that mean functions are well approximated by a straight line over a small range of the data</span>
<span id="cb50-1215"><a href="#cb50-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1216"><a href="#cb50-1216" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Example: In the FEV dataset, the logarithm of height is approximately linear over the range of heights sampled (look at the plot)</span>
<span id="cb50-1217"><a href="#cb50-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1218"><a href="#cb50-1218" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We can often choose untransformed predictors when science would suggest a non-linear association</span>
<span id="cb50-1219"><a href="#cb50-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1220"><a href="#cb50-1220" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Can have major advantages in interpreting the results of the analysis</span>
<span id="cb50-1221"><a href="#cb50-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1222"><a href="#cb50-1222" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In the FEV example, it is far more natural to compare heights by difference than by ratios</span>
<span id="cb50-1223"><a href="#cb50-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1224"><a href="#cb50-1224" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>We would rather characterize two children as differing by 4 inches in height rather than as the 44 inch child being 10% taller than the 40 inch child</span>
<span id="cb50-1225"><a href="#cb50-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1226"><a href="#cb50-1226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Looking Ahead to Multivariable Models</span></span>
<span id="cb50-1227"><a href="#cb50-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1228"><a href="#cb50-1228" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The relative importance of having the "true" transformation for a predictor depends on the statistical role</span>
<span id="cb50-1229"><a href="#cb50-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1230"><a href="#cb50-1230" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Predictor of Interest</span>
<span id="cb50-1231"><a href="#cb50-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1232"><a href="#cb50-1232" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Effect Modifiers</span>
<span id="cb50-1233"><a href="#cb50-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1234"><a href="#cb50-1234" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Confounders</span>
<span id="cb50-1235"><a href="#cb50-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1236"><a href="#cb50-1236" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Precision variables</span>
<span id="cb50-1237"><a href="#cb50-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1238"><a href="#cb50-1238" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We treat these variables different when planning our analysis</span>
<span id="cb50-1239"><a href="#cb50-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1240"><a href="#cb50-1240" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Predictor of Interest (should be pre-specified)</span>
<span id="cb50-1241"><a href="#cb50-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1242"><a href="#cb50-1242" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>In general, don't worry about modeling the exact association until you have even established an association (binary search)</span>
<span id="cb50-1243"><a href="#cb50-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1244"><a href="#cb50-1244" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Need to have a prespecified model for the POI</span>
<span id="cb50-1245"><a href="#cb50-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1246"><a href="#cb50-1246" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Searching for the best fit can inflate the type I error</span>
<span id="cb50-1247"><a href="#cb50-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1248"><a href="#cb50-1248" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Make most accurate, precise inference about the presence of the association first</span>
<span id="cb50-1249"><a href="#cb50-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1250"><a href="#cb50-1250" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Exploratory models can suggest models for future analyses</span>
<span id="cb50-1251"><a href="#cb50-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1252"><a href="#cb50-1252" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Effect Modifiers (difficult to do right anyway)</span>
<span id="cb50-1253"><a href="#cb50-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1254"><a href="#cb50-1254" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Modeling of effect modifiers is invariably just a test for the existence of an interaction</span>
<span id="cb50-1255"><a href="#cb50-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1256"><a href="#cb50-1256" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>We rarely have a lot of precision to answer questions in subgroups of the data</span>
<span id="cb50-1257"><a href="#cb50-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1258"><a href="#cb50-1258" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Patterns of interaction can be so complex that it is unlikely that we will really capture the interactions across all subgroups in a single model</span>
<span id="cb50-1259"><a href="#cb50-1259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1260"><a href="#cb50-1260" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Typically, we would restrict future studies to analyses treating subgroups separately</span>
<span id="cb50-1261"><a href="#cb50-1261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1262"><a href="#cb50-1262" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Confounders (matters the most)</span>
<span id="cb50-1263"><a href="#cb50-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1264"><a href="#cb50-1264" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>It is important to have an appropriate model of the association between the confounder and the response</span>
<span id="cb50-1265"><a href="#cb50-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1266"><a href="#cb50-1266" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Failure to accurately model the confounder means that some residual confounding will exist</span>
<span id="cb50-1267"><a href="#cb50-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1268"><a href="#cb50-1268" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>However, searching for the best model may inflate the type I error for inference about the predictor of interest by overstating the precision of the study</span>
<span id="cb50-1269"><a href="#cb50-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1270"><a href="#cb50-1270" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>Luckily, we rarely care about inference for the confounder, so we are free to use inefficient means of adjustment (e.g. a stratified analysis)</span>
<span id="cb50-1271"><a href="#cb50-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1272"><a href="#cb50-1272" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Precision Variables</span>
<span id="cb50-1273"><a href="#cb50-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1274"><a href="#cb50-1274" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>When modeling precision variables, it is rarely worth the effort to use the "best" transformation</span>
<span id="cb50-1275"><a href="#cb50-1275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1276"><a href="#cb50-1276" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>We usually capture the largest part of the added precision using crude models</span>
<span id="cb50-1277"><a href="#cb50-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1278"><a href="#cb50-1278" aria-hidden="true" tabindex="-1"></a><span class="ss">        -   </span>We generally do not care about estimating association between the response and the precision variable</span>
<span id="cb50-1279"><a href="#cb50-1279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-1280"><a href="#cb50-1280" aria-hidden="true" tabindex="-1"></a><span class="ss">            -   </span>Most often, precision variables represent known effects on the response</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024-2026, James C Slaughter</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/chrissl789/modern-regression/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>